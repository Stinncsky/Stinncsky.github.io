{
    "version": "https://jsonfeed.org/version/1",
    "title": "漠溟绽灵的小站",
    "subtitle": "谁知道里面有什么",
    "icon": "https://stinncsky.github.io/images/favicon.ico",
    "description": "嘿嘿嘿~~",
    "home_page_url": "https://stinncsky.github.io",
    "items": [
        {
            "id": "https://stinncsky.github.io/study-notes/code-implementation/Transformer%E7%9A%84%E5%AE%9E%E7%8E%B0/",
            "url": "https://stinncsky.github.io/study-notes/code-implementation/Transformer%E7%9A%84%E5%AE%9E%E7%8E%B0/",
            "title": "Transformer的实现",
            "date_published": "2025-07-19T17:17:29.000Z",
            "content_html": "<p>本文基于<span class=\"exturl\" data-url=\"aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vaGFwcHktbGxtLyMvLi9jaGFwdGVyMi8lRTclQUMlQUMlRTQlQkElOEMlRTclQUIlQTAlMjBUcmFuc2Zvcm1lciVFNiU5RSVCNiVFNiU5RSU4NA==\"> Happy-LLM 第二章 Transformer 架构</span>的实现，详细解析 Transformer 模型的核心组件及其 PyTorch 实现。</p>\n<h1 id=\"位置编码机制\"><a class=\"anchor\" href=\"#位置编码机制\">#</a> 位置编码机制</h1>\n<p>Transformer 架构采用<strong>自注意力机制</strong>处理序列数据，但自注意力本身对位置信息不敏感。为了让模型理解序列中元素的位置关系，需要引入位置编码。</p>\n<details class=\"info\"><summary>绝对位置编码Sinusoidal详解</summary><div>\n<p>绝对位置编码通过<strong>正余弦函数</strong>为序列中的每个位置生成固定的编码向量。该方法的核心思想是利用不同频率的三角函数，为每个位置创建唯一且有规律的表示。</p>\n<p><strong>核心公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">PE_{(pos,2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.03853em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8539999999999999em;vertical-align:-0.704em;\"></span><span class=\"mop\">sin</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">PE_{(pos,2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.03853em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8539999999999999em;vertical-align:-0.704em;\"></span><span class=\"mop\">cos</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">pos</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span> 表示位置索引（0, 1, 2, ...）</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 表示维度索引（0, 1, 2, ..., <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant=\"normal\">/</mi><mn>2</mn><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">d_{model}/2-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>）</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是模型的隐藏层维度</li>\n</ul>\n<p><strong>优势：</strong></p>\n<ol>\n<li><strong>可扩展性</strong>：无需训练即可处理任意长度的序列</li>\n<li><strong>相对位置关系</strong>：任何位置的编码都可以表示为其他位置编码的线性组合</li>\n<li><strong>计算效率</strong>：预计算后直接加法操作，无需额外参数</li>\n</ol>\n<p><strong>缺点：</strong></p>\n<ol>\n<li><strong>固定性</strong>：无法根据任务自适应调整</li>\n<li><strong>远距离建模能力有限</strong>：对于超长序列，位置信息可能变得模糊</li>\n</ol>\n</div></details>\n<figure class=\"highlight python\"><figcaption><span>位置编码实现</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vaGFwcHktbGxtLyMvLi9jaGFwdGVyMi8lRTclQUMlQUMlRTQlQkElOEMlRTclQUIlQTAlMjBUcmFuc2Zvcm1lciVFNiU5RSVCNiVFNiU5RSU4NA==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">PositionalEncoding</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = nn.Dropout(args.dropout)</span><br><span class=\"line\">        <span class=\"comment\"># block size 是序列的最大长度</span></span><br><span class=\"line\">        pe = torch.zeros(args.block_size, args.d_model)</span><br><span class=\"line\">        position = torch.arange(<span class=\"number\">0</span>, args.block_size, dtype=torch.<span class=\"built_in\">float</span>).unsqueeze(<span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        div_term = torch.exp(torch.arange(<span class=\"number\">0</span>, args.d_model, <span class=\"number\">2</span>).<span class=\"built_in\">float</span>() * (-np.log(<span class=\"number\">10000.0</span>) / args.d_model))</span><br><span class=\"line\">        pe[:, <span class=\"number\">0</span>::<span class=\"number\">2</span>] = torch.sin(position * div_term)</span><br><span class=\"line\">        pe[:, <span class=\"number\">1</span>::<span class=\"number\">2</span>] = torch.cos(position * div_term)</span><br><span class=\"line\">        pe = pe.unsqueeze(<span class=\"number\">0</span>)  <span class=\"comment\"># 增加 batch 维度</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.register_buffer(<span class=\"string\">&#x27;pe&#x27;</span>, pe)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.pe[:, :x.size(<span class=\"number\">1</span>)].requires_grad_(<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.dropout(x)</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon\">\n<p>位置编码通过<strong>加法</strong>而非<strong>拼接</strong>的方式与词嵌入结合，这样既保持了模型维度不变，又融入了位置信息。</p>\n</div>\n<h1 id=\"多头注意力机制\"><a class=\"anchor\" href=\"#多头注意力机制\">#</a> 多头注意力机制</h1>\n<p>多头注意力是 Transformer 的核心创新，它允许模型同时关注序列中不同位置的信息，并从多个表示子空间中学习不同类型的依赖关系。</p>\n<h2 id=\"注意力计算原理\"><a class=\"anchor\" href=\"#注意力计算原理\">#</a> 注意力计算原理</h2>\n<p><strong>标准注意力公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence=\"true\">)</mo></mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.468361em;vertical-align:-0.95003em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183309999999999em;\"><span style=\"top:-2.25278em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> (Query)：查询矩阵，形状为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> (Key)：键矩阵，形状为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span> (Value)：值矩阵，形状为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：键向量的维度，用于缩放以防止 softmax 梯度消失</li>\n</ul>\n<p><strong>多头注意力公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>Concat</mtext><mo stretchy=\"false\">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>h</mi></msub><mo stretchy=\"false\">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\text{MultiHead}(Q,K,V) = \\text{Concat}(head_1, ..., head_h)W^O\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">MultiHead</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Concat</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator=\"true\">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator=\"true\">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.236103em;vertical-align:-0.276864em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9592389999999998em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.180908em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<figure class=\"highlight python\"><figcaption><span>多头注意力实现</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vaGFwcHktbGxtLyMvLi9jaGFwdGVyMi8lRTclQUMlQUMlRTQlQkElOEMlRTclQUIlQTAlMjBUcmFuc2Zvcm1lciVFNiU5RSVCNiVFNiU5RSU4NA==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MultiHeadAttention</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs, is_causal=<span class=\"literal\">False</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> args.d_model % args.num_heads == <span class=\"number\">0</span>, <span class=\"string\">&quot;d_model must be divisible by num_heads&quot;</span></span><br><span class=\"line\">        <span class=\"comment\"># 表示当前没有进行模型并行（即所有计算都在一个设备上完成）</span></span><br><span class=\"line\">        model_parallel_size = <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"comment\"># 所以每个头的本地数量是总头数除以模型并行大小</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.n_local_heads = args.num_heads // model_parallel_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.head_dim = args.d_model // args.num_heads</span><br><span class=\"line\">        <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">        权重矩阵本质上就是一个线性变换的参数。</span></span><br><span class=\"line\"><span class=\"string\">        PyTorch 的线性层（nn.Linear）内部实现就是一个权重矩阵和一个可选的偏置项。</span></span><br><span class=\"line\"><span class=\"string\">        线性层的前向计算就是输入张量与权重矩阵做矩阵乘法（加上偏置），</span></span><br><span class=\"line\"><span class=\"string\">        这和我们手动定义权重矩阵并做线性变换是一样的。</span></span><br><span class=\"line\"><span class=\"string\">        &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.wq = nn.Linear(args.d_model, args.num_heads * <span class=\"variable language_\">self</span>.head_dim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.wk = nn.Linear(args.d_model, args.num_heads * <span class=\"variable language_\">self</span>.head_dim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.wv = nn.Linear(args.d_model, args.num_heads * <span class=\"variable language_\">self</span>.head_dim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.wo = nn.Linear(args.num_heads * <span class=\"variable language_\">self</span>.head_dim, args.d_model, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 功能：以args.dropout的概率随机置零</span></span><br><span class=\"line\">        <span class=\"comment\"># 注意力的 dropout</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.attn_dropout = nn.Dropout(args.dropout)</span><br><span class=\"line\">        <span class=\"comment\"># 残差连接的 dropout</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.resid_dropout = nn.Dropout(args.dropout)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.is_causal = is_causal</span><br><span class=\"line\">        <span class=\"keyword\">if</span> is_causal:</span><br><span class=\"line\">            <span class=\"string\">&#x27;&#x27;&#x27;</span></span><br><span class=\"line\"><span class=\"string\">            这个张量的形状是 (1, 1, args.max_seq_len, args.max_seq_len)。</span></span><br><span class=\"line\"><span class=\"string\">                第一个 1：通常表示 batch 维度（批次大小）。</span></span><br><span class=\"line\"><span class=\"string\">                第二个 1：通常表示头数（比如多头注意力中的单头）。</span></span><br><span class=\"line\"><span class=\"string\">                args.max_seq_len：序列长度，表示每个样本的最大长度。</span></span><br><span class=\"line\"><span class=\"string\">                args.max_seq_len：同样是序列长度，用于构造掩码矩阵。</span></span><br><span class=\"line\"><span class=\"string\">            &#x27;&#x27;&#x27;</span></span><br><span class=\"line\">            mask = torch.full((<span class=\"number\">1</span>, <span class=\"number\">1</span>, args.max_seq_len, args.max_seq_len), <span class=\"built_in\">float</span>(<span class=\"string\">&#x27;-inf&#x27;</span>))</span><br><span class=\"line\">            <span class=\"comment\"># 这里的 torch.triu(mask, diagonal=1) 会将上三角部分（不包括对角线）设置为负无穷大。</span></span><br><span class=\"line\">            <span class=\"comment\"># 这样做的目的是为了在计算注意力时，确保每个位置只能看到它之前的位置，</span></span><br><span class=\"line\">            <span class=\"comment\"># 也就是实现了因果注意力（Causal Attention）。</span></span><br><span class=\"line\">            <span class=\"comment\"># 参数 diagonal=1 表示从对角线的上方一行开始填充负无穷大。</span></span><br><span class=\"line\">            mask = torch.triu(mask, diagonal=<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 缓冲区是模型的一部分，但不会被视为可训练参数。这种机制通常用于存储固定的张量。</span></span><br><span class=\"line\">            <span class=\"variable language_\">self</span>.register_buffer(<span class=\"string\">&#x27;mask&#x27;</span>, mask)</span><br></pre></td></tr></table></figure>\n<h2 id=\"因果掩码机制\"><a class=\"anchor\" href=\"#因果掩码机制\">#</a> 因果掩码机制</h2>\n<p>对于解码器中的<strong>掩码自注意力</strong>，需要确保每个位置只能关注到它之前的位置，这通过<strong>上三角掩码</strong>实现：</p>\n<figure class=\"highlight python\"><figcaption><span>注意力前向传播</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, query, key, value, attn_mask=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    batch_size, seq_len, _ = query.size()</span><br><span class=\"line\">    xq, xk, xv = <span class=\"variable language_\">self</span>.wq(query), <span class=\"variable language_\">self</span>.wk(key), <span class=\"variable language_\">self</span>.wv(value)</span><br><span class=\"line\">    <span class=\"comment\"># 将 Q、K、V 拆分成多头，维度为 (B, T, n_head, C // n_head)，然后交换维度，变成 (B, n_head, T, C // n_head)</span></span><br><span class=\"line\">    <span class=\"comment\"># query、key、value 的形状是 (batch_size, seq_len, d_model)</span></span><br><span class=\"line\">    <span class=\"comment\"># 线性变换后，xq、xk、xv 的形状是 (batch_size, seq_len, num_heads * head_dim)</span></span><br><span class=\"line\">    <span class=\"comment\"># 然后将它们重塑为 (batch_size, seq_len, n_local_heads, head_dim)</span></span><br><span class=\"line\">    <span class=\"comment\"># 由于在注意力计算中，我们需要将每个头的维度分开处理，</span></span><br><span class=\"line\">    <span class=\"comment\"># 所以我们需要将最后的维度进行转置，使得每个头的维度在第二个维度上。</span></span><br><span class=\"line\">    <span class=\"comment\"># 然后将它们转置为 (batch_size, n_local_heads, seq_len, head_dim)</span></span><br><span class=\"line\">    xq = xq.view(batch_size, seq_len, <span class=\"variable language_\">self</span>.n_local_heads, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    xk = xk.view(batch_size, seq_len, <span class=\"variable language_\">self</span>.n_local_heads, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    xv = xv.view(batch_size, seq_len, <span class=\"variable language_\">self</span>.n_local_heads, <span class=\"variable language_\">self</span>.head_dim).transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    scores = torch.matmul(xq, xk.transpose(<span class=\"number\">2</span>, <span class=\"number\">3</span>)) / (<span class=\"variable language_\">self</span>.head_dim ** <span class=\"number\">0.5</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"variable language_\">self</span>.is_causal:</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> <span class=\"built_in\">hasattr</span>(<span class=\"variable language_\">self</span>, <span class=\"string\">&#x27;mask&#x27;</span>), <span class=\"string\">&quot;Causal mask not initialized&quot;</span></span><br><span class=\"line\">        scores = scores + <span class=\"variable language_\">self</span>.mask[:, :, :seq_len, :seq_len]</span><br><span class=\"line\">    <span class=\"comment\"># 注意力分数通常是浮点数，保持类型一致</span></span><br><span class=\"line\">    scores = F.softmax(scores.<span class=\"built_in\">float</span>(), dim=-<span class=\"number\">1</span>).type_as(xq)</span><br><span class=\"line\">    scores = <span class=\"variable language_\">self</span>.attn_dropout(scores)</span><br><span class=\"line\">    output = torch.matmul(scores, xv)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 将输出的形状从 (batch_size, n_local_heads, seq_len, head_dim) 转换为 (batch_size, seq_len, num_heads * head_dim)</span></span><br><span class=\"line\">    <span class=\"comment\"># 这里的 contiguous() 是为了确保内存布局是连续的，</span></span><br><span class=\"line\">    <span class=\"comment\"># 这里的 -1 表示自动计算最后一个维度的大小，</span></span><br><span class=\"line\">    <span class=\"comment\"># 这样可以确保输出的形状是 (batch_size, seq_len, num_heads * head_dim)</span></span><br><span class=\"line\">    output = output.transpose(<span class=\"number\">1</span>, <span class=\"number\">2</span>).contiguous().view(batch_size, seq_len, -<span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    output = <span class=\"variable language_\">self</span>.wo(output)</span><br><span class=\"line\">    output = <span class=\"variable language_\">self</span>.resid_dropout(output)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> output</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon\">\n<p>缩放因子 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.18278000000000005em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span></span> 的作用是防止点积结果过大导致 softmax 函数进入梯度消失区域，确保训练稳定性。</p>\n</div>\n<h1 id=\"前馈神经网络\"><a class=\"anchor\" href=\"#前馈神经网络\">#</a> 前馈神经网络</h1>\n<p>Transformer 中的前馈神经网络（FFN）是一个简单的两层全连接网络，为模型提供非线性变换能力。</p>\n<p><strong>FFN 公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>FFN</mtext><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">FFN</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中激活函数采用 ReLU，隐藏层维度通常是输入维度的 4 倍。</p>\n<figure class=\"highlight python\"><figcaption><span>前馈网络实现</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">FFN</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, dim: <span class=\"built_in\">int</span>, hidden_dim: <span class=\"built_in\">int</span>, dropout: <span class=\"built_in\">float</span> = <span class=\"number\">0.1</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.w1 = nn.Linear(dim, hidden_dim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.w2 = nn.Linear(hidden_dim, dim, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = nn.Dropout(dropout)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 原公式：</span></span><br><span class=\"line\">        <span class=\"comment\"># FFN(x) = max(0, xW1 + b1)W2 + b2</span></span><br><span class=\"line\">        <span class=\"comment\"># 其中 W1, b1, W2, b2 是可学习参数，max(0, ·) 是 ReLU 激活函数</span></span><br><span class=\"line\">        res = <span class=\"variable language_\">self</span>.dropout(<span class=\"variable language_\">self</span>.w2(F.relu(<span class=\"variable language_\">self</span>.w1(x))));</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res</span><br></pre></td></tr></table></figure>\n<h1 id=\"层归一化\"><a class=\"anchor\" href=\"#层归一化\">#</a> 层归一化</h1>\n<p>层归一化在 Transformer 中起到稳定训练和加速收敛的作用。与批归一化不同，层归一化在特征维度上进行标准化。</p>\n<p><strong>Layer Norm 公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>LayerNorm</mtext><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>γ</mi><mfrac><mrow><mi>x</mi><mo>−</mo><mi>μ</mi></mrow><mrow><mi>σ</mi><mo>+</mo><mi>ϵ</mi></mrow></mfrac><mo>+</mo><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\text{LayerNorm}(x) = \\gamma \\frac{x - \\mu}{\\sigma + \\epsilon} + \\beta\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">LayerNorm</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0296600000000002em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2603300000000002em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> 分别是输入在特征维度上的均值和标准差</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>γ</mi></mrow><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 是可学习的缩放和偏移参数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span> 是防止除零的小常数</li>\n</ul>\n<figure class=\"highlight python\"><figcaption><span>层归一化实现</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LayerNorm</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, features, eps: <span class=\"built_in\">float</span> = <span class=\"number\">1e-6</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.weight = nn.Parameter(torch.ones(features))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.bias = nn.Parameter(torch.zeros(features))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.eps = eps</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        mean = x.mean(dim=-<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        std = x.std(dim=-<span class=\"number\">1</span>, keepdim=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        normalized = (x - mean) / (std + <span class=\"variable language_\">self</span>.eps)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.weight * normalized + <span class=\"variable language_\">self</span>.bias</span><br></pre></td></tr></table></figure>\n<h1 id=\"编码器架构\"><a class=\"anchor\" href=\"#编码器架构\">#</a> 编码器架构</h1>\n<p>编码器采用<strong> Pre-LayerNorm</strong> 结构，即在每个子层之前进行层归一化，这种结构相比 Post-LayerNorm 具有更好的训练稳定性。</p>\n<figure class=\"highlight python\"><figcaption><span>编码器层实现</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">EncoderLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.self_attn = MultiHeadAttention(args, is_causal=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ffn = FFN(args.d_model, args.d_model * <span class=\"number\">4</span>, dropout=args.dropout)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ln1 = LayerNorm(args.d_model)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ln2 = LayerNorm(args.d_model)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 实际上经典的tansformer采用的是Pre-LN结构，</span></span><br><span class=\"line\">        <span class=\"comment\"># 即在每个子层之前进行层归一化，而不是在子层之后。</span></span><br><span class=\"line\">        <span class=\"comment\"># 残差依然是在子层之后进行的。</span></span><br><span class=\"line\">        <span class=\"comment\"># Self-attention</span></span><br><span class=\"line\">        x_norm = <span class=\"variable language_\">self</span>.ln1(x)</span><br><span class=\"line\">        attn_output = x + <span class=\"variable language_\">self</span>.self_attn.forward(x_norm, x_norm, x_norm)</span><br><span class=\"line\">        <span class=\"comment\"># FFN</span></span><br><span class=\"line\">        output = attn_output + <span class=\"variable language_\">self</span>.ffn(<span class=\"variable language_\">self</span>.ln2(attn_output))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br></pre></td></tr></table></figure>\n<p><strong>编码器堆叠：</strong></p>\n<figure class=\"highlight python\"><figcaption><span>完整编码器</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Encoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.layers = nn.ModuleList([EncoderLayer(args) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(args.n_layers)])</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ln = LayerNorm(args.d_model)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.layers:</span><br><span class=\"line\">            x = layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.ln(x)  <span class=\"comment\"># 最后一个层归一化</span></span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon\">\n<p>编码器的自注意力可以看到序列中的所有位置，因此不需要掩码机制。</p>\n</div>\n<h1 id=\"解码器架构\"><a class=\"anchor\" href=\"#解码器架构\">#</a> 解码器架构</h1>\n<p>解码器比编码器多了一个<strong>交叉注意力</strong>层，用于关注编码器的输出。解码器包含三个主要组件：</p>\n<ol>\n<li><strong>掩码自注意力</strong>：只能关注当前位置之前的内容</li>\n<li><strong>交叉注意力</strong>：Query 来自解码器，Key 和 Value 来自编码器</li>\n<li><strong>前馈神经网络</strong>：提供非线性变换</li>\n</ol>\n<figure class=\"highlight python\"><figcaption><span>解码器层实现</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">DecoderLayer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.mask_norm = LayerNorm(args.d_model)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.masked_self_attn = MultiHeadAttention(args, is_causal=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.multi_norm = LayerNorm(args.d_model)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.multi_attn = MultiHeadAttention(args, is_causal=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ffn_norm = LayerNorm(args.d_model)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ffn = FFN(args.d_model, args.d_model * <span class=\"number\">4</span>, dropout=args.dropout)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, enc_output</span>):</span><br><span class=\"line\">        <span class=\"comment\"># layer norm</span></span><br><span class=\"line\">        x_norm = <span class=\"variable language_\">self</span>.mask_norm(x)</span><br><span class=\"line\">        <span class=\"comment\"># Masked self-attention</span></span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.masked_self_attn.forward(x_norm, x_norm, x_norm)</span><br><span class=\"line\">        <span class=\"comment\"># layer norm</span></span><br><span class=\"line\">        x_norm = <span class=\"variable language_\">self</span>.multi_norm(x)</span><br><span class=\"line\">        <span class=\"comment\"># Multi-head attention with encoder output</span></span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.multi_attn.forward(x_norm, enc_output, enc_output)</span><br><span class=\"line\">        <span class=\"comment\"># layer norm</span></span><br><span class=\"line\">        x_norm = <span class=\"variable language_\">self</span>.ffn_norm(x)</span><br><span class=\"line\">        <span class=\"comment\"># Feed-forward network</span></span><br><span class=\"line\">        x = x + <span class=\"variable language_\">self</span>.ffn(x_norm)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> x</span><br></pre></td></tr></table></figure>\n<p><strong>解码器堆叠</strong></p>\n<figure class=\"highlight python\"><figcaption><span>完整解码器</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Decoder</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.layers = nn.ModuleList([DecoderLayer(args) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(args.n_layers)])</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.ln = LayerNorm(args.d_model)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, enc_output</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.layers:</span><br><span class=\"line\">            x = layer(x, enc_output)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.ln(x)  <span class=\"comment\"># 最后一个层归一化</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"完整transformer模型\"><a class=\"anchor\" href=\"#完整transformer模型\">#</a> 完整 Transformer 模型</h1>\n<p>将所有组件整合，构建完整的 Transformer 模型：</p>\n<figure class=\"highlight python\"><figcaption><span>模型配置类</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">ModelArgs</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, d_model, num_heads, dropout=<span class=\"number\">0.1</span>, max_seq_len=<span class=\"number\">512</span>, n_layers=<span class=\"number\">6</span>,</span></span><br><span class=\"line\"><span class=\"params\">                 vocab_size=<span class=\"number\">10000</span>, block_size=<span class=\"number\">128</span></span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.d_model = d_model</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_heads = num_heads</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.dropout = dropout</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.max_seq_len = max_seq_len</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.n_layers = n_layers</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.vocab_size = vocab_size</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.block_size = block_size</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><figcaption><span>完整Transformer模型</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly9kYXRhd2hhbGVjaGluYS5naXRodWIuaW8vaGFwcHktbGxtLyMvLi9jaGFwdGVyMi8lRTclQUMlQUMlRTQlQkElOEMlRTclQUIlQTAlMjBUcmFuc2Zvcm1lciVFNiU5RSVCNiVFNiU5RSU4NA==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Transformer</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, args: ModelArgs</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 必须输入词表大小和 block size</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> args.vocab_size <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> args.block_size <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.args = args</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.transformer = nn.ModuleDict(<span class=\"built_in\">dict</span>(</span><br><span class=\"line\">            encoder=Encoder(args),</span><br><span class=\"line\">            decoder=Decoder(args),</span><br><span class=\"line\">            positional_encoding=PositionalEncoding(args),</span><br><span class=\"line\">            embedding=nn.Embedding(args.vocab_size, args.d_model, padding_idx=<span class=\"number\">0</span>),</span><br><span class=\"line\">            dropout=nn.Dropout(args.dropout),</span><br><span class=\"line\">        ))</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.lm_head = nn.Linear(args.d_model, args.vocab_size, bias=<span class=\"literal\">False</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.apply(<span class=\"variable language_\">self</span>._init_weights)</span><br><span class=\"line\">        <span class=\"comment\"># 查看所有参数的数量</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;number of parameters: %.2fM&quot;</span> % (<span class=\"variable language_\">self</span>.get_num_params()/<span class=\"number\">1e6</span>,))</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">_init_weights</span>(<span class=\"params\">self, module</span>):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(module, nn.Linear):</span><br><span class=\"line\">            <span class=\"comment\"># 使用正态分布初始化线性层的权重</span></span><br><span class=\"line\">            nn.init.normal_(module.weight, mean=<span class=\"number\">0.0</span>, std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> module.bias <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">                nn.init.zeros_(module.bias)</span><br><span class=\"line\">        <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(module, nn.Embedding):</span><br><span class=\"line\">            <span class=\"comment\"># 嵌入层的权重使用正态分布初始化</span></span><br><span class=\"line\">            nn.init.normal_(module.weight, mean=<span class=\"number\">0.0</span>, std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_num_params</span>(<span class=\"params\">self, non_embedding=<span class=\"literal\">True</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        计算模型参数的数量</span></span><br><span class=\"line\"><span class=\"string\">        :param non_embedding: 是否排除嵌入层参数</span></span><br><span class=\"line\"><span class=\"string\">        :return: 参数数量</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> non_embedding:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(p.numel() <span class=\"keyword\">for</span> n, p <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.named_parameters() <span class=\"keyword\">if</span> <span class=\"string\">&#x27;embedding&#x27;</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> n)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">sum</span>(p.numel() <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.parameters())</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x, targets=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">        <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">        :param x: 输入序列，形状为 (batch_size, seq_len, 1)</span></span><br><span class=\"line\"><span class=\"string\">        :param targets: 目标序列，形状为 (batch_size, seq_len, 1)，可选用于计算损失</span></span><br><span class=\"line\"><span class=\"string\">        :return: 输出 logits，形状为 (batch_size, seq_len, vocab_size)</span></span><br><span class=\"line\"><span class=\"string\">        &quot;&quot;&quot;</span></span><br><span class=\"line\">        device = x.device</span><br><span class=\"line\">        batch_size, seq_len = x.size()</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> seq_len &lt;= <span class=\"variable language_\">self</span>.args.block_size, <span class=\"string\">&quot;Sequence length exceeds block size&quot;</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;x&quot;</span>, x.shape)</span><br><span class=\"line\">        <span class=\"comment\"># 通过embedding层将输入序列转换为词向量 形状为 (batch_size, seq_len, d_model)</span></span><br><span class=\"line\">        tok_emb = <span class=\"variable language_\">self</span>.transformer.embedding(x)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;tok_emb&quot;</span>, tok_emb.shape)</span><br><span class=\"line\">        pos_emb = <span class=\"variable language_\">self</span>.transformer.positional_encoding(tok_emb)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;pos_emb&quot;</span>, pos_emb.shape)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.transformer.dropout(pos_emb)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;x after dropout&quot;</span>, x.shape)</span><br><span class=\"line\">        enc_output = <span class=\"variable language_\">self</span>.transformer.encoder(x)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;enc_output&quot;</span>, enc_output.shape)</span><br><span class=\"line\">        x = <span class=\"variable language_\">self</span>.transformer.decoder(x, enc_output)</span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&quot;x after decoder&quot;</span>, x.shape)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> targets <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 计算损失</span></span><br><span class=\"line\">            logits = <span class=\"variable language_\">self</span>.lm_head(x)</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;logits&quot;</span>, logits.shape)</span><br><span class=\"line\">            <span class=\"comment\"># 计算交叉熵损失</span></span><br><span class=\"line\">            loss = F.cross_entropy(logits.view(-<span class=\"number\">1</span>, logits.size(-<span class=\"number\">1</span>)), targets.view(-<span class=\"number\">1</span>), ignore_index=-<span class=\"number\">1</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> logits, loss</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            logits = <span class=\"variable language_\">self</span>.lm_head(x[:, [-<span class=\"number\">1</span>], :])  <span class=\"comment\"># 只取序列中的最后一个作为输出</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;logits&quot;</span>, logits.shape)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> logits</span><br></pre></td></tr></table></figure>\n<h1 id=\"模型初始化与训练细节\"><a class=\"anchor\" href=\"#模型初始化与训练细节\">#</a> 模型初始化与训练细节</h1>\n<h2 id=\"权重初始化策略\"><a class=\"anchor\" href=\"#权重初始化策略\">#</a> 权重初始化策略</h2>\n<p>模型采用<strong> Xavier 初始化</strong>的变种，对不同类型的层使用不同的初始化方法：</p>\n<ul>\n<li><strong>线性层</strong>：使用均值为 0，标准差为 0.02 的正态分布</li>\n<li><strong>嵌入层</strong>：同样使用正态分布初始化，确保词向量的合理分布</li>\n</ul>\n<h2 id=\"参数统计\"><a class=\"anchor\" href=\"#参数统计\">#</a> 参数统计</h2>\n<p>模型提供参数统计功能，可以选择是否包含嵌入层参数。这对于模型分析和资源估算很有用。</p>\n<div class=\"note info no-icon\">\n<p>Pre-LayerNorm 结构相比原始的 Post-LayerNorm 结构具有更好的<strong>梯度流</strong>和<strong>训练稳定性</strong>，因此被广泛采用。</p>\n</div>\n<h1 id=\"数据流转换过程\"><a class=\"anchor\" href=\"#数据流转换过程\">#</a> 数据流转换过程</h1>\n<p>Transformer 的前向传播过程涉及多次维度变换：</p>\n<ol>\n<li><strong>输入嵌入</strong>：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo stretchy=\"false\">)</mo><mo>→</mo><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len) \\rightarrow (batch\\_size, seq\\_len, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li><strong>位置编码</strong>：与嵌入向量相加，维度保持不变</li>\n<li><strong>编码器处理</strong>：维度保持<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len, d_{model})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li><strong>解码器处理</strong>：同时接收编码器输出和目标序列</li>\n<li><strong>输出投影</strong>：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo stretchy=\"false\">)</mo><mo>→</mo><mo stretchy=\"false\">(</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo separator=\"true\">,</mo><mi>s</mi><mi>e</mi><mi>q</mi><mi mathvariant=\"normal\">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo separator=\"true\">,</mo><mi>v</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>b</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(batch\\_size, seq\\_len, d_{model}) \\rightarrow (batch\\_size, seq\\_len, vocab\\_size)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.06em;vertical-align:-0.31em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">h</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">b</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></li>\n</ol>\n<p>这种完整的实现展示了 Transformer 架构的核心思想：通过<strong>自注意力机制</strong>实现序列建模，通过<strong>残差连接</strong>和<strong>层归一化</strong>保证训练稳定性，通过<strong>位置编码</strong>引入位置信息。该实现为理解和扩展 Transformer 系列模型奠定了坚实基础。</p>\n",
            "tags": [
                "学习笔记",
                "代码实现",
                "PyTorch",
                "神经网络",
                "深度学习",
                "Transformer",
                "注意力机制",
                "位置编码",
                "多头注意力",
                "序列建模",
                "机器学习"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1233-%E5%88%A0%E9%99%A4%E5%AD%90%E6%96%87%E4%BB%B6%E5%A4%B9/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1233-%E5%88%A0%E9%99%A4%E5%AD%90%E6%96%87%E4%BB%B6%E5%A4%B9/",
            "title": "力扣每日一题：1233. 删除子文件夹",
            "date_published": "2025-07-19T04:56:22.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9yZW1vdmUtc3ViLWZvbGRlcnMtZnJvbS10aGUtZmlsZXN5c3RlbT9lbnZUeXBlPWRhaWx5LXF1ZXN0aW9uJmFtcDtlbnZJZD0yMDI1LTA3LTE5\">LeetCode 1233</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>你是一位系统管理员，手里有一份文件夹列表  <code>folder</code> ，你的任务是要删除该列表中的所有 子文件夹，并以 任意顺序 返回剩下的文件夹。</p>\n<p>如果文件夹  <code>folder[i]</code>  位于另一个文件夹  <code>folder[j]</code>  下，那么  <code>folder[i]</code>  就是  <code>folder[j]</code>  的 子文件夹 。 <code>folder[j]</code>  的子文件夹必须以  <code>folder[j]</code>  开头，后跟一个  <code>&quot;/&quot;</code> 。例如， <code>&quot;/a/b&quot;</code>  是  <code>&quot;/a&quot;</code>  的一个子文件夹，但  <code>&quot;/b&quot;</code>  不是  <code>&quot;/a/b/c&quot;</code>  的一个子文件夹。</p>\n<p>文件夹的「路径」是由一个或多个按以下格式串联形成的字符串： <code>'/'</code>  后跟一个或者多个小写英文字母。</p>\n<pre><code>例如，`&quot;/leetcode&quot;` 和 `&quot;/leetcode/problems&quot;` 都是有效的路径，而空字符串和 `&quot;/&quot;` 不是。\n</code></pre>\n<div class=\"note info no-icon\">\n<ul>\n<li>1 &lt;=  <code>folder.length</code>  &lt;= 4 * 104</li>\n<li>2 &lt;=  <code>folder[i].length</code>  &lt;= 100</li>\n<li><code>folder[i]</code>  只包含小写字母和 '/'</li>\n<li><code>folder[i]</code>  总是以字符 '/' 起始</li>\n<li><code>folder</code>  每个元素都是 唯一 的</li>\n</ul>\n</div>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>思路一：排序 + 哈希表</p>\n<ol>\n<li>首先对文件夹路径进行排序，这样可以确保子文件夹在父文件夹之前。</li>\n<li>使用哈希表记录所有文件夹路径。</li>\n<li>遍历文件夹路径，如果当前路径是某个已存在路径的前缀，则说明是子文件夹，跳过。</li>\n<li>否则，将当前路径加入结果集。</li>\n</ol>\n<p>思路二：排序</p>\n<ol>\n<li>对文件夹路径进行排序。</li>\n<li>遍历排序后的文件夹路径，检查当前路径是否是上一个路径的子文件夹。</li>\n<li>如果是，则跳过；如果不是，则将其加入结果集。</li>\n</ol>\n<div class=\"note warning\">\n<p>该思路通过查看用时更少的代码得到的。<br />\n由于直接排序就是字典序，所以如果当前路径是上一个路径的子文件夹，则一定是相邻的。如果上以一个文件夹是子文件夹，且当前文件夹是上一个文件夹的子文件夹，则当前文件夹一定是上一个文件夹的父文件夹的子文件夹。所以不用担心会漏掉其他的子文件夹，只要最开始的父文件夹不被删除即可。</p>\n</div>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法1</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">vector&lt;string&gt; <span class=\"title\">removeSubfolders</span><span class=\"params\">(vector&lt;string&gt;&amp; folder)</span> </span>&#123;</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(folder);</span><br><span class=\"line\">        unordered_map&lt;string,<span class=\"type\">bool</span>&gt; mp;</span><br><span class=\"line\">        vector&lt;string&gt; ans;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> f:folder)&#123;</span><br><span class=\"line\">            mp[f] = <span class=\"number\">1</span>;</span><br><span class=\"line\">            <span class=\"keyword\">auto</span> s = f;</span><br><span class=\"line\">            <span class=\"type\">bool</span> is = <span class=\"literal\">false</span>;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (f.<span class=\"built_in\">rfind</span>(<span class=\"string\">&#x27;/&#x27;</span>) != <span class=\"number\">0</span> &amp;&amp; !is)&#123;</span><br><span class=\"line\">                f = f.<span class=\"built_in\">substr</span>(<span class=\"number\">0</span>,f.<span class=\"built_in\">rfind</span>(<span class=\"string\">&#x27;/&#x27;</span>));</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (mp[f]) is = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!is) ans.<span class=\"built_in\">push_back</span>(s);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><figcaption><span>C++ 解法2</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\">vector&lt;string&gt; <span class=\"title\">removeSubfolders</span><span class=\"params\">(vector&lt;string&gt;&amp; folder)</span> </span>&#123;</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(folder);</span><br><span class=\"line\">        vector&lt;string&gt; ans;</span><br><span class=\"line\">        ans.<span class=\"built_in\">push_back</span>(folder[<span class=\"number\">0</span>]);</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; folder.<span class=\"built_in\">size</span>(); i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!folder[i].<span class=\"built_in\">starts_with</span>(ans.<span class=\"built_in\">back</span>()) || folder[i][ans.<span class=\"built_in\">back</span>().<span class=\"built_in\">size</span>()] != <span class=\"string\">&#x27;/&#x27;</span>) ans.<span class=\"built_in\">push_back</span>(folder[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "字符串",
                "排序"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/code-implementation/PyTorch%E7%9A%84%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8D%95%E6%9E%84%E5%BB%BA/",
            "url": "https://stinncsky.github.io/study-notes/code-implementation/PyTorch%E7%9A%84%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8D%95%E6%9E%84%E5%BB%BA/",
            "title": "PyTorch的初步使用：线性模型简单构建",
            "date_published": "2025-07-18T08:18:11.000Z",
            "content_html": "<div class=\"note info no-icon\">\n<p>本文<strong>代码来源：</strong> <span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">《动手学深度学习》(PyTorch 版)</span></p>\n</div>\n<h1 id=\"数据批处理与小批量梯度下降\"><a class=\"anchor\" href=\"#数据批处理与小批量梯度下降\">#</a> 数据批处理与小批量梯度下降</h1>\n<p>在深度学习训练过程中，小批量随机梯度下降是主流的优化方法。PyTorch 提供了便捷的数据加载工具来实现批处理。</p>\n<details class=\"info\"><summary>小批量随机梯度下降原理</summary><div>\n<p>小批量随机梯度下降（mini-batch stochastic gradient descent）是梯度下降算法的变种，它在每次迭代中使用一个小批量（mini-batch）的样本来计算梯度。</p>\n<p><strong>算法流程：</strong></p>\n<ol>\n<li>将训练数据集分成若干个大小为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span> 的小批量</li>\n<li>对于每个小批量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><msubsup><mo stretchy=\"false\">}</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\{x^{(i)}, y^{(i)}\\}_{i=1}^m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.146664em;vertical-align:-0.258664em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">}</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-2.441336em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span>，计算梯度：<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>L</mi><mo stretchy=\"false\">(</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy=\"false\">(</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\nabla_\\theta J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\nabla_\\theta L(f_\\theta(x^{(i)}), y^{(i)})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.929066em;vertical-align:-1.277669em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</li>\n<li>更新参数：<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>θ</mi><mo>←</mo><mi>θ</mi><mo>−</mo><mi>η</mi><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span></span></p>\n</li>\n</ol>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span> 是学习率，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi></mrow><annotation encoding=\"application/x-tex\">L</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">L</span></span></span></span> 是损失函数，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding=\"application/x-tex\">f_\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是模型。</p>\n<p><strong>优势：</strong></p>\n<ul>\n<li>相比全批量梯度下降，计算效率更高</li>\n<li>相比单样本随机梯度下降，梯度估计更稳定</li>\n<li>能够利用现代 GPU 的并行计算能力</li>\n</ul>\n</div></details>\n<figure class=\"highlight python\"><figcaption><span>数据加载器实现</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.utils.data <span class=\"keyword\">as</span> Data</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将训练数据的特征和标签组合</span></span><br><span class=\"line\">dataset = Data.TensorDataset(features, labels)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 随机读取小批量</span></span><br><span class=\"line\">data_iter = Data.DataLoader(dataset, batch_size, shuffle=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon\">\n<p>使用 <code>DataLoader</code>  可以自动处理数据的随机打乱和批处理，大大简化了训练流程。</p>\n</div>\n<h1 id=\"神经网络模型定义\"><a class=\"anchor\" href=\"#神经网络模型定义\">#</a> 神经网络模型定义</h1>\n<p>PyTorch 提供了两种主要方式来构建神经网络：继承 <code>nn.Module</code>  类和使用 <code>nn.Sequential</code>  容器。</p>\n<h2 id=\"方式一继承nnmodule类\"><a class=\"anchor\" href=\"#方式一继承nnmodule类\">#</a> 方式一：继承 nn.Module 类</h2>\n<p>通过继承 <code>nn.Module</code>  类，可以灵活定义网络结构和前向传播过程。</p>\n<figure class=\"highlight python\"><figcaption><span>线性网络类定义</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LinearNet</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, n_feature</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(LinearNet, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.linear = nn.Linear(n_feature, <span class=\"number\">1</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># forward 定义前向传播</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        y = <span class=\"variable language_\">self</span>.linear(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> y</span><br><span class=\"line\"></span><br><span class=\"line\">net = LinearNet(num_inputs)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net) <span class=\"comment\"># 使用print可以打印出网络的结构</span></span><br></pre></td></tr></table></figure>\n<div class=\"note warning no-icon\">\n<p><code>torch.nn</code>  仅支持输入一个 batch 的样本，不支持单个样本输入。如果只有单个样本，可使用 <code>input.unsqueeze(0)</code>  来添加一维。</p>\n</div>\n<h2 id=\"方式二使用nnsequential\"><a class=\"anchor\" href=\"#方式二使用nnsequential\">#</a> 方式二：使用 nn.Sequential</h2>\n<p><code>nn.Sequential</code>  提供了一种更简洁的方式来构建顺序网络。</p>\n<figure class=\"highlight python\"><figcaption><span>Sequential网络构建的三种写法</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 写法一</span></span><br><span class=\"line\">net = nn.Sequential(</span><br><span class=\"line\">    nn.Linear(num_inputs, <span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 此处还可以传入其他层</span></span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 写法二</span></span><br><span class=\"line\">net = nn.Sequential()</span><br><span class=\"line\">net.add_module(<span class=\"string\">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class=\"number\">1</span>))</span><br><span class=\"line\"><span class=\"comment\"># net.add_module ......</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 写法三</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> collections <span class=\"keyword\">import</span> OrderedDict</span><br><span class=\"line\">net = nn.Sequential(OrderedDict([</span><br><span class=\"line\">          (<span class=\"string\">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class=\"number\">1</span>))</span><br><span class=\"line\">          <span class=\"comment\"># ......</span></span><br><span class=\"line\">        ]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(net)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(net[<span class=\"number\">0</span>])</span><br></pre></td></tr></table></figure>\n<h1 id=\"参数初始化\"><a class=\"anchor\" href=\"#参数初始化\">#</a> 参数初始化</h1>\n<p>神经网络的参数初始化对训练效果有重要影响。PyTorch 提供了多种初始化方法。</p>\n<figure class=\"highlight python\"><figcaption><span>参数初始化方法</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.nn <span class=\"keyword\">import</span> init</span><br><span class=\"line\"></span><br><span class=\"line\">init.normal_(net[<span class=\"number\">0</span>].weight, mean=<span class=\"number\">0</span>, std=<span class=\"number\">0.01</span>)</span><br><span class=\"line\">init.constant_(net[<span class=\"number\">0</span>].bias, val=<span class=\"number\">0</span>)  <span class=\"comment\"># 也可以直接修改bias的data: net[0].bias.data.fill_(0)</span></span><br></pre></td></tr></table></figure>\n<details class=\"info\"><summary>常用初始化方法</summary><div>\n<p>PyTorch 的 <code>torch.nn.init</code>  模块提供了多种参数初始化方法：</p>\n<ul>\n<li><code>normal_()</code> : 正态分布初始化</li>\n<li><code>uniform_()</code> : 均匀分布初始化</li>\n<li><code>constant_()</code> : 常数初始化</li>\n<li><code>xavier_uniform_()</code> : Xavier 均匀分布初始化</li>\n<li><code>kaiming_normal_()</code> : Kaiming 正态分布初始化</li>\n</ul>\n<p>选择合适的初始化方法可以避免梯度消失或梯度爆炸问题，加速网络收敛。</p>\n</div></details>\n<h1 id=\"损失函数定义\"><a class=\"anchor\" href=\"#损失函数定义\">#</a> 损失函数定义</h1>\n<p>损失函数用于衡量模型预测值与真实值之间的差异。</p>\n<figure class=\"highlight python\"><figcaption><span>均方误差损失函数</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss = nn.MSELoss()</span><br></pre></td></tr></table></figure>\n<h1 id=\"优化器配置\"><a class=\"anchor\" href=\"#优化器配置\">#</a> 优化器配置</h1>\n<p>优化器负责根据梯度更新模型参数。PyTorch 提供了多种优化算法。</p>\n<h2 id=\"基本优化器设置\"><a class=\"anchor\" href=\"#基本优化器设置\">#</a> 基本优化器设置</h2>\n<figure class=\"highlight python\"><figcaption><span>SGD优化器配置</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.optim <span class=\"keyword\">as</span> optim</span><br><span class=\"line\"></span><br><span class=\"line\">optimizer = optim.SGD(net.parameters(), lr=<span class=\"number\">0.03</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(optimizer)</span><br></pre></td></tr></table></figure>\n<h2 id=\"不同参数组的学习率设置\"><a class=\"anchor\" href=\"#不同参数组的学习率设置\">#</a> 不同参数组的学习率设置</h2>\n<figure class=\"highlight python\"><figcaption><span>分组学习率设置</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">optimizer = optim.SGD([</span><br><span class=\"line\">        <span class=\"comment\"># 如果对某个参数不指定学习率，就使用最外层的默认学习率</span></span><br><span class=\"line\">        &#123;<span class=\"string\">&#x27;params&#x27;</span>: net.subnet1.parameters()&#125;, <span class=\"comment\"># lr=0.03</span></span><br><span class=\"line\">        &#123;<span class=\"string\">&#x27;params&#x27;</span>: net.subnet2.parameters(), <span class=\"string\">&#x27;lr&#x27;</span>: <span class=\"number\">0.01</span>&#125;</span><br><span class=\"line\">      ], lr=<span class=\"number\">0.03</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"动态调整学习率\"><a class=\"anchor\" href=\"#动态调整学习率\">#</a> 动态调整学习率</h2>\n<figure class=\"highlight python\"><figcaption><span>学习率调整</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 调整学习率</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> param_group <span class=\"keyword\">in</span> optimizer.param_groups:</span><br><span class=\"line\">    param_group[<span class=\"string\">&#x27;lr&#x27;</span>] *= <span class=\"number\">0.1</span> <span class=\"comment\"># 学习率为之前的0.1倍</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"模型训练流程\"><a class=\"anchor\" href=\"#模型训练流程\">#</a> 模型训练流程</h1>\n<p>完整的训练流程包括前向传播、损失计算、反向传播和参数更新四个步骤。</p>\n<figure class=\"highlight python\"><figcaption><span>完整训练循环</span><span class=\"exturl\" data-url=\"aHR0cHM6Ly90YW5nc2h1c2VuLm1lL0RpdmUtaW50by1ETC1QeVRvcmNoLw==\">参考链接</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_epochs = <span class=\"number\">3</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>, num_epochs + <span class=\"number\">1</span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> X, y <span class=\"keyword\">in</span> data_iter:</span><br><span class=\"line\">        output = net(X)</span><br><span class=\"line\">        l = loss(output, y.view(-<span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">        optimizer.zero_grad() <span class=\"comment\"># 梯度清零，等价于net.zero_grad()</span></span><br><span class=\"line\">        l.backward()</span><br><span class=\"line\">        optimizer.step()</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;epoch %d, loss: %f&#x27;</span> % (epoch, l.item()))</span><br></pre></td></tr></table></figure>\n<h1 id=\"关键注意事项\"><a class=\"anchor\" href=\"#关键注意事项\">#</a> 关键注意事项</h1>\n<h2 id=\"计算图管理\"><a class=\"anchor\" href=\"#计算图管理\">#</a> 计算图管理</h2>\n<div class=\"note danger no-icon\">\n<p>对赋值操作，要么使用 <code>.data</code>  要么用 <code>with torch.no_grad():</code> ，否则会被加入计算图中，影响内存使用和计算效率。</p>\n</div>\n<details class=\"info\"><summary>计算图的影响</summary><div>\n<p>PyTorch 采用动态计算图机制，所有参与梯度计算的张量操作都会被记录在计算图中。如果直接对参数进行赋值操作而不使用 <code>.data</code>  或 <code>torch.no_grad()</code> ，这些操作也会被记录，导致：</p>\n<ol>\n<li>不必要的内存消耗</li>\n<li>计算图变得复杂</li>\n<li>可能影响梯度计算的正确性</li>\n</ol>\n<p><strong>正确做法：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 方法一：使用.data</span></span><br><span class=\"line\">param.data = new_value</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方法二：使用torch.no_grad()</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    param.copy_(new_value)</span><br></pre></td></tr></table></figure>\n</div></details>\n<h2 id=\"梯度累积问题\"><a class=\"anchor\" href=\"#梯度累积问题\">#</a> 梯度累积问题</h2>\n<div class=\"note warning no-icon\">\n<p>每次完整修改一次参数，记得要梯度清零 <code>w.grad.data.zero_()</code> ，否则梯度会累积。</p>\n</div>\n<details class=\"info\"><summary>梯度累积的原因与解决</summary><div>\n<p>在 PyTorch 中，调用 <code>loss.backward()</code>  时，梯度会累加到参数的 <code>.grad</code>  属性中，而不是替换。这种设计是为了支持梯度累积等高级用法。</p>\n<p><strong>问题：</strong> 如果不清零梯度，多次迭代的梯度会累积，导致参数更新方向错误。</p>\n<p><strong>解决方案：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 方法一：使用优化器清零（推荐）</span></span><br><span class=\"line\">optimizer.zero_grad()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 方法二：手动清零</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> net.parameters():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> param.grad <span class=\"keyword\">is</span> <span class=\"keyword\">not</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        param.grad.data.zero_()</span><br></pre></td></tr></table></figure>\n</div></details>\n<hr />\n",
            "tags": [
                "学习笔记",
                "代码实现",
                "PyTorch",
                "神经网络",
                "梯度下降",
                "损失函数",
                "优化器",
                "数据加载器",
                "参数初始化",
                "SGD",
                "深度学习"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A2163-%E5%88%A0%E9%99%A4%E5%85%83%E7%B4%A0%E5%90%8E%E5%92%8C%E7%9A%84%E6%9C%80%E5%B0%8F%E5%B7%AE%E5%80%BC/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A2163-%E5%88%A0%E9%99%A4%E5%85%83%E7%B4%A0%E5%90%8E%E5%92%8C%E7%9A%84%E6%9C%80%E5%B0%8F%E5%B7%AE%E5%80%BC/",
            "title": "力扣每日一题：2163. 删除元素后和的最小差值",
            "date_published": "2025-07-18T04:19:15.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9taW5pbXVtLWRpZmZlcmVuY2UtaW4tc3Vtcy1hZnRlci1yZW1vdmFsLW9mLWVsZW1lbnRzP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMTg=\">LeetCode 2163</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个下标从 0 开始的整数数组  <code>nums</code>  ，它包含  <code>3 * n</code>  个元素。</p>\n<p>你可以从  <code>nums</code>  中删除 恰好  <code>n</code>  个元素，剩下的  <code>2 * n</code>  个元素将会被分成两个 相同大小 的部分。</p>\n<pre><code>前面 `n` 个元素属于第一部分，它们的和记为 `sumfirst` 。\n后面 `n` 个元素属于第二部分，它们的和记为 `sumsecond` 。\n</code></pre>\n<p>两部分和的 差值 记为  <code>sumfirst - sumsecond</code>  。</p>\n<pre><code>比方说，`sumfirst = 3` 且 `sumsecond = 2` ，它们的差值为 `1` 。\n再比方，`sumfirst = 2` 且 `sumsecond = 3` ，它们的差值为 `-1` 。\n</code></pre>\n<p>请你返回删除  <code>n</code>  个元素之后，剩下两部分和的 差值的最小值 是多少。</p>\n<div class=\"note info no-icon\">\n<ul>\n<li>nums.length == 3 * n</li>\n<li>1 &lt;= n &lt;= 10^5</li>\n<li>1 &lt;= nums[i] &lt;= 10^5</li>\n</ul>\n</div>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>首先很容易想到，前  <code>n</code>  个元素如果留下来，那么前  <code>n</code>  个留下来的元素就只能属于第一部分，后  <code>n</code>  个留下来的元素只能属于第二部分。因此要区分两部分，就只能在中间  <code>n</code>  个元素里取分割点。<br />\n由于两部分都必须是  <code>n</code>  个元素，因此我们可以将问题转换为在中间  <code>n</code>  个元素的  <code>n+1</code>  个分割点中选择一个，使其分成两部分。并求前一部分的  <code>n</code>  个最小元素和后面  <code>n</code>  个最大元素的和的差值。遍历所有可能的分割点，计算出最小差值。<br />\n为此，我们通过使用前缀和和后缀和来维护分割点的和。具体步骤如下：</p>\n<ol>\n<li>计算前  <code>n</code>  个元素的前缀和  <code>pre</code> ，以及后  <code>n</code>  个元素的后缀和  <code>suf</code> 。</li>\n<li>使用最大堆维护前  <code>n</code>  个元素的最小和，使用最小堆维护后  <code>n</code>  个元素的最大和。</li>\n<li>使用堆来计算出  <code>pre</code>  和  <code>suf</code>  的值。</li>\n<li>遍历所有可能的分割点，计算出最小差值。</li>\n</ol>\n<div class=\"note info no-icon\">\n<p>最大和值为 10^10，因此可以使用  <code>long long</code>  类型来存储和。</p>\n</div>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">long</span> <span class=\"type\">long</span> <span class=\"title\">minimumDifference</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = nums.<span class=\"built_in\">size</span>() / <span class=\"number\">3</span>;</span><br><span class=\"line\">        <span class=\"function\">vector&lt;<span class=\"type\">long</span> <span class=\"type\">long</span>&gt; <span class=\"title\">pre</span><span class=\"params\">(n<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span>, <span class=\"title\">suf</span><span class=\"params\">(n<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\">        <span class=\"type\">long</span> <span class=\"type\">long</span> pre_sum = <span class=\"number\">0</span>, suf_sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">        priority_queue&lt;<span class=\"type\">int</span>&gt; pre_max;</span><br><span class=\"line\">        priority_queue&lt;<span class=\"type\">int</span>, vector&lt;<span class=\"type\">int</span>&gt;, greater&lt;<span class=\"type\">int</span>&gt;&gt; suf_min;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            pre_sum += nums[i];</span><br><span class=\"line\">            pre_max.<span class=\"built_in\">push</span>(nums[i]);</span><br><span class=\"line\">            suf_sum += nums[<span class=\"number\">2</span>*n+i];</span><br><span class=\"line\">            suf_min.<span class=\"built_in\">push</span>(nums[<span class=\"number\">2</span>*n+i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        pre[<span class=\"number\">0</span>] = pre_sum;</span><br><span class=\"line\">        suf[n] = suf_sum;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            pre[i<span class=\"number\">+1</span>] = pre[i] + nums[n+i];</span><br><span class=\"line\">            pre_max.<span class=\"built_in\">push</span>(nums[n+i]);</span><br><span class=\"line\">            pre[i<span class=\"number\">+1</span>] -= pre_max.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">            pre_max.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            suf[n<span class=\"number\">-1</span>-i] = suf[n-i] + nums[<span class=\"number\">2</span>*n<span class=\"number\">-1</span>-i];</span><br><span class=\"line\">            suf_min.<span class=\"built_in\">push</span>(nums[<span class=\"number\">2</span>*n<span class=\"number\">-1</span>-i]);</span><br><span class=\"line\">            suf[n<span class=\"number\">-1</span>-i] -= suf_min.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">            suf_min.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"type\">long</span> <span class=\"type\">long</span> ans = pre[<span class=\"number\">0</span>]-suf[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++)&#123;</span><br><span class=\"line\">            ans = <span class=\"built_in\">min</span>(pre[i]-suf[i], ans);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 化简优化一点的写法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">long</span> <span class=\"type\">long</span> <span class=\"title\">minimumDifference</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = nums.<span class=\"built_in\">size</span>() / <span class=\"number\">3</span>;</span><br><span class=\"line\">        <span class=\"function\">vector&lt;<span class=\"type\">long</span> <span class=\"type\">long</span>&gt; <span class=\"title\">pre</span><span class=\"params\">(n<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span>, <span class=\"title\">suf</span><span class=\"params\">(n<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\">        <span class=\"type\">long</span> <span class=\"type\">long</span> pre_sum = <span class=\"number\">0</span>, suf_sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"function\">priority_queue&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">pre_max</span><span class=\"params\">(nums.begin(), nums.begin()+n)</span></span>;</span><br><span class=\"line\">        priority_queue&lt;<span class=\"type\">int</span>, vector&lt;<span class=\"type\">int</span>&gt;, greater&lt;<span class=\"type\">int</span>&gt;&gt; <span class=\"built_in\">suf_min</span>(nums.<span class=\"built_in\">end</span>()-n, nums.<span class=\"built_in\">end</span>());</span><br><span class=\"line\">        pre_sum = <span class=\"built_in\">reduce</span>(nums.<span class=\"built_in\">begin</span>(), nums.<span class=\"built_in\">begin</span>()+n, <span class=\"number\">0ll</span>);</span><br><span class=\"line\">        suf_sum = <span class=\"built_in\">reduce</span>(nums.<span class=\"built_in\">end</span>()-n, nums.<span class=\"built_in\">end</span>(), <span class=\"number\">0ll</span>);</span><br><span class=\"line\">        pre[<span class=\"number\">0</span>] = pre_sum;</span><br><span class=\"line\">        suf[n] = suf_sum;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            pre[i<span class=\"number\">+1</span>] = pre[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (pre_max.<span class=\"built_in\">top</span>() &gt; nums[n+i])&#123;</span><br><span class=\"line\">                pre[i<span class=\"number\">+1</span>] += nums[n+i];</span><br><span class=\"line\">                pre_max.<span class=\"built_in\">push</span>(nums[n+i]);</span><br><span class=\"line\">                pre[i<span class=\"number\">+1</span>] -= pre_max.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">                pre_max.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            suf[n<span class=\"number\">-1</span>-i] = suf[n-i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (suf_min.<span class=\"built_in\">top</span>() &lt; nums[<span class=\"number\">2</span>*n<span class=\"number\">-1</span>-i])&#123;</span><br><span class=\"line\">                suf[n<span class=\"number\">-1</span>-i] += nums[<span class=\"number\">2</span>*n<span class=\"number\">-1</span>-i];</span><br><span class=\"line\">                suf_min.<span class=\"built_in\">push</span>(nums[<span class=\"number\">2</span>*n<span class=\"number\">-1</span>-i]);</span><br><span class=\"line\">                suf[n<span class=\"number\">-1</span>-i] -= suf_min.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">                suf_min.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"type\">long</span> <span class=\"type\">long</span> ans = pre[<span class=\"number\">0</span>]-suf[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i++)&#123;</span><br><span class=\"line\">            ans = <span class=\"built_in\">min</span>(pre[i]-suf[i], ans);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "堆",
                "动态规划",
                "优先队列",
                "前缀和",
                "后缀和"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3202-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-II/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3202-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-II/",
            "title": "力扣每日一题：3202. 找出有效子序列的最大长度 II",
            "date_published": "2025-07-17T04:52:35.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9maW5kLXRoZS1tYXhpbXVtLWxlbmd0aC1vZi12YWxpZC1zdWJzZXF1ZW5jZS1paT9lbnZUeXBlPWRhaWx5LXF1ZXN0aW9uJmFtcDtlbnZJZD0yMDI1LTA3LTE3\">LeetCode 3201</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个整数数组  <code>nums</code>  和一个 正 整数  <code>k</code>  。</p>\n<p><code>nums</code>  的一个 子序列  <code>sub</code>  的长度为  <code>x</code>  ，如果其满足以下条件，则称其为 有效子序列 ：</p>\n<pre><code>(sub[0] + sub[1]) % k == (sub[1] + sub[2]) % k == ... == (sub[x - 2] + sub[x - 1]) % k\n</code></pre>\n<p>返回  <code>nums</code>  的 最长有效子序列 的长度。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>思路一：<br />\n我们可以使用动态规划来解决这个问题。首先由于我们需要计算的数字都是小于  <code>k</code>  的，因此可以对于每一个  <code>nums[i]</code>  都先 % k ，接着我们可以使用一个二维数组  <code>dp</code>  来记录状态。<br />\n设  <code>dp[i][j]</code>  表示以  <code>i</code>  结尾，且最后一个数字的余数为  <code>j</code>  的最长有效子序列的长度。<br />\n我们可以遍历  <code>nums</code>  数组，对于每一个  <code>nums[i]</code> ，我们可以遍历之前的所有状态  <code>j</code> ，如果  <code>vis[j]</code>  为真，即前一个数存在，则我们可以更新  <code>dp[nums[i]][(j + nums[i]) % k]</code>  为  <code>dp[j][(j + nums[i]) % k] + 1</code> ，<br />\n最后我们只需要返回  <code>ans + 1</code>  即可。</p>\n<p>思路二：<br />\n由于是在  <code>k</code>  取模的情况下，我们可以选择遍历  <code>k</code>  个状态。对于每一个余数状态，我们可以使用一个一维数组  <code>dp</code>  来记录状态， <code>dp[j]</code>  表示最后一个数字为  <code>j</code>  的最长有效子序列的长度。<br />\n然后遍历  <code>nums</code>  数组，对于每一个  <code>nums[j]</code> ，我们可以更新  <code>dp[nums[j] % k]</code>  为  <code>dp[(i - nums[j]%k + k)%k] + 1</code> 。即找余数为  <code>i</code>  时，当前数为  <code>nums[j]</code>  时，前一个数为多少，由于余数固定，所以前一个数也固定，也不用担心选中的序列中会出现第三种数。<br />\n最后取  <code>k</code>  个状态下，所有  <code>dp[j]</code>  的最大值即可。</p>\n<div class=\"note warning no-icon\">\n<p>注意每个状态 dp 清零。</p>\n</div>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<div class=\"note info no-icon\">\n<p>这里只提供思路一的代码。思路二是我通过看 leetcode 执行速度最快的代码时分析出来的。</p>\n</div>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法1</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maximumLength</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt;&amp; nums, <span class=\"type\">int</span> k)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = nums.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        vector&lt;vector&lt;<span class=\"type\">int</span>&gt;&gt; <span class=\"built_in\">dp</span>(k, <span class=\"built_in\">vector</span>&lt;<span class=\"type\">int</span>&gt;(k,<span class=\"number\">0</span>));</span><br><span class=\"line\">        <span class=\"function\">vector&lt;<span class=\"type\">bool</span>&gt; <span class=\"title\">vis</span><span class=\"params\">(k<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            nums[i] %= k;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt; k; j++)&#123;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!vis[j]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">                <span class=\"type\">int</span> cur = (j + nums[i])%k;</span><br><span class=\"line\">                dp[nums[i]][cur] = dp[j][cur] + <span class=\"number\">1</span>;</span><br><span class=\"line\">                ans = <span class=\"built_in\">max</span>(ans,dp[nums[i]][cur]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            vis[nums[i]] = <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "动态规划"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3201-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-I/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3201-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-I/",
            "title": "力扣每日一题：3201. 找出有效子序列的最大长度 I",
            "date_published": "2025-07-16T03:40:13.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9maW5kLXRoZS1tYXhpbXVtLWxlbmd0aC1vZi12YWxpZC1zdWJzZXF1ZW5jZS1pP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMTY=\">LeetCode 3201</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个整数数组  <code>nums</code> 。</p>\n<p><code>nums</code>  的子序列  <code>sub</code>  的长度为  <code>x</code>  ，如果其满足以下条件，则称其为 有效子序列：</p>\n<pre><code>`(sub[0] + sub[1]) % 2 == (sub[1] + sub[2]) % 2 == ... == (sub[x - 2] + sub[x - 1]) % 2`\n</code></pre>\n<p>返回  <code>nums</code>  的 最长的有效子序列 的长度。</p>\n<p>一个 子序列 指的是从原数组中删除一些元素（也可以不删除任何元素），剩余元素保持原来顺序组成的新数组。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>这道题满足的有效子序列一共三种情况</p>\n<ol>\n<li>全部为偶数</li>\n<li>全部为奇数</li>\n<li>奇偶交替</li>\n</ol>\n<h2 id=\"对于前两种情况的最长有效子序列可以直接统计偶数和奇数的数量-而第三种情况我们则可以从开始贪心地选择奇偶交替的元素-对于选择奇偶交替的过程下一个元素不能选则说明有多个奇偶性相同的元素被放在了一起因此我们可以将原数组看作是如果相邻元素的奇偶性相同则可以将其合并为一个元素-然后我们就会得到一个奇偶性交替的序列-显然的此时选择数组中的每一个元素才是最长的而对于消除掉的元素即使加回来也不会影响这种情况的最长长度-最后返回几种情况的最大值即可\"><a class=\"anchor\" href=\"#对于前两种情况的最长有效子序列可以直接统计偶数和奇数的数量-而第三种情况我们则可以从开始贪心地选择奇偶交替的元素-对于选择奇偶交替的过程下一个元素不能选则说明有多个奇偶性相同的元素被放在了一起因此我们可以将原数组看作是如果相邻元素的奇偶性相同则可以将其合并为一个元素-然后我们就会得到一个奇偶性交替的序列-显然的此时选择数组中的每一个元素才是最长的而对于消除掉的元素即使加回来也不会影响这种情况的最长长度-最后返回几种情况的最大值即可\">#</a> 对于前两种情况的最长有效子序列，可以直接统计偶数和奇数的数量。而第三种情况，我们则可以从开始，贪心地选择奇偶交替的元素。<br />\n对于选择奇偶交替的过程，下一个元素不能选，则说明有多个奇偶性相同的元素被放在了一起，因此我们可以将原数组看作是，如果相邻元素的奇偶性相同，则可以将其合并为一个元素。然后我们就会得到一个奇偶性交替的序列。显然的，此时选择数组中的每一个元素才是最长的，而对于消除掉的元素，即使加回来也不会影响这种情况的最长长度。<br />\n最后返回几种情况的最大值即可。</h2>\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maximumLength</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> cnt_e = <span class=\"number\">0</span>, cnt_o = <span class=\"number\">0</span>, cnt_cross = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = nums.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (nums[<span class=\"number\">0</span>] % <span class=\"number\">2</span>) cnt_o++;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> cnt_e++;</span><br><span class=\"line\">        cnt_cross++;</span><br><span class=\"line\">        <span class=\"type\">int</span> tmp = nums[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (nums[i] &amp; <span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">                cnt_o++;</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                cnt_e++;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> ((nums[i] + tmp) &amp; <span class=\"number\">1</span>)&#123;</span><br><span class=\"line\">                cnt_cross++;</span><br><span class=\"line\">                tmp = nums[i];</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">max</span>(cnt_cross,<span class=\"built_in\">max</span>(cnt_e, cnt_o));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "贪心"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/Transformer/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/Transformer/",
            "title": "Transformer",
            "date_published": "2025-07-15T13:33:51.000Z",
            "content_html": "<h1 id=\"transformer-架构概述\"><a class=\"anchor\" href=\"#transformer-架构概述\">#</a> Transformer 架构概述</h1>\n<p>Transformer 是一种基于注意力机制的神经网络架构，由 Google 在 2017 年的论文 &quot;Attention Is All You Need&quot; 中提出。它彻底改变了序列到序列任务的处理方式，成为现代自然语言处理的基础架构。</p>\n<div style=\"text-align: center;\">\n  <img data-src=\"/assets/transformer.png\" alt=\"Transformer架构图\" style=\"max-width: 50%; height: auto;\">\n</div>\n<details class=\"info\"><summary>Seq2Seq 序列到序列模型</summary><div>\n<p>Seq2Seq（Sequence-to-Sequence）是一种神经网络架构模式，用于处理输入序列到输出序列的映射任务。它由编码器（Encoder）和解码器（Decoder）两部分组成，编码器将输入序列编码为固定长度的向量表示，解码器基于这个表示生成目标序列。典型应用包括机器翻译、文本摘要、对话系统等。QA（问答）系统也可以使用 Seq2Seq 架构，将问题作为输入序列，答案作为输出序列。</p>\n</div></details>\n<h1 id=\"编码器架构-encoder\"><a class=\"anchor\" href=\"#编码器架构-encoder\">#</a> 编码器架构 (Encoder)</h1>\n<p>编码器负责将输入序列转换为一组向量表示。在 Transformer 中，编码器可以使用不同的技术实现，如 RNN、CNN，但 Transformer 采用的是自注意力机制（Self-Attention）。</p>\n<h2 id=\"多层块结构\"><a class=\"anchor\" href=\"#多层块结构\">#</a> 多层块结构</h2>\n<p>编码器由 N 个相同的块（Block）组成。每个块包含以下组件：</p>\n<ol>\n<li><strong>多头自注意力层</strong>（Multi-Head Self-Attention）</li>\n<li><strong>前馈神经网络</strong>（Feed Forward Network）</li>\n<li><strong>残差连接</strong>（Residual Connection）</li>\n<li><strong>层归一化</strong>（Layer Normalization）</li>\n</ol>\n<h3 id=\"多头自注意力机制\"><a class=\"anchor\" href=\"#多头自注意力机制\">#</a> 多头自注意力机制</h3>\n<p>多头自注意力是 Transformer 的核心组件，它允许模型同时关注不同位置的信息。</p>\n<p><strong>基础注意力计算：</strong></p>\n<p>对于输入序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span></span></span></span>，首先通过线性变换得到查询（Query）、键（Key）和值（Value）矩阵：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>X</mi><msup><mi>W</mi><mi>Q</mi></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi>K</mi><mo>=</mo><mi>X</mi><msup><mi>W</mi><mi>K</mi></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi>V</mi><mo>=</mo><mi>X</mi><msup><mi>W</mi><mi>V</mi></msup></mrow><annotation encoding=\"application/x-tex\">Q = XW^Q, \\quad K = XW^K, \\quad V = XW^V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.085771em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.891331em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0857709999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8913309999999999em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>缩放点积注意力：</strong></p>\n<p>由于点积操作可能产生很大的值（特别是当维度 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 较大时），需要进行缩放以避免 softmax 函数进入饱和区域：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence=\"true\">)</mo></mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.468361em;vertical-align:-0.95003em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5183309999999999em;\"><span style=\"top:-2.25278em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<div class=\"note info no-icon\">\n<p>缩放因子 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>1</mn><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{\\sqrt{d_k}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.538em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.5864385em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8622307142857143em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8222307142857144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17776928571428574em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> 是关键设计，它防止了点积值过大导致的梯度消失问题。</p>\n</div>\n<p><strong>多头机制：</strong></p>\n<p>多头注意力并行运行 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span> 个注意力头，每个头学习不同的表示子空间：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>Concat</mtext><mo stretchy=\"false\">(</mo><msub><mtext>head</mtext><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mtext>head</mtext><mi>h</mi></msub><mo stretchy=\"false\">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">MultiHead</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Concat</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中每个注意力头计算为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mtext>head</mtext><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator=\"true\">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator=\"true\">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.236103em;vertical-align:-0.276864em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9592389999999998em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.180908em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<details class=\"info\"><summary>维度缩放的必要性</summary><div>\n<p>当键向量的维度 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 很大时，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">QK^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span> 的值会变得很大，这会使 softmax 函数的梯度变得很小，导致训练困难。通过除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.18278000000000005em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span></span> 进行缩放，可以将点积的方差控制在合理范围内。假设 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 的元素是均值为 0、方差为 1 的独立随机变量，那么 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">QK^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span> 的方差为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.18278000000000005em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span></span> 后方差变为 1。</p>\n</div></details>\n<details class=\"info\"><summary>残差连接 (Residual Connection)</summary><div>\n<p>残差连接是一种网络设计技巧，通过将层的输入直接加到其输出上来缓解深度网络的梯度消失问题。在 Transformer 中，残差连接的公式为：输出 = LayerNorm (x + SubLayer (x))，其中 x 是输入，SubLayer (x) 是子层（如注意力层或前馈层）的输出。这种设计使得网络可以更深，训练更稳定。</p>\n</div></details>\n<details class=\"info\"><summary>层归一化 (Layer Normalization)</summary><div>\n<p>层归一化是一种正则化技术，对每个样本的特征维度进行归一化。计算公式为：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>x</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo>=</mo><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">x&#x27;_i = \\frac{x_i - \\mu}{\\sigma}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.010556em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-2.441336em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.199439em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.854439em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">σ</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">μ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> 是均值，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> 是标准差。与批归一化不同，层归一化在每个样本内部进行归一化，不依赖于批次大小，特别适合处理序列数据。</p>\n</div></details>\n<h2 id=\"位置编码\"><a class=\"anchor\" href=\"#位置编码\">#</a> 位置编码</h2>\n<p>由于自注意力机制本身不包含位置信息，编码器输入时需要加上位置编码（Positional Encoding），为每个位置的词向量添加位置信息。</p>\n<div class=\"note info no-icon\">\n<p>编码器的输入 = 词嵌入 + 位置编码</p>\n</div>\n<details class=\"info\"><summary>前馈神经网络 (Feed Forward)</summary><div>\n<p>前馈神经网络是 Transformer 块中的第二个主要组件。它是一个简单的两层全连接网络，在第一层后使用 ReLU 激活函数。数学表示为：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">FFN(x) = \\max(0, xW_1 + b_1)W_2 + b_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，其中第一层进行线性变换并应用 ReLU，第二层再进行线性变换输出最终结果。这个网络对序列中的每个位置独立进行相同的变换，提供非线性变换能力。</p>\n</div></details>\n<h1 id=\"解码器架构-decoder\"><a class=\"anchor\" href=\"#解码器架构-decoder\">#</a> 解码器架构 (Decoder)</h1>\n<p>解码器负责基于编码器的输出生成目标序列。Transformer 支持两种主要的解码方式：</p>\n<h2 id=\"自回归解码-auto-regressive\"><a class=\"anchor\" href=\"#自回归解码-auto-regressive\">#</a> 自回归解码 (Auto-Regressive)</h2>\n<p>自回归解码采用逐步生成的方式：</p>\n<ol>\n<li>从特殊标记 BOS（Begin of Sequence）开始</li>\n<li>通过 Softmax 层输出词汇表大小的概率分布</li>\n<li>选择概率最高的词作为输出</li>\n<li>将输出作为下一步的输入，重复此过程</li>\n<li>当输出 END 标记时停止生成</li>\n</ol>\n<h3 id=\"掩码自注意力\"><a class=\"anchor\" href=\"#掩码自注意力\">#</a> 掩码自注意力</h3>\n<p>在自回归解码中使用掩码自注意力（Masked Self-Attention），确保位置 i 只能关注位置 1 到 i 的信息，不能看到未来的信息。</p>\n<details class=\"info\"><summary>Teacher Forcing 教师强制</summary><div>\n<p>Teacher Forcing 是训练序列生成模型的一种技术。在训练阶段，不使用模型前一步的预测输出作为当前步的输入，而是直接使用正确答案（Ground Truth）作为输入。这样可以加速训练过程，避免错误累积。但在推理阶段仍需要使用模型自己的输出，这种训练和推理的差异被称为 Exposure Bias。</p>\n</div></details>\n<h2 id=\"非自回归解码-non-auto-regressive-nat\"><a class=\"anchor\" href=\"#非自回归解码-non-auto-regressive-nat\">#</a> 非自回归解码 (Non-Auto-Regressive, NAT)</h2>\n<p>非自回归解码同时输出所有位置的结果：</p>\n<ol>\n<li>输入多个 BEGIN 标记</li>\n<li>并行生成所有输出位置</li>\n<li>不需要逐步迭代</li>\n</ol>\n<details class=\"info\"><summary>Ground Truth 真实标签</summary><div>\n<p>Ground Truth 指的是数据集中的正确答案或标准答案。在机器学习中，模型的预测结果会与 Ground Truth 进行比较来计算损失函数。在序列生成任务中，Ground Truth 是目标序列的正确内容，用于训练过程中的监督学习和模型评估。</p>\n</div></details>\n<h1 id=\"交叉注意力机制-cross-attention\"><a class=\"anchor\" href=\"#交叉注意力机制-cross-attention\">#</a> 交叉注意力机制 (Cross-Attention)</h1>\n<p>交叉注意力是连接编码器和解码器的关键机制：</p>\n<ol>\n<li>解码器通过掩码自注意力处理 BEGIN 标记，得到查询向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Q</mi></mrow><annotation encoding=\"application/x-tex\">Q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span></span></span></span></li>\n<li>编码器输出 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>a</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi></mrow><annotation encoding=\"application/x-tex\">a_1, a_2, a_3, ...</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span></span></span></span> 通过线性变换得到键向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>k</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>k</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">K = [k_1, k_2, k_3, ...]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mclose\">]</span></span></span></span> 和值向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><msub><mi>v</mi><mn>3</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">V = [v_1, v_2, v_3, ...]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>计算注意力权重：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Attention_Weights</mtext><mo>=</mo><mtext>softmax</mtext><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\text{Attention\\_Weights} = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.00444em;vertical-align:-0.31em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention_Weights</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.80002em;vertical-align:-0.65002em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.089473em;\"><span style=\"top:-2.5864385em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8622307142857143em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8222307142857144em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17776928571428574em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">Q</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9190928571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></li>\n<li>加权求和：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Output</mtext><mo>=</mo><mtext>Attention_Weights</mtext><mo>⋅</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">\\text{Output} = \\text{Attention\\_Weights} \\cdot V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">Output</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00444em;vertical-align:-0.31em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention_Weights</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></li>\n<li>将结果送入前馈网络处理</li>\n</ol>\n<div class=\"note info no-icon\">\n<p>交叉注意力使解码器能够关注编码器的所有位置，实现输入序列信息的有效传递。同样使用缩放点积注意力机制以保持数值稳定性。</p>\n</div>\n<details class=\"info\"><summary>Copy Mechanism 复制机制</summary><div>\n<p>复制机制允许模型在生成输出时直接从输入序列中复制词汇，而不仅仅从固定词汇表中选择。这在处理包含专有名词、数字或罕见词汇的任务中特别有用。复制机制通过注意力权重确定从输入的哪个位置复制内容，常用于文本摘要、对话生成等任务。</p>\n</div></details>\n<h1 id=\"训练与优化\"><a class=\"anchor\" href=\"#训练与优化\">#</a> 训练与优化</h1>\n<h2 id=\"损失函数\"><a class=\"anchor\" href=\"#损失函数\">#</a> 损失函数</h2>\n<p>Transformer 使用交叉熵损失函数进行训练：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi mathvariant=\"script\">L</mi><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathcal{L} = -\\sum_{i=1}^{N} y_i \\log(\\hat{y}_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是真实标签，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是模型预测的概率分布。</p>\n<details class=\"info\"><summary>Error Propagation 误差传播</summary><div>\n<p>误差传播是指训练过程中梯度通过网络层向后传播的过程。在深度网络中，梯度可能在传播过程中变得很小（梯度消失）或很大（梯度爆炸）。Transformer 通过残差连接和层归一化来缓解这些问题，确保梯度能够有效地传播到网络的各个层。</p>\n</div></details>\n<h2 id=\"高级训练技巧\"><a class=\"anchor\" href=\"#高级训练技巧\">#</a> 高级训练技巧</h2>\n<details class=\"info\"><summary>Scheduled Sampling 计划采样</summary><div>\n<p>Scheduled Sampling 是解决 Exposure Bias 的一种技术。在训练过程中，不总是使用 Ground Truth 作为输入，而是按照某种策略偶尔使用模型自己的预测结果作为输入。这种 &quot;偶尔给错误样本&quot; 的做法可以让模型更好地适应推理时的情况，提高模型的鲁棒性。</p>\n</div></details>\n<details class=\"info\"><summary>Guided Attention 引导注意力</summary><div>\n<p>Guided Attention 是一种约束注意力分布的技术，通过在损失函数中添加注意力正则项来引导模型学习更合理的注意力模式。这在某些任务中可以提高模型的可解释性和性能，例如确保翻译模型的注意力更多地关注相关的源语言词汇。</p>\n</div></details>\n<h1 id=\"推理与评估\"><a class=\"anchor\" href=\"#推理与评估\">#</a> 推理与评估</h1>\n<h2 id=\"束搜索解码\"><a class=\"anchor\" href=\"#束搜索解码\">#</a> 束搜索解码</h2>\n<details class=\"info\"><summary>Beam Search 束搜索</summary><div>\n<p>Beam Search 是一种启发式搜索算法，用于在解码时寻找更优的输出序列。与贪心搜索不同，束搜索在每一步保持 k 个最优的部分序列（称为束），并从中扩展出新的候选序列。这种方法在计算效率和输出质量之间取得平衡，通常能产生比贪心搜索更好的结果。</p>\n</div></details>\n<h2 id=\"评估指标\"><a class=\"anchor\" href=\"#评估指标\">#</a> 评估指标</h2>\n<details class=\"info\"><summary>BLEU Score 双语评估替补</summary><div>\n<p>BLEU（Bilingual Evaluation Understudy）是评估机器翻译和文本生成质量的标准指标。它通过计算生成文本与参考文本之间的 n-gram 重叠度来评分，分数范围从 0 到 1，越高表示质量越好。BLEU 考虑了精确度和简洁性，但也有局限性，如无法很好地处理同义词替换。</p>\n</div></details>\n<h1 id=\"实现技巧与优化\"><a class=\"anchor\" href=\"#实现技巧与优化\">#</a> 实现技巧与优化</h1>\n<div class=\"note warning no-icon\">\n<p>当传统优化方法无法解决问题时，可以考虑使用强化学习（Reinforcement Learning, RL）进行进一步优化。</p>\n</div>\n<p>Transformer 的成功不仅在于其创新的架构设计，还在于许多精心设计的实现细节和训练技巧。这些 &quot;神秘的小技巧&quot; 往往是模型性能提升的关键因素。</p>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "深度学习",
                "Transformer",
                "注意力机制",
                "多头注意力",
                "序列到序列",
                "编码器解码器",
                "自注意力",
                "交叉注意力",
                "放缩"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3136-%E6%9C%89%E6%95%88%E5%8D%95%E8%AF%8D/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3136-%E6%9C%89%E6%95%88%E5%8D%95%E8%AF%8D/",
            "title": "力扣每日一题：3136. 有效单词",
            "date_published": "2025-07-15T07:35:26.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy92YWxpZC13b3JkP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMTU=\">LeetCode 3136</span> 的题解，记录了解题思路、代码实现及复杂度分析。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>有效单词 需要满足以下几个条件：</p>\n<pre><code>至少 包含 3 个字符。\n由数字 0-9 和英文大小写字母组成。（不必包含所有这类字符。）\n至少 包含一个 元音字母 。\n至少 包含一个 辅音字母 。\n</code></pre>\n<p>给你一个字符串  <code>word</code>  。如果  <code>word</code>  是一个有效单词，则返回  <code>true</code>  ，否则返回  <code>false</code>  。</p>\n<p>注意：<br />\n'a'、'e'、'i'、'o'、'u' 及其大写形式都属于 元音字母 。<br />\n英文中的 辅音字母 是指那些除元音字母之外的字母。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>首先判断长度是否满足要求，如果小于 3 则直接返回 false。接着遍历字符串，检查每个字符是否符合要求，首先看是否是字母或数字，为了方便判断，我们将字母统一转换为小写。然后分别统计元音字母和数字的数量。最后根据统计结果判断是否满足有效单词的条件。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">isValid</span><span class=\"params\">(string word)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> cnt = <span class=\"number\">0</span>, cntn = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (word.<span class=\"built_in\">size</span>() &lt; <span class=\"number\">3</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> c:word)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!<span class=\"built_in\">isalpha</span>(c) &amp;&amp; !<span class=\"built_in\">isdigit</span>(c)) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">            c = <span class=\"built_in\">tolower</span>(c);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (c == <span class=\"string\">&#x27;a&#x27;</span> || c == <span class=\"string\">&#x27;e&#x27;</span> || c == <span class=\"string\">&#x27;i&#x27;</span> || c == <span class=\"string\">&#x27;o&#x27;</span> || c == <span class=\"string\">&#x27;u&#x27;</span>) cnt++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">isdigit</span>(c)) cntn++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (cnt &gt; <span class=\"number\">0</span> &amp;&amp; word.<span class=\"built_in\">size</span>() - cnt - cntn &gt; <span class=\"number\">0</span>) <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "字符串"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B/",
            "title": "自注意力",
            "date_published": "2025-07-14T10:33:49.000Z",
            "content_html": "<h1 id=\"自注意力机制序列建模的革命性突破\"><a class=\"anchor\" href=\"#自注意力机制序列建模的革命性突破\">#</a> 自注意力机制：序列建模的革命性突破</h1>\n<p>自注意力机制是现代深度学习中最重要的创新之一，它彻底改变了序列数据的处理方式。从最初简单的词表示方法到复杂的注意力计算，这一技术路径展现了机器学习领域的巨大进步。</p>\n<h2 id=\"从简单表示到智能编码\"><a class=\"anchor\" href=\"#从简单表示到智能编码\">#</a> 从简单表示到智能编码</h2>\n<h3 id=\"传统词表示的局限性\"><a class=\"anchor\" href=\"#传统词表示的局限性\">#</a> 传统词表示的局限性</h3>\n<p>在自然语言处理的早期阶段，<ins class=\"dot\">one-hot encoding</ins> 是最常用的词表示方法。这种方法简单直观，但存在根本性缺陷：<strong>无法表示词之间的关系</strong>。</p>\n<details class=\"info\"><summary>One-Hot Encoding详解</summary><div>\n<p>One-hot encoding 是一种稀疏的向量表示方法，对于词汇表中的每个词，我们创建一个长度等于词汇表大小的向量。在这个向量中，只有对应该词的位置为 1，其他位置全为 0。</p>\n<p><strong>优点：</strong></p>\n<ul>\n<li>实现简单，易于理解</li>\n<li>每个词都有唯一的表示</li>\n<li>计算复杂度低</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>向量维度等于词汇表大小，通常非常高维</li>\n<li>所有词向量间的距离相等，无法体现语义相似性</li>\n<li>稀疏表示，存储效率低</li>\n<li>无法处理未见过的词（OOV 问题）</li>\n</ul>\n<p>例如，对于词汇表 {猫，狗，汽车}，&quot;猫&quot; 的 one-hot 表示为 [1, 0, 0]，&quot;狗&quot; 为 [0, 1, 0]。尽管 &quot;猫&quot; 和 &quot;狗&quot; 在语义上相关，但它们的向量表示完全正交。</p>\n</div></details>\n<div class=\"note warning no-icon\">\n<p>One-hot encoding 的根本问题在于：所有词之间的距离都相等，&quot;猫&quot; 和 &quot;狗&quot; 的相似度与 &quot;猫&quot; 和 &quot;汽车&quot; 的相似度完全一样，这显然不符合人类的语言直觉。</p>\n</div>\n<p>为了解决这个问题，研究者们开发了<ins class=\"dot\"> word embedding</ins> 技术，它能够将词映射到低维稠密空间中，使得语义相似的词在向量空间中距离更近。</p>\n<details class=\"success\"><summary>Word Embedding深度解析</summary><div>\n<p>Word embedding 是将词汇映射到连续向量空间的技术，其核心思想是 &quot;分布式假设&quot;：在相似上下文中出现的词具有相似的含义。</p>\n<p><strong>主要方法：</strong></p>\n<ol>\n<li>\n<p><strong>Word2Vec</strong>: 包括 CBOW 和 Skip-gram 两种架构</p>\n<ul>\n<li>CBOW：根据上下文预测中心词</li>\n<li>Skip-gram：根据中心词预测上下文</li>\n</ul>\n</li>\n<li>\n<p><strong>GloVe</strong>: 全局向量表示，结合了全局统计信息</p>\n</li>\n<li>\n<p><strong>FastText</strong>: 考虑子词信息，能够处理未见过的词</p>\n</li>\n</ol>\n<p><strong>关键特性：</strong></p>\n<ul>\n<li>向量维度通常为 100-1000，远小于词汇表大小</li>\n<li>语义相似的词在向量空间中距离较近</li>\n<li>支持向量运算：king - man + woman ≈ queen</li>\n<li>能够捕获多种语义关系（同义词、反义词、词性等）</li>\n</ul>\n</div></details>\n<h2 id=\"序列处理的多样化需求\"><a class=\"anchor\" href=\"#序列处理的多样化需求\">#</a> 序列处理的多样化需求</h2>\n<p>在实际应用中，我们面临着各种不同类型的序列数据处理需求。<ins class=\"dot\">输入会是一组向量</ins>，这些向量可以表示：</p>\n<ul>\n<li><strong>文本序列</strong>：句子中的词嵌入向量</li>\n<li><strong>语音信号</strong>：声音的特征向量序列</li>\n<li><strong>图像序列</strong>：视频帧或图像 patch 的特征向量</li>\n</ul>\n<p>根据任务需求的不同，<ins class=\"dot\">输出的可能性</ins>主要分为三类：</p>\n<div class=\"tab\" data-id=\"type1\" data-title=\"序列到序列 (Seq2Seq)\">\n<p><strong>输入输出数量一样</strong></p>\n<ul>\n<li>典型应用：词性标注、命名实体识别</li>\n<li>每个输入位置对应一个输出标签</li>\n<li>模型需要为每个时间步产生预测结果</li>\n</ul>\n</div>\n<div class=\"tab\" data-id=\"type2\" data-title=\"序列到标量 (Seq2Label)\">\n<p><strong>一堆向量输入只需要一个输出</strong></p>\n<ul>\n<li>典型应用：情感分析、文本分类</li>\n<li>整个序列映射到单一的类别或数值</li>\n<li>需要聚合整个序列的信息</li>\n</ul>\n</div>\n<div class=\"tab\" data-id=\"type3\" data-title=\"序列到变长序列 (Seq2VarSeq)\">\n<p><strong>一堆向量输入，不确定输出的数量</strong></p>\n<ul>\n<li>典型应用：机器翻译、文本摘要</li>\n<li>输出长度不固定，由模型决定</li>\n<li>需要学习何时停止生成</li>\n</ul>\n</div>\n<h2 id=\"从局部感知到全局理解\"><a class=\"anchor\" href=\"#从局部感知到全局理解\">#</a> 从局部感知到全局理解</h2>\n<h3 id=\"传统方法的困境\"><a class=\"anchor\" href=\"#传统方法的困境\">#</a> 传统方法的困境</h3>\n<p>在自注意力机制出现之前，处理序列标注任务最常见的方法是<ins class=\"dot\"> sequence labeling</ins>，即开设一个滑动窗口，同时考虑邻近的几个词输入到全连接层中进行预测。</p>\n<figure class=\"highlight python\"><figcaption><span>滑动窗口序列标注示例</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sliding_window_predict</span>(<span class=\"params\">sequence, window_size=<span class=\"number\">3</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;传统滑动窗口方法&quot;&quot;&quot;</span></span><br><span class=\"line\">    predictions = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(sequence)):</span><br><span class=\"line\">        <span class=\"comment\"># 获取窗口内的词向量</span></span><br><span class=\"line\">        start = <span class=\"built_in\">max</span>(<span class=\"number\">0</span>, i - window_size // <span class=\"number\">2</span>)</span><br><span class=\"line\">        end = <span class=\"built_in\">min</span>(<span class=\"built_in\">len</span>(sequence), i + window_size // <span class=\"number\">2</span> + <span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        window_vectors = sequence[start:end]</span><br><span class=\"line\">        <span class=\"comment\"># 拼接窗口内向量作为特征</span></span><br><span class=\"line\">        features = concatenate(window_vectors)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 通过全连接层预测</span></span><br><span class=\"line\">        prediction = fully_connected_layer(features)</span><br><span class=\"line\">        predictions.append(prediction)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> predictions</span><br></pre></td></tr></table></figure>\n<div class=\"note danger no-icon\">\n<p>滑动窗口方法的核心缺陷：<strong>长度限制不能保证可以把一整个句子覆盖</strong>，导致模型无法获得足够的上下文信息来做出准确预测。</p>\n</div>\n<p>考虑句子：&quot;这部电影的剧情很复杂，但是演员的表演非常出色，总体来说还是值得推荐的。&quot; 如果我们要判断 &quot;推荐&quot; 这个词的情感倾向，仅仅看其周围几个词是不够的，需要理解整个句子的语义。</p>\n<h3 id=\"自注意力的突破性思路\"><a class=\"anchor\" href=\"#自注意力的突破性思路\">#</a> 自注意力的突破性思路</h3>\n<p><ins class=\"dot\">通过自注意力来考虑一整个句子</ins>，这一思路彻底改变了序列建模的范式。自注意力机制能够：</p>\n<ol>\n<li><strong>全局感知</strong>：每个位置都能 &quot;看到&quot; 序列中的所有其他位置</li>\n<li><strong>动态加权</strong>：根据内容自动决定关注程度</li>\n<li><strong>并行计算</strong>：不依赖于递归结构，可以高效并行</li>\n</ol>\n<h2 id=\"自注意力机制的数学原理\"><a class=\"anchor\" href=\"#自注意力机制的数学原理\">#</a> 自注意力机制的数学原理</h2>\n<h3 id=\"核心计算流程\"><a class=\"anchor\" href=\"#核心计算流程\">#</a> 核心计算流程</h3>\n<p>假设我们有输入序列 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><msup><mi>a</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>4</mn></msup><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{a^1, a^2, a^3, a^4\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">}</span></span></span></span>，自注意力的计算过程如下：</p>\n<p><strong>第一步：计算查询、键、值向量</strong></p>\n<p>对于每个输入向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding=\"application/x-tex\">a^i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.824664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span></span></span>，我们通过三个不同的线性变换得到：</p>\n<ul>\n<li>查询向量：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>q</mi><mi>i</mi></msup><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding=\"application/x-tex\">q^i = W^q a^i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.019104em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.824664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span></span></span></li>\n<li>键向量：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>k</mi><mi>i</mi></msup><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding=\"application/x-tex\">k^i = W^k a^i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.824664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span></span></span></li>\n<li>值向量：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>v</mi><mi>i</mi></msup><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><msup><mi>a</mi><mi>i</mi></msup></mrow><annotation encoding=\"application/x-tex\">v^i = W^v a^i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.824664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.824664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span></span></span></li>\n</ul>\n<p>具体地：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>q</mi><mn>1</mn></msup><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><msup><mi>a</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>k</mi><mn>1</mn></msup><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><msup><mi>a</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>v</mi><mn>1</mn></msup><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><msup><mi>a</mi><mn>1</mn></msup></mrow><annotation encoding=\"application/x-tex\">q^1 = W^q a^1, \\quad k^1 = W^k a^1, \\quad v^1 = W^v a^1\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714392em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.093548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>q</mi><mn>2</mn></msup><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><msup><mi>a</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>k</mi><mn>2</mn></msup><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><msup><mi>a</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>v</mi><mn>2</mn></msup><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><msup><mi>a</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">q^2 = W^q a^2, \\quad k^2 = W^k a^2, \\quad v^2 = W^v a^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714392em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.093548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>q</mi><mn>3</mn></msup><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><msup><mi>a</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>k</mi><mn>3</mn></msup><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><msup><mi>a</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>v</mi><mn>3</mn></msup><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><msup><mi>a</mi><mn>3</mn></msup></mrow><annotation encoding=\"application/x-tex\">q^3 = W^q a^3, \\quad k^3 = W^k a^3, \\quad v^3 = W^v a^3\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714392em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.093548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>q</mi><mn>4</mn></msup><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><msup><mi>a</mi><mn>4</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>k</mi><mn>4</mn></msup><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><msup><mi>a</mi><mn>4</mn></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msup><mi>v</mi><mn>4</mn></msup><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><msup><mi>a</mi><mn>4</mn></msup></mrow><annotation encoding=\"application/x-tex\">q^4 = W^q a^4, \\quad k^4 = W^k a^4, \\quad v^4 = W^v a^4\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714392em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.093548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>第二步：计算注意力权重</strong></p>\n<p><ins class=\"dot\">获得两个向量关联度的方法</ins>主要有两种：</p>\n<div class=\"tab\" data-id=\"method1\" data-title=\"点积注意力 (Dot-Product)\">\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><msup><mi>q</mi><mi>i</mi></msup><mo>⋅</mo><msup><mi>k</mi><mi>j</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha_{i,j} = q^i \\cdot k^j\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0691039999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.874664em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.874664em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>计算简单，效率高，是最常用的方法</p>\n</div>\n<div class=\"tab\" data-id=\"method2\" data-title=\"加性注意力 (Additive)\">\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><msup><mi>v</mi><mi>T</mi></msup><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mn>1</mn></msub><msup><mi>q</mi><mi>i</mi></msup><mo>+</mo><msub><mi>W</mi><mn>2</mn></msub><msup><mi>k</mi><mi>j</mi></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha_{i,j} = v^T \\tanh(W_1 q^i + W_2 k^j)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">tanh</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.124664em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.874664em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>参数更多，表达能力更强，但计算复杂度更高</p>\n</div>\n<details class=\"info\"><summary>注意力计算方法对比</summary><div>\n<p><strong>点积注意力 (Dot-Product Attention)</strong></p>\n<ul>\n<li>优点：计算效率高，参数少，易于并行化</li>\n<li>缺点：当向量维度很大时，点积值可能过大导致梯度消失</li>\n<li>改进：scaled dot-product，除以 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.18278000000000005em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span></span> 进行缩放</li>\n</ul>\n<p><strong>加性注意力 (Additive Attention)</strong></p>\n<ul>\n<li>优点：表达能力强，不受向量维度影响</li>\n<li>缺点：参数多，计算复杂度高</li>\n<li>适用场景：向量维度较大或需要更强表达能力时</li>\n</ul>\n<p>实际应用中，scaled dot-product 因其效率优势被广泛采用。</p>\n</div></details>\n<p>以第一个位置为例，计算与所有位置的关联度：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo>=</mo><msup><mi>q</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>k</mi><mn>1</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha_{1,1} = q^1 \\cdot k^1\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo>=</mo><msup><mi>q</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha_{1,2} = q^1 \\cdot k^2\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn></mrow></msub><mo>=</mo><msup><mi>q</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>k</mi><mn>3</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha_{1,3} = q^1 \\cdot k^3\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">3</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>4</mn></mrow></msub><mo>=</mo><msup><mi>q</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>k</mi><mn>4</mn></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha_{1,4} = q^1 \\cdot k^4\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">4</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0585479999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>第三步：归一化注意力权重</strong></p>\n<p>使用 softmax 函数对注意力权重进行归一化：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo separator=\"true\">,</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo separator=\"true\">,</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo separator=\"true\">,</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>4</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn></mrow></msub><mo separator=\"true\">,</mo><msub><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>4</mn></mrow></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha&#x27;_{1,1}, \\alpha&#x27;_{1,2}, \\alpha&#x27;_{1,3}, \\alpha&#x27;_{1,4} = \\text{softmax}(\\alpha_{1,1}, \\alpha_{1,2}, \\alpha_{1,3}, \\alpha_{1,4})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.185em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">3</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">4</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">3</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">4</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><strong>第四步：计算输出向量</strong></p>\n<p>最终的输出向量是所有值向量的加权组合：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>b</mi><mn>1</mn></msup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mn>4</mn></munderover><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mi>i</mi></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><msup><mi>v</mi><mi>i</mi></msup><mo>=</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><msup><mi>v</mi><mn>1</mn></msup><mo>+</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><msup><mi>v</mi><mn>2</mn></msup><mo>+</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><msup><mi>v</mi><mn>3</mn></msup><mo>+</mo><msubsup><mi>α</mi><mrow><mn>1</mn><mo separator=\"true\">,</mo><mn>4</mn></mrow><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><msup><mi>v</mi><mn>4</mn></msup></mrow><annotation encoding=\"application/x-tex\">b^1 = \\sum_{i=1}^{4} \\alpha&#x27;_{1,i} v^i = \\alpha&#x27;_{1,1} v^1 + \\alpha&#x27;_{1,2} v^2 + \\alpha&#x27;_{1,3} v^3 + \\alpha&#x27;_{1,4} v^4\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8641079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0787820000000004em;vertical-align:-1.277669em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8011130000000004em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">4</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2472159999999999em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2472159999999999em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2472159999999999em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">3</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2472159999999999em;vertical-align:-0.383108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">4</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<h3 id=\"矩阵化表示\"><a class=\"anchor\" href=\"#矩阵化表示\">#</a> 矩阵化表示</h3>\n<p>为了提高计算效率，我们将上述过程用矩阵形式表示：</p>\n<p>设输入矩阵：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>I</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msup><mi>a</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>a</mi><mn>4</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">I = [a^1, a^2, a^3, a^4]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></p>\n<p>计算查询、键、值矩阵：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>Q</mi><mo>=</mo><msup><mi>W</mi><mi>q</mi></msup><mi>I</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msup><mi>q</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>q</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>q</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>q</mi><mn>4</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">Q = W^q I = [q^1, q^2, q^3, q^4]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714392em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714392em;\"><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>K</mi><mo>=</mo><msup><mi>W</mi><mi>k</mi></msup><mi>I</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msup><mi>k</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>k</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>k</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>k</mi><mn>4</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">K = W^k I = [k^1, k^2, k^3, k^4]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8991079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>V</mi><mo>=</mo><msup><mi>W</mi><mi>v</mi></msup><mi>I</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msup><mi>v</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>v</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>v</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>v</mi><mn>4</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">V = W^v I = [v^1, v^2, v^3, v^4]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7143919999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>注意力权重矩阵：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>A</mi><mo>=</mo><msup><mi>K</mi><mi>T</mi></msup><mi>Q</mi><mo>=</mo><mrow><mo fence=\"true\">(</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>1</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>2</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>3</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>1</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>4</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>1</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>2</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>3</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>4</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>3</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>1</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>3</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>2</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>3</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>3</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>3</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>4</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>4</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>1</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>4</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>2</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>4</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>3</mn></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><msup><mi>k</mi><mn>4</mn></msup><mo>⋅</mo><msup><mi>q</mi><mn>4</mn></msup></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">A = K^T Q = \\begin{pmatrix}\nk^1 \\cdot q^1 &amp; k^1 \\cdot q^2 &amp; k^1 \\cdot q^3 &amp; k^1 \\cdot q^4 \\\\\nk^2 \\cdot q^1 &amp; k^2 \\cdot q^2 &amp; k^2 \\cdot q^3 &amp; k^2 \\cdot q^4 \\\\\nk^3 \\cdot q^1 &amp; k^3 \\cdot q^2 &amp; k^3 \\cdot q^3 &amp; k^3 \\cdot q^4 \\\\\nk^4 \\cdot q^1 &amp; k^4 \\cdot q^2 &amp; k^4 \\cdot q^3 &amp; k^4 \\cdot q^4\n\\end{pmatrix}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0857709999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\">Q</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:4.80006em;vertical-align:-2.15003em;\"></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500299999999997em;\"><span style=\"top:-1.6499900000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎝</span></span></span><span style=\"top:-2.8000000000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎜</span></span></span><span style=\"top:-3.39501em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎜</span></span></span><span style=\"top:-3.41001em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎜</span></span></span><span style=\"top:-4.65003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎛</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.15003em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500000000000004em;\"><span style=\"top:-4.8100000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span><span style=\"top:-1.2099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500000000000004em;\"><span style=\"top:-4.8100000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-1.2099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500000000000004em;\"><span style=\"top:-4.8100000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span><span style=\"top:-1.2099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500000000000004em;\"><span style=\"top:-4.8100000000000005em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span><span style=\"top:-1.2099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.1500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.6500299999999997em;\"><span style=\"top:-1.6499900000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎠</span></span></span><span style=\"top:-2.8000000000000003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎟</span></span></span><span style=\"top:-3.39501em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎟</span></span></span><span style=\"top:-3.41001em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎟</span></span></span><span style=\"top:-4.65003em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.15003em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p>归一化后的注意力矩阵：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mi>A</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">A&#x27; = \\text{softmax}(A)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.801892em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>最终输出：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>O</mi><mo>=</mo><mi>V</mi><msup><mi>A</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mo stretchy=\"false\">[</mo><msup><mi>b</mi><mn>1</mn></msup><mo separator=\"true\">,</mo><msup><mi>b</mi><mn>2</mn></msup><mo separator=\"true\">,</mo><msup><mi>b</mi><mn>3</mn></msup><mo separator=\"true\">,</mo><msup><mi>b</mi><mn>4</mn></msup><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">O = V A&#x27; = [b^1, b^2, b^3, b^4]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.801892em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1141079999999999em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<div class=\"note success no-icon\">\n<p>这种矩阵化表示使得自注意力计算可以高效地进行并行化处理，这是其相比 RNN 的重要优势之一。</p>\n</div>\n<h2 id=\"多头注意力增强表达能力\"><a class=\"anchor\" href=\"#多头注意力增强表达能力\">#</a> 多头注意力：增强表达能力</h2>\n<p>单一的注意力头可能无法捕获序列中的所有重要关系。<ins class=\"dot\">Multi-head self-attention</ins> 通过使用多个不同的注意力头来解决这个问题。</p>\n<details class=\"warning\"><summary>Multi-Head Attention详细机制</summary><div>\n<p>多头注意力的核心思想是让模型能够从多个不同的表示子空间中学习信息。</p>\n<p><strong>实现步骤：</strong></p>\n<ol>\n<li><strong>多组参数矩阵</strong>：为每个头准备独立的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>q</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>k</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>v</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">W^q_i, W^k_i, W^v_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.125972em;vertical-align:-0.276864em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7823em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-2.441336em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li><strong>并行计算</strong>：每个头独立计算自注意力</li>\n<li><strong>结果拼接</strong>：将所有头的输出拼接起来</li>\n<li><strong>线性变换</strong>：通过输出投影矩阵进行最终变换</li>\n</ol>\n<p><strong>数学表示：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mtext>head</mtext><mi>i</mi></msub><mo>=</mo><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>q</mi></msubsup><mo separator=\"true\">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>k</mi></msubsup><mo separator=\"true\">,</mo><mi>V</mi><msubsup><mi>W</mi><mi>i</mi><mi>v</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{head}_i = \\text{Attention}(QW^q_i, KW^k_i, VW^v_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1759719999999998em;vertical-align:-0.276864em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7822999999999999em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.180908em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8991079999999998em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>MultiHead</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mtext>Concat</mtext><mo stretchy=\"false\">(</mo><msub><mtext>head</mtext><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mtext>head</mtext><mi>h</mi></msub><mo stretchy=\"false\">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">MultiHead</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Concat</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">head</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>优势分析：</strong></p>\n<ul>\n<li>不同的头可以关注不同类型的关系（语法、语义等）</li>\n<li>增加模型容量而不显著增加计算复杂度</li>\n<li>提供更丰富的特征表示</li>\n</ul>\n</div></details>\n<figure class=\"highlight python\"><figcaption><span>多头注意力实现框架</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MultiHeadAttention</span>:</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, d_model, num_heads</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.num_heads = num_heads</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.d_k = d_model // num_heads</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 每个头的参数矩阵</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W_q = [LinearLayer(d_model, <span class=\"variable language_\">self</span>.d_k) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_heads)]</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W_k = [LinearLayer(d_model, <span class=\"variable language_\">self</span>.d_k) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_heads)]  </span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W_v = [LinearLayer(d_model, <span class=\"variable language_\">self</span>.d_k) <span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(num_heads)]</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 输出投影层</span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.W_o = LinearLayer(d_model, d_model)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, query, key, value</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 并行计算所有头</span></span><br><span class=\"line\">        attention_heads = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"variable language_\">self</span>.num_heads):</span><br><span class=\"line\">            q_i = <span class=\"variable language_\">self</span>.W_q[i](query)</span><br><span class=\"line\">            k_i = <span class=\"variable language_\">self</span>.W_k[i](key) </span><br><span class=\"line\">            v_i = <span class=\"variable language_\">self</span>.W_v[i](value)</span><br><span class=\"line\">            </span><br><span class=\"line\">            head_i = scaled_dot_product_attention(q_i, k_i, v_i)</span><br><span class=\"line\">            attention_heads.append(head_i)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 拼接并投影</span></span><br><span class=\"line\">        concatenated = concatenate(attention_heads)</span><br><span class=\"line\">        output = <span class=\"variable language_\">self</span>.W_o(concatenated)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">return</span> output</span><br></pre></td></tr></table></figure>\n<h2 id=\"位置信息的重要性\"><a class=\"anchor\" href=\"#位置信息的重要性\">#</a> 位置信息的重要性</h2>\n<h3 id=\"位置编码的必要性\"><a class=\"anchor\" href=\"#位置编码的必要性\">#</a> 位置编码的必要性</h3>\n<p>自注意力机制本身是位置无关的，即调换输入序列的顺序不会影响注意力权重的计算。但在实际的序列任务中，位置信息是至关重要的。</p>\n<div class=\"note info no-icon\">\n<p>&quot;我爱你&quot; 和 &quot;你爱我&quot; 虽然包含相同的词，但含义完全不同。这说明词语的位置信息对于理解句子含义是必不可少的。</p>\n</div>\n<p><ins class=\"dot\">Positional encoding</ins> 的作用是为模型提供序列中每个位置的信息。最常用的方法是在输入向量中加入位置编码：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>input</mtext><mo>=</mo><msub><mi>e</mi><mi>i</mi></msub><mo>+</mo><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\text{input} = e_i + a_i\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8623000000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord text\"><span class=\"mord\">input</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">e_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是位置编码向量，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>a</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">a_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是原始输入向量。</p>\n<details class=\"primary\"><summary>位置编码方法详解</summary><div>\n<p><strong>1. 正弦余弦位置编码（Sinusoidal Positional Encoding）</strong></p>\n<p>这是 Transformer 原论文中提出的方法：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msub><mo>=</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">PE_{(pos,2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.03853em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8539999999999999em;vertical-align:-0.704em;\"></span><span class=\"mop\">sin</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msub><mo>=</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">PE_{(pos,2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.03853em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8539999999999999em;vertical-align:-0.704em;\"></span><span class=\"mop\">cos</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.2960000000000003em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.704em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">pos</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span></span></span></span> 是位置索引</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 是维度索引</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是模型维度</li>\n</ul>\n<p><strong>优点：</strong></p>\n<ul>\n<li>无需训练参数</li>\n<li>可以处理任意长度的序列</li>\n<li>具有良好的外推性</li>\n</ul>\n<p><strong>2. 可学习位置编码（Learnable Positional Encoding）</strong></p>\n<p>直接学习每个位置的编码向量：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo>=</mo><mtext>Embedding</mtext><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">PE_{pos} = \\text{Embedding}(pos)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Embedding</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">s</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><strong>优点：</strong></p>\n<ul>\n<li>可以学习到任务特定的位置表示</li>\n<li>灵活性更高</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>无法处理超过训练长度的序列</li>\n<li>需要额外的参数</li>\n</ul>\n<p><strong>3. 相对位置编码（Relative Positional Encoding）</strong></p>\n<p>不是给每个绝对位置编码，而是编码相对位置关系：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mi>q</mi><mi>i</mi></msub><mo>⋅</mo><mo stretchy=\"false\">(</mo><msub><mi>k</mi><mi>j</mi></msub><mo>+</mo><msub><mi>r</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub><mo stretchy=\"false\">)</mo></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac></mrow><annotation encoding=\"application/x-tex\">\\alpha_{i,j} = \\frac{q_i \\cdot (k_j + r_{i-j})}{\\sqrt{d_k}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.357em;vertical-align:-0.93em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.25278em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.85722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.81722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18278000000000005em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.93em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>−</mo><mi>j</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">r_{i-j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 表示位置 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>j</mi></mrow><annotation encoding=\"application/x-tex\">j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.85396em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05724em;\">j</span></span></span></span> 之间的相对位置编码。</p>\n</div></details>\n<h2 id=\"rnn与自注意力的对比分析\"><a class=\"anchor\" href=\"#rnn与自注意力的对比分析\">#</a> RNN 与自注意力的对比分析</h2>\n<p>在自注意力机制普及之前，<ins class=\"dot\">RNN</ins>（循环神经网络）是处理序列数据的主流方法。</p>\n<details class=\"info\"><summary>RNN基础概念回顾</summary><div>\n<p>** 循环神经网络（Recurrent Neural Network, RNN）** 是一类专门处理序列数据的神经网络。其核心特点是具有 &quot;记忆&quot; 能力，能够利用之前的信息来影响当前的输出。</p>\n<p><strong>基本结构：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>h</mi></mrow></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>W</mi><mrow><mi>x</mi><mi>h</mi></mrow></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">h_t = \\tanh(W_{hh}h_{t-1} + W_{xh}x_t + b_h)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">tanh</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>W</mi><mrow><mi>h</mi><mi>y</mi></mrow></msub><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>y</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_t = W_{hy}h_t + b_y\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>主要变种：</strong></p>\n<ul>\n<li><strong>LSTM（长短期记忆网络）</strong>：通过门控机制解决梯度消失问题</li>\n<li><strong>GRU（门控循环单元）</strong>：LSTM 的简化版本，参数更少</li>\n</ul>\n<p><strong>应用场景：</strong></p>\n<ul>\n<li>语言模型、机器翻译</li>\n<li>语音识别、情感分析</li>\n<li>时间序列预测</li>\n</ul>\n</div></details>\n<p>下面是 RNN 与自注意力机制的详细对比：</p>\n<table>\n<thead>\n<tr>\n<th>维度</th>\n<th>RNN</th>\n<th>Self-Attention</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>计算复杂度</strong></td>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo>⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n \\cdot d^2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></td>\n<td><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^2 \\cdot d)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mclose\">)</span></span></span></span></td>\n</tr>\n<tr>\n<td><strong>并行化能力</strong></td>\n<td>串行计算，无法并行</td>\n<td>高度并行化</td>\n</tr>\n<tr>\n<td><strong>长距离依赖</strong></td>\n<td>梯度消失，难以建模</td>\n<td>直接建模，效果好</td>\n</tr>\n<tr>\n<td><strong>内存需求</strong></td>\n<td>需要存储所有中间状态</td>\n<td>只需存储注意力矩阵</td>\n</tr>\n<tr>\n<td><strong>位置信息</strong></td>\n<td>隐式编码在状态中</td>\n<td>需要显式位置编码</td>\n</tr>\n</tbody>\n</table>\n<figure class=\"highlight python\"><figcaption><span>RNN与Self-Attention处理流程对比</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># RNN处理方式</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">rnn_process</span>(<span class=\"params\">sequence</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;RNN串行处理序列&quot;&quot;&quot;</span></span><br><span class=\"line\">    hidden_state = init_hidden()</span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> timestep <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(sequence)):</span><br><span class=\"line\">        <span class=\"comment\"># 必须按顺序处理，无法并行</span></span><br><span class=\"line\">        hidden_state = rnn_cell(sequence[timestep], hidden_state)</span><br><span class=\"line\">        output = output_layer(hidden_state)</span><br><span class=\"line\">        outputs.append(output)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> outputs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Self-Attention处理方式  </span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">self_attention_process</span>(<span class=\"params\">sequence</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;Self-Attention并行处理序列&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 所有位置可以同时计算</span></span><br><span class=\"line\">    Q, K, V = compute_qkv(sequence)  <span class=\"comment\"># 并行计算</span></span><br><span class=\"line\">    attention_weights = compute_attention(Q, K)  <span class=\"comment\"># 并行计算</span></span><br><span class=\"line\">    outputs = apply_attention(attention_weights, V)  <span class=\"comment\"># 并行计算</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> outputs</span><br></pre></td></tr></table></figure>\n<div class=\"note warning no-icon\">\n<p>当序列长度 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> 较短时，自注意力的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^2 \\cdot d)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mclose\">)</span></span></span></span> 复杂度是可接受的。但当处理非常长的序列时，二次复杂度可能成为瓶颈，这也催生了各种高效注意力机制的研究。</p>\n</div>\n<h2 id=\"自注意力的扩展应用\"><a class=\"anchor\" href=\"#自注意力的扩展应用\">#</a> 自注意力的扩展应用</h2>\n<h3 id=\"与cnn的关系\"><a class=\"anchor\" href=\"#与cnn的关系\">#</a> 与 CNN 的关系</h3>\n<p>有趣的是，<ins class=\"dot\">CNN 可以看作是只考虑一小部分的简化版 self-attention</ins>。</p>\n<p>在 CNN 中，每个位置只与其感受野内的邻近位置交互，这可以视为一种受限的注意力机制，其中注意力权重是固定的（由卷积核决定），且只在局部范围内非零。</p>\n<figure class=\"highlight python\"><figcaption><span>CNN与Self-Attention的类比</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CNN的局部连接</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cnn_like_attention</span>(<span class=\"params\">sequence, kernel_size=<span class=\"number\">3</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;CNN风格的受限注意力&quot;&quot;&quot;</span></span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(sequence)):</span><br><span class=\"line\">        <span class=\"comment\"># 只关注局部窗口</span></span><br><span class=\"line\">        start = <span class=\"built_in\">max</span>(<span class=\"number\">0</span>, i - kernel_size // <span class=\"number\">2</span>)</span><br><span class=\"line\">        end = <span class=\"built_in\">min</span>(<span class=\"built_in\">len</span>(sequence), i + kernel_size // <span class=\"number\">2</span> + <span class=\"number\">1</span>)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># 固定的注意力权重（卷积核）</span></span><br><span class=\"line\">        local_features = sequence[start:end]</span><br><span class=\"line\">        output = fixed_weight_combination(local_features)</span><br><span class=\"line\">        outputs.append(output)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">return</span> outputs</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Self-Attention的全局连接</span></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">full_self_attention</span>(<span class=\"params\">sequence</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;完整的自注意力机制&quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"comment\"># 每个位置都能关注到所有位置</span></span><br><span class=\"line\">    <span class=\"comment\"># 注意力权重是动态学习的</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> self_attention(sequence)</span><br></pre></td></tr></table></figure>\n<p>这种类比帮助我们理解：</p>\n<ul>\n<li><strong>CNN</strong>：局部感受野 + 参数共享 + 固定权重</li>\n<li><strong>Self-Attention</strong>：全局感受野 + 动态权重 + 内容相关</li>\n</ul>\n<h3 id=\"图神经网络的连接\"><a class=\"anchor\" href=\"#图神经网络的连接\">#</a> 图神经网络的连接</h3>\n<p><ins class=\"dot\">Self-attention 用在图上也是一种 GNN</ins>（图神经网络）。在图结构上，自注意力可以让每个节点关注其他所有节点，这与图注意力网络（Graph Attention Network, GAT）的思想不谋而合。</p>\n<details class=\"success\"><summary>图上的自注意力机制</summary><div>\n<p>当将自注意力应用到图数据时，我们可以：</p>\n<p><strong>1. 节点级注意力</strong><br />\n每个节点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>v</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">v_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 计算对其他节点 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>v</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">v_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 的注意力权重：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mtext>softmax</mtext><mrow><mo fence=\"true\">(</mo><mtext>LeakyReLU</mtext><mrow><mo fence=\"true\">(</mo><msup><mi mathvariant=\"bold\">a</mi><mi>T</mi></msup><mo stretchy=\"false\">[</mo><mi>W</mi><msub><mi mathvariant=\"bold\">h</mi><mi>i</mi></msub><mi mathvariant=\"normal\">∥</mi><mi>W</mi><msub><mi mathvariant=\"bold\">h</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\alpha_{ij} = \\text{softmax}\\left(\\text{LeakyReLU}\\left(\\mathbf{a}^T[W\\mathbf{h}_i \\| W\\mathbf{h}_j]\\right)\\right)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2413409999999998em;vertical-align:-0.35001em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord text\"><span class=\"mord\">LeakyReLU</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">a</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">h</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∥</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">h</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span></span></span></span></span></p>\n<p><strong>2. 考虑图结构</strong><br />\n可以将注意力限制在邻居节点上，或者使用图的拓扑信息来调节注意力权重。</p>\n<p><strong>3. 多关系建模</strong><br />\n对于异构图，可以为不同类型的关系使用不同的注意力头。</p>\n<p><strong>应用场景：</strong></p>\n<ul>\n<li>社交网络分析</li>\n<li>分子性质预测</li>\n<li>推荐系统</li>\n<li>知识图谱推理</li>\n</ul>\n</div></details>\n<h2 id=\"改进与优化方向\"><a class=\"anchor\" href=\"#改进与优化方向\">#</a> 改进与优化方向</h2>\n<h3 id=\"计算效率优化\"><a class=\"anchor\" href=\"#计算效率优化\">#</a> 计算效率优化</h3>\n<p>由于标准自注意力的 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span> 复杂度，研究者们提出了多种优化方案：</p>\n<details class=\"info\"><summary>高效注意力机制</summary><div>\n<p><strong>1. Truncated Self-Attention（截断自注意力）</strong><br />\n限制每个位置只能关注其附近的一定范围内的位置，将复杂度降为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo>⋅</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n \\cdot w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span>，其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span></span></span></span> 是窗口大小。</p>\n<p><strong>2. Sparse Attention</strong></p>\n<ul>\n<li>Local Attention：只关注局部邻居</li>\n<li>Strided Attention：以固定步长关注位置</li>\n<li>Random Attention：随机选择关注位置</li>\n</ul>\n<p><strong>3. Linear Attention</strong><br />\n 通过核技巧将复杂度降为 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo>⋅</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n \\cdot d)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mclose\">)</span></span></span></span>：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Attention</mtext><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>K</mi><msup><mo stretchy=\"false\">)</mo><mi>T</mi></msup><mi>V</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\text{Attention}(Q,K,V) = \\phi(Q)(\\phi(K)^TV)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Attention</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><strong>4. Low-rank Approximation</strong><br />\n 假设注意力矩阵是低秩的，使用矩阵分解来近似。</p>\n</div></details>\n<p><ins class=\"dot\">Truncated self-attention</ins> 是其中一种重要的优化方案，它在保持一定性能的同时显著降低了计算复杂度。</p>\n<h3 id=\"任务特定改进\"><a class=\"anchor\" href=\"#任务特定改进\">#</a> 任务特定改进</h3>\n<ul>\n<li><strong>文档级建模</strong>：Longformer, BigBird 等处理长文档</li>\n<li><strong>多模态融合</strong>：视觉 - 语言任务中的跨模态注意力</li>\n<li><strong>层次化注意力</strong>：先局部后全局的分层处理</li>\n</ul>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "深度学习",
                "Transformer",
                "注意力机制",
                "位置编码",
                "多头注意力",
                "序列建模",
                "机器学习",
                "自注意力",
                "词嵌入",
                "序列标注"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1290-%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%93%BE%E8%A1%A8%E8%BD%AC%E6%95%B4%E6%95%B0/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1290-%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%93%BE%E8%A1%A8%E8%BD%AC%E6%95%B4%E6%95%B0/",
            "title": "力扣每日一题：1290. 二进制链表转整数",
            "date_published": "2025-07-14T04:17:45.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9jb252ZXJ0LWJpbmFyeS1udW1iZXItaW4tYS1saW5rZWQtbGlzdC10by1pbnRlZ2VyP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMTQ=\">LeetCode 1290</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个单链表的引用结点 head。链表中每个结点的值不是 0 就是 1。已知此链表是一个整数数字的二进制表示形式。</p>\n<p>请你返回该链表所表示数字的 十进制值 。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>每次对当前值乘二，然后再加上当前节点的值。直到链表结束。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\"> * Definition for singly-linked list.</span></span><br><span class=\"line\"><span class=\"comment\"> * struct ListNode &#123;</span></span><br><span class=\"line\"><span class=\"comment\"> *     int val;</span></span><br><span class=\"line\"><span class=\"comment\"> *     ListNode *next;</span></span><br><span class=\"line\"><span class=\"comment\"> *     ListNode() : val(0), next(nullptr) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> *     ListNode(int x) : val(x), next(nullptr) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> *     ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125;</span></span><br><span class=\"line\"><span class=\"comment\"> * &#125;;</span></span><br><span class=\"line\"><span class=\"comment\"> */</span></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">getDecimalValue</span><span class=\"params\">(ListNode* head)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> res = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (head != <span class=\"literal\">nullptr</span>)&#123;</span><br><span class=\"line\">            res &lt;&lt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">            res += head-&gt;val;</span><br><span class=\"line\">            head = head-&gt;next;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A2410-%E8%BF%90%E5%8A%A8%E5%91%98%E5%92%8C%E8%AE%AD%E7%BB%83%E5%B8%88%E7%9A%84%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%95%B0/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A2410-%E8%BF%90%E5%8A%A8%E5%91%98%E5%92%8C%E8%AE%AD%E7%BB%83%E5%B8%88%E7%9A%84%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%95%B0/",
            "title": "力扣每日一题：2410. 运动员和训练师的最大匹配数",
            "date_published": "2025-07-12T17:19:56.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9tYXhpbXVtLW1hdGNoaW5nLW9mLXBsYXllcnMtd2l0aC10cmFpbmVycz9lbnZUeXBlPWRhaWx5LXF1ZXN0aW9uJmFtcDtlbnZJZD0yMDI1LTA3LTEz\">LeetCode 2410</span> 的题解，记录了解题思路、代码实现及复杂度分析。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个下标从 0 开始的整数数组  <code>players</code>  ，其中  <code>players[i]</code>  表示第  <code>i</code>  名运动员的 能力 值，同时给你一个下标从 0 开始的整数数组  <code>trainers</code>  ，其中  <code>trainers[j]</code>  表示第  <code>j</code>  名训练师的 训练能力值 。</p>\n<p>如果第  <code>i</code>  名运动员的能力值 小于等于 第  <code>j</code>  名训练师的能力值，那么第  <code>i</code>  名运动员可以 匹配 第  <code>j</code>  名训练师。除此以外，每名运动员至多可以匹配一位训练师，每位训练师最多可以匹配一位运动员。</p>\n<p>请你返回满足上述要求  <code>players</code>  和  <code>trainers</code>  的 最大 匹配数。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>本题可以使用双指针的贪心策略来解决。首先对运动员和训练师的能力值进行排序，然后使用两个指针分别遍历运动员和训练师数组。当训练师的能力值大于等于运动员的能力值时，说明该运动员可以匹配该训练师，此时将两个指针都向前移动，并增加匹配计数；如果训练师的能力值小于运动员的能力值，则只移动训练师的指针，寻找下一个可能匹配的训练师。这样可以确保每个运动员都能找到最合适的训练师，从而最大化匹配数。而没被选中的训练师则说明他们的能力值都小于当前最小能力值的运动员，因此可以跳过。若是当前没被选中的能力值最小的运动员也无法匹配任何训练师，则可以直接结束匹配。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">matchPlayersAndTrainers</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt;&amp; players, vector&lt;<span class=\"type\">int</span>&gt;&amp; trainers)</span> </span>&#123;</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(players);</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(trainers);</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> i = <span class=\"number\">0</span>, j = <span class=\"number\">0</span>, n = players.<span class=\"built_in\">size</span>(), m = trainers.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (j &lt; m &amp;&amp; i &lt; n)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (j &lt; m &amp;&amp; trainers[j] &lt; players[i]) j++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (j &lt; m) i++, j++, ans++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "贪心",
                "双指针"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1900-%E6%9C%80%E4%BD%B3%E8%BF%90%E5%8A%A8%E5%91%98%E7%9A%84%E6%AF%94%E6%8B%BC%E5%9B%9E%E5%90%88/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1900-%E6%9C%80%E4%BD%B3%E8%BF%90%E5%8A%A8%E5%91%98%E7%9A%84%E6%AF%94%E6%8B%BC%E5%9B%9E%E5%90%88/",
            "title": "力扣每日一题：1900. 最佳运动员的比拼回合",
            "date_published": "2025-07-12T16:20:14.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy90aGUtZWFybGllc3QtYW5kLWxhdGVzdC1yb3VuZHMtd2hlcmUtcGxheWVycy1jb21wZXRlP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMTI=\">LeetCode 1900</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p><code>n</code>  名运动员参与一场锦标赛，所有运动员站成一排，并根据 最开始的 站位从  <code>1</code>  到  <code>n</code>  编号（运动员  <code>1</code>  是这一排中的第一个运动员，运动员  <code>2</code>  是第二个运动员，依此类推）。</p>\n<p>锦标赛由多个回合组成（从回合  <code>1</code>  开始）。每一回合中，这一排从前往后数的第  <code>i</code>  名运动员需要与从后往前数的第  <code>i</code>  名运动员比拼，获胜者将会进入下一回合。如果当前回合中运动员数目为奇数，那么中间那位运动员将轮空晋级下一回合。</p>\n<pre><code>例如，当前回合中，运动员 1, 2, 4, 6, 7 站成一排\n    运动员 1 需要和运动员 7 比拼\n    运动员 2 需要和运动员 6 比拼\n    运动员 4 轮空晋级下一回合\n</code></pre>\n<p>每回合结束后，获胜者将会基于最开始分配给他们的原始顺序（升序）重新排成一排。</p>\n<p>编号为  <code>firstPlayer</code>  和  <code>secondPlayer</code>  的运动员是本场锦标赛中的最佳运动员。在他们开始比拼之前，完全可以战胜任何其他运动员。而任意两个其他运动员进行比拼时，其中任意一个都有获胜的可能，因此你可以 裁定 谁是这一回合的获胜者。</p>\n<p>给你三个整数  <code>n</code> 、 <code>firstPlayer</code>  和  <code>secondPlayer</code>  。返回一个由两个值组成的整数数组，分别表示两位最佳运动员在本场锦标赛中比拼的 最早 回合数和 最晚 回合数。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>本题 n 最大为 28，使用深度优先搜索（DFS）来模拟每一回合的比拼过程。我们需要记录每个运动员在每一回合的状态，并计算出最佳运动员的最早和最晚比拼回合数。</p>\n<p>我们可以使用一个四维数组  <code>ans[fp][sp][n][is_er]</code>  来存储状态，其中  <code>fp</code>  和  <code>sp</code>  分别表示第一名和第二名运动员的编号， <code>n</code>  表示当前回合的运动员数量， <code>is_er</code>  表示是否计算最早回合数。</p>\n<p>我们通过递归函数  <code>dfs(fp, sp, n, is_er)</code>  来实现深度优先搜索。函数的返回值是当前状态下的最早或最晚回合数。<br />\n递归时，若  <code>n - sp + 1 == fp</code> ，说明两名运动员在同一回合中相遇，返回 1。</p>\n<p>若  <code>fp &gt; n / 2</code> ，由于这道题是对称的，因此我们可以只考虑  <code>fp</code>  在前半部分的情况，因此当  <code>fp</code>  大于  <code>n / 2</code>  时，我们将其转换为对称的情况。<br />\n接下来，我们需要处理  <code>fp</code>  和  <code>sp</code>  的位置关系，并根据当前回合的运动员数量进行递归。</p>\n<p>我们定义几个变量：</p>\n<ul>\n<li><code>pre</code> ：表示第一名运动员之前的可能会减少的运动员数量，在 mid 和 pre 有重合的情况下，减去 mid 和第二名运动员造成的影响。</li>\n<li><code>mid</code> ：表示第一名和第二名运动员之间的可能会减少的运动员数量。</li>\n<li><code>offset</code> ：表示第一名和第二名运动员之间一定会减少的运动员数量。</li>\n</ul>\n<p>接下来考虑第二名运动员的位置关系：</p>\n<ul>\n<li>如果  <code>sp &gt; (n + 1) / 2</code> ，说明第二名运动员在后半部分，我们通过计算  <code>tmp</code>  来获取第二名运动员的对称之后，在前半部分的位置，即相当于将两名运动员放在同一侧进行比较，来获取我们需要的这几个变量。</li>\n<li>如果  <code>sp &lt;= (n + 1) / 2</code> ，说明第二名运动员在前半部分，我们直接计算  <code>mid</code>  和  <code>pre</code>  的值。</li>\n</ul>\n<p>接下来，我们需要遍历所有可能的  <code>i</code>  和  <code>j</code> ，来确定下一回合所有可能的运动员组合。对于每一对  <code>(i, j)</code> ，我们需要计算出下一回合的第一名和第二名运动员的编号，并递归调用  <code>dfs</code>  函数。<br />\n如果  <code>n - sp + 1 &lt; fp</code> ，说明  <code>mid</code>  和  <code>pre</code>  有重合的情况，我们需要减去  <code>mid</code>  和第二名运动员造成的影响。</p>\n<p>这里的代码可以修改成没有最后一个参数  <code>is_er</code> ，直接返回最早和最晚回合数的结果。但是博主不想改了😵。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"type\">int</span> ans[<span class=\"number\">29</span>][<span class=\"number\">29</span>][<span class=\"number\">29</span>][<span class=\"number\">2</span>] = &#123;<span class=\"number\">0</span>&#125;;</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"type\">int</span> fp, <span class=\"type\">int</span> sp, <span class=\"type\">int</span> n, <span class=\"type\">bool</span> is_er)</span></span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> &amp; res = ans[fp][sp][n][is_er];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (res) <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (n - sp + <span class=\"number\">1</span> == fp) <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (fp &gt; n / <span class=\"number\">2</span>)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"built_in\">dfs</span>(<span class=\"built_in\">min</span>(n - fp + <span class=\"number\">1</span>, n - sp + <span class=\"number\">1</span>), <span class=\"built_in\">max</span>(n - sp + <span class=\"number\">1</span>, n - fp + <span class=\"number\">1</span>), n, is_er);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"type\">int</span> pre, mid,offset = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (sp &gt; (n + <span class=\"number\">1</span>) / <span class=\"number\">2</span>) &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> tmp = n - sp + <span class=\"number\">1</span>;</span><br><span class=\"line\">            offset = n/<span class=\"number\">2</span> - <span class=\"built_in\">max</span>(fp,tmp) + <span class=\"number\">1</span>;</span><br><span class=\"line\">            mid = <span class=\"built_in\">abs</span>(fp-tmp) - <span class=\"number\">1</span>;</span><br><span class=\"line\">            pre = <span class=\"built_in\">min</span>(fp,tmp) - <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            mid = sp - fp - <span class=\"number\">1</span>;</span><br><span class=\"line\">            pre = fp<span class=\"number\">-1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"type\">int</span> e = <span class=\"number\">30</span>, l = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt;= pre; i++)&#123;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt;= mid; j++)&#123;</span><br><span class=\"line\">                <span class=\"type\">int</span> tmp = <span class=\"number\">0</span>;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (n - sp + <span class=\"number\">1</span> &lt; fp)&#123;</span><br><span class=\"line\">                    tmp = <span class=\"built_in\">dfs</span>(fp - i - <span class=\"number\">1</span> - mid + j, sp - mid - offset - i - <span class=\"number\">1</span>, (n<span class=\"number\">+1</span>)/<span class=\"number\">2</span>, is_er);</span><br><span class=\"line\">                &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                    tmp = <span class=\"built_in\">dfs</span>(fp - i, sp - j - offset - i, (n + <span class=\"number\">1</span>)/<span class=\"number\">2</span>, is_er);</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">                e = <span class=\"built_in\">min</span>(e, tmp);</span><br><span class=\"line\">                l = <span class=\"built_in\">max</span>(l, tmp);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (is_er) res =  e + <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> res = l + <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">earliestAndLatest</span><span class=\"params\">(<span class=\"type\">int</span> n, <span class=\"type\">int</span> firstPlayer, <span class=\"type\">int</span> secondPlayer)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> &#123;<span class=\"built_in\">dfs</span>(firstPlayer,secondPlayer,n,<span class=\"number\">1</span>),<span class=\"built_in\">dfs</span>(firstPlayer,secondPlayer,n,<span class=\"number\">0</span>)&#125;;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "深度优先搜索",
                "状态压缩",
                "记忆化搜索"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3169-%E6%97%A0%E9%9C%80%E5%BC%80%E4%BC%9A%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%97%A5/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3169-%E6%97%A0%E9%9C%80%E5%BC%80%E4%BC%9A%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%97%A5/",
            "title": "力扣每日一题：3169. 无需开会的工作日",
            "date_published": "2025-07-10T19:46:53.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9jb3VudC1kYXlzLXdpdGhvdXQtbWVldGluZ3M/ZW52VHlwZT1kYWlseS1xdWVzdGlvbiZhbXA7ZW52SWQ9MjAyNS0wNy0xMQ==\">LeetCode 3169</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个正整数  <code>days</code> ，表示员工可工作的总天数（从第 1 天开始）。另给你一个二维数组  <code>meetings</code> ，长度为 n，其中  <code>meetings[i] = [start_i, end_i]</code>  表示第 i 次会议的开始和结束天数（包含首尾）。</p>\n<p>返回员工可工作且没有安排会议的天数。</p>\n<p>注意：会议时间可能会有重叠。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>我们要求员工的空闲时间，因为会议是顺序发生的，因此空闲时间一定产生在时间相邻的会议之间，所以首先根据会议的开始时间排序，除了第一个会议前的空闲时间，后续会议之间的空闲时间可以通过比较前面所有会议的结束时间最大值（即需要等待前面开始的会议都结束，若该会议还没开始，才会有空闲时间）和当前会议的开始时间来计算。最后还需要考虑最后一个结束的会议结束后的空闲时间。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">countDays</span><span class=\"params\">(<span class=\"type\">int</span> days, vector&lt;vector&lt;<span class=\"type\">int</span>&gt;&gt;&amp; meetings)</span> </span>&#123;</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(meetings);</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        ans += meetings[<span class=\"number\">0</span>][<span class=\"number\">0</span>] - <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = meetings.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        <span class=\"type\">int</span> pre_max = meetings[<span class=\"number\">0</span>][<span class=\"number\">1</span>];</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; n; i++) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (pre_max &lt; meetings[i][<span class=\"number\">0</span>]) ans += meetings[i][<span class=\"number\">0</span>] - pre_max - <span class=\"number\">1</span>;</span><br><span class=\"line\">            pre_max = <span class=\"built_in\">max</span>(pre_max, meetings[i][<span class=\"number\">1</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        ans += days - pre_max;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "排序"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3440-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-II/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3440-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-II/",
            "title": "力扣每日一题：3440. 重新安排会议得到最多空余时间 II",
            "date_published": "2025-07-09T18:05:41.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9yZXNjaGVkdWxlLW1lZXRpbmdzLWZvci1tYXhpbXVtLWZyZWUtdGltZS1paT9lbnZUeXBlPWRhaWx5LXF1ZXN0aW9uJmFtcDtlbnZJZD0yMDI1LTA3LTEw\">LeetCode 3440</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个整数  <code>eventTime</code>  表示一个活动的总时长，这个活动开始于  <code>t = 0</code>  ，结束于  <code>t = eventTime</code>  。</p>\n<p>同时给你两个长度为  <code>n</code>  的整数数组  <code>startTime</code>  和  <code>endTime</code>  。它们表示这次活动中  <code>n</code>  个时间 没有重叠 的会议，其中第  <code>i</code>  个会议的时间为  <code>[startTime[i], endTime[i]]</code>  。</p>\n<p>你可以重新安排 至多 一个会议，安排的规则是将会议时间平移，且保持原来的 会议时长 ，你的目的是移动会议后 最大化 相邻两个会议之间的 最长 连续空余时间。</p>\n<p>请你返回重新安排会议以后，可以得到的 最大 空余时间。</p>\n<p>注意，会议 不能 安排到整个活动的时间以外，且会议之间需要保持互不重叠。</p>\n<p>注意：重新安排会议以后，会议之间的顺序可以发生改变。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>只能安排一个会议，不考虑顺序，因此只有两种情况：（设该会议时间为 tmp，会议前后空闲时间分别为 f1 和 f2）<br />\n1. 除了该会议前后的空闲时间之外，还有空闲时间可以安排该会议，则通过调整该会议能得到的空闲时间为 f1 + tmp + f2<br />\n2. 没有其他空闲时间可以安排，只能在该会议前后进行调整，得到的空闲时间为 f1 + f2<br />\n 最终结果则为所有情况的最大值。<br />\n而解决问题的关键在于判断是否存在其他空闲时间可以不按顺序安排该会议，我的解决思路是使用一个 map 来记录每个空闲时间的出现次数。然后进行遍历，计算每个会议前后的空闲时间，并更新 map 中的空闲时间计数。使用  <code>lower_bound</code>  函数来判断是否存在其他空闲时间可以安排该会议。</p>\n<div class=\"note info\">\n<p>还有一个效率更好的实现方法是，通过使用前缀后缀最大值来记录每个会议前后的最大空闲时间，从而避免使用 map 进行频繁的插入和删除操作。</p>\n</div>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maxFreeTime</span><span class=\"params\">(<span class=\"type\">int</span> eventTime, vector&lt;<span class=\"type\">int</span>&gt;&amp; startTime, vector&lt;<span class=\"type\">int</span>&gt;&amp; endTime)</span> </span>&#123;</span><br><span class=\"line\">        map&lt;<span class=\"type\">int</span>,<span class=\"type\">int</span>&gt; free_cnt;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = startTime.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        free_cnt[startTime[<span class=\"number\">0</span>]]++;</span><br><span class=\"line\">        free_cnt[eventTime-endTime[n<span class=\"number\">-1</span>]]++;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>;i&lt;n<span class=\"number\">-1</span>;i++)&#123;</span><br><span class=\"line\">            free_cnt[startTime[i<span class=\"number\">+1</span>]-endTime[i]]++;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> f1,f2;</span><br><span class=\"line\">        f2 = startTime[<span class=\"number\">0</span>];</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> map_del = [&amp;](<span class=\"type\">int</span> val)&#123;</span><br><span class=\"line\">            free_cnt[val]--;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (free_cnt[val] == <span class=\"number\">0</span>) free_cnt.<span class=\"built_in\">erase</span>(val);</span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> solve = [&amp;](<span class=\"type\">int</span> st, <span class=\"type\">int</span> et, <span class=\"type\">int</span> tmp)&#123;</span><br><span class=\"line\">            f1 = f2;</span><br><span class=\"line\">            f2 = st - et;</span><br><span class=\"line\">            <span class=\"built_in\">map_del</span>(f1), <span class=\"built_in\">map_del</span>(f2);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (free_cnt.<span class=\"built_in\">lower_bound</span>(tmp) != free_cnt.<span class=\"built_in\">end</span>())&#123;</span><br><span class=\"line\">                ans = <span class=\"built_in\">max</span>(ans, f1 + tmp + f2);</span><br><span class=\"line\">            &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">                ans = <span class=\"built_in\">max</span>(ans, f1 + f2);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            free_cnt[f1]++, free_cnt[f2]++;</span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i++)&#123;</span><br><span class=\"line\">            <span class=\"built_in\">solve</span>(startTime[i<span class=\"number\">+1</span>], endTime[i], endTime[i]-startTime[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"built_in\">solve</span>(eventTime,endTime[n<span class=\"number\">-1</span>], endTime[n<span class=\"number\">-1</span>]-startTime[n<span class=\"number\">-1</span>]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "枚举"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/",
            "title": "卷积神经网络CNN",
            "date_published": "2025-07-09T11:22:34.000Z",
            "content_html": "<h1 id=\"卷积神经网络基础概念\"><a class=\"anchor\" href=\"#卷积神经网络基础概念\">#</a> 卷积神经网络基础概念</h1>\n<p>** 卷积神经网络（Convolutional Neural Network, CNN）** 是一种专门用于处理具有网格状拓扑结构数据的深度学习架构，在<ins class=\"dot\">图像分类</ins>、目标检测、图像分割等计算机视觉任务中表现卓越。</p>\n<details class=\"info\"><summary>关键概念：Tensor</summary><div>\n<p>**Tensor（张量）** 是 CNN 中数据的基本表示形式，可以理解为多维数组：</p>\n<ul>\n<li><strong>0 维张量</strong>：标量（单个数值）</li>\n<li><strong>1 维张量</strong>：向量（一维数组）</li>\n<li><strong>2 维张量</strong>：矩阵（二维数组）</li>\n<li><strong>3 维张量</strong>：如 RGB 图像（高度 × 宽度 × 通道数）</li>\n<li><strong>4 维张量</strong>：批量图像数据（批量大小 × 高度 × 宽度 × 通道数）</li>\n</ul>\n<p>在 CNN 中，图像通常表示为 3 维张量，其中包含<strong>高度（Height）</strong>、** 宽度（Width）<strong>和</strong>颜色通道（Color Channels）** 三个维度。</p>\n</div></details>\n<h2 id=\"传统全连接网络的局限性\"><a class=\"anchor\" href=\"#传统全连接网络的局限性\">#</a> 传统全连接网络的局限性</h2>\n<p>传统的神经网络在处理图像时存在显著问题。以一张 100×100 像素的 RGB 彩色图像为例：</p>\n<ul>\n<li>图像维度：100 × 100 × 3 = 30,000 个像素值</li>\n<li>如果使用 1000 个神经元的全连接层：需要 30,000 × 1000 = <strong>3×10^7 个权重参数</strong></li>\n</ul>\n<div class=\"note warning no-icon\">\n<p>参数量过多导致：</p>\n<ol>\n<li><strong>过拟合风险</strong>：模型容易记住训练数据而非学习特征</li>\n<li><strong>计算复杂度高</strong>：训练和推理速度慢</li>\n<li><strong>内存占用大</strong>：存储和加载模型困难</li>\n</ol>\n</div>\n<p>更重要的是，图像具有<strong>空间局部性</strong>特征 —— 相邻像素通常高度相关，而全连接网络无法有效利用这种空间结构信息。</p>\n<h1 id=\"cnn的核心思想感受野与参数共享\"><a class=\"anchor\" href=\"#cnn的核心思想感受野与参数共享\">#</a> CNN 的核心思想：感受野与参数共享</h1>\n<h2 id=\"感受野机制\"><a class=\"anchor\" href=\"#感受野机制\">#</a> 感受野机制</h2>\n<p>CNN 的突破性创新在于引入了<ins class=\"dot\">感受野</ins>（Receptive Field）概念，让每个神经元只关注图像的局部区域。</p>\n<details class=\"success\"><summary>感受野详解</summary><div>\n<p>** 感受野（Receptive Field）** 是指神经网络中某个神经元能够 &quot;看到&quot; 的输入区域范围。在 CNN 中：</p>\n<ul>\n<li><strong>局部连接</strong>：每个神经元只与输入的一个小区域相连</li>\n<li><strong>重叠覆盖</strong>：不同神经元的感受野可以重叠，确保信息不丢失</li>\n<li><strong>多神经元协作</strong>：多个神经元可以负责同一个感受野，提取不同特征</li>\n<li><strong>逐层扩大</strong>：随着网络深度增加，后层神经元的有效感受野逐渐扩大</li>\n</ul>\n<p>经典设置：感受野大小通常为 3×3 或 5×5，考虑所有颜色通道。</p>\n</div></details>\n<div class=\"note info no-icon\">\n<p>实际上，我们<ins class=\"dot\">只需要图像的部分特征就可以进行有效识别</ins>，比如识别猫咪时，我们主要关注耳朵、眼睛、胡须等局部特征，而不需要分析整张图片的每个像素。</p>\n</div>\n<h2 id=\"参数共享策略\"><a class=\"anchor\" href=\"#参数共享策略\">#</a> 参数共享策略</h2>\n<p>CNN 的第二个关键创新是<strong>参数共享</strong>：不同位置的感受野使用相同的权重参数。</p>\n<figure class=\"highlight python\"><figcaption><span>参数共享示例</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 传统全连接：每个连接都有独立参数</span></span><br><span class=\"line\">w1, w2, w3, ..., w_n  <span class=\"comment\"># n个不同的权重</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># CNN卷积：所有位置共享同一组参数  </span></span><br><span class=\"line\">w_shared = [w1, w2, w3, ..., w_k]  <span class=\"comment\"># 只有k个权重（k &lt;&lt; n）</span></span><br><span class=\"line\"><span class=\"comment\"># 这组权重在所有感受野位置重复使用</span></span><br></pre></td></tr></table></figure>\n<p><strong>为什么可以共享参数？</strong></p>\n<p>不同位置要检测的基本模式是相同的 —— 边缘、角点、纹理等特征在图像的任何位置都可能出现，因此使用相同的参数是合理的。</p>\n<h1 id=\"卷积层cnn的核心组件\"><a class=\"anchor\" href=\"#卷积层cnn的核心组件\">#</a> 卷积层：CNN 的核心组件</h1>\n<p><strong>卷积层 = 感受野 + 参数共享</strong></p>\n<details class=\"info\"><summary>卷积核详解</summary><div>\n<p>** 卷积核（Filter/Kernel）** 是 CNN 中的特征检测器：</p>\n<ul>\n<li><strong>结构</strong>：通常为 3×3、5×5 或 7×7 的小矩阵</li>\n<li><strong>功能</strong>：检测特定的图像特征（如边缘、角点、纹理）</li>\n<li><strong>参数</strong>：卷积核中的数值就是需要学习的权重参数</li>\n<li><strong>数量</strong>：一个卷积层通常包含多个卷积核，每个检测不同类型的特征</li>\n<li><strong>深度</strong>：卷积核的深度必须等于输入数据的通道数</li>\n</ul>\n</div></details>\n<h2 id=\"卷积操作过程\"><a class=\"anchor\" href=\"#卷积操作过程\">#</a> 卷积操作过程</h2>\n<ol>\n<li><strong>扫描过程</strong>：卷积核以指定的步长（stride）在输入图像上滑动</li>\n<li><strong>特征提取</strong>：在每个位置进行元素相乘并求和</li>\n<li><strong>生成特征图</strong>：每个卷积核扫过整张图后，生成一张<strong>特征图（Feature Map）</strong></li>\n</ol>\n<details class=\"warning\"><summary>步长设置</summary><div>\n<p>** 步长（Stride）** 控制卷积核的移动距离：</p>\n<ul>\n<li><strong>stride = 1</strong>：卷积核每次移动 1 个像素，特征图尺寸较大，信息保留更完整</li>\n<li><strong>stride = 2</strong>：卷积核每次移动 2 个像素，特征图尺寸缩小一半，计算更高效</li>\n</ul>\n<p>经典设置通常使用 stride = 1 或 2。当卷积核移动超出图像边界时，可以使用 ** 填充（Padding）** 来处理边界问题。</p>\n</div></details>\n<h2 id=\"多层卷积的层次化特征学习\"><a class=\"anchor\" href=\"#多层卷积的层次化特征学习\">#</a> 多层卷积的层次化特征学习</h2>\n<figure class=\"highlight python\"><figcaption><span>卷积层级示例</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 第一层卷积：检测基础特征</span></span><br><span class=\"line\">input_shape: (H, W, <span class=\"number\">3</span>)      <span class=\"comment\"># 原始RGB图像</span></span><br><span class=\"line\">filter_1: <span class=\"number\">32</span>个<span class=\"number\">3</span>×<span class=\"number\">3</span>×<span class=\"number\">3</span>卷积核    <span class=\"comment\"># 输出32个特征图</span></span><br><span class=\"line\">output_1: (H<span class=\"string\">&#x27;, W&#x27;</span>, <span class=\"number\">32</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 第二层卷积：组合基础特征  </span></span><br><span class=\"line\">filter_2: <span class=\"number\">64</span>个<span class=\"number\">3</span>×<span class=\"number\">3</span>×<span class=\"number\">32</span>卷积核   <span class=\"comment\"># 处理32个输入通道</span></span><br><span class=\"line\">output_2: (H<span class=\"string\">&#x27;&#x27;</span>, W<span class=\"string\">&#x27;&#x27;</span>, <span class=\"number\">64</span>)    <span class=\"comment\"># 输出64个更复杂的特征图</span></span><br></pre></td></tr></table></figure>\n<div class=\"note success no-icon\">\n<p><strong>层次化特征学习</strong>：</p>\n<ul>\n<li><strong>浅层</strong>：检测边缘、角点等基础特征</li>\n<li><strong>中层</strong>：组合基础特征形成纹理、形状</li>\n<li><strong>深层</strong>：形成高级语义特征，如物体部分</li>\n</ul>\n</div>\n<h1 id=\"池化层降维与抗干扰\"><a class=\"anchor\" href=\"#池化层降维与抗干扰\">#</a> 池化层：降维与抗干扰</h1>\n<p>在卷积层之后，通常会添加 ** 池化层（Pooling Layer）** 来减少特征图的空间维度。</p>\n<details class=\"primary\"><summary>最大池化详解</summary><div>\n<p>** 最大池化（Max Pooling）** 是最常用的池化操作：</p>\n<ul>\n<li><strong>操作</strong>：在指定区域内选择最大值作为输出</li>\n<li><strong>窗口大小</strong>：通常为 2×2 或 3×3</li>\n<li><strong>效果</strong>：\n<ul>\n<li>减少参数数量和计算量</li>\n<li>提供平移不变性（轻微位移不影响结果）</li>\n<li>保留最显著的特征信息</li>\n</ul>\n</li>\n</ul>\n<p><strong>示例</strong>：2×2 最大池化将 4 个值缩减为 1 个值，特征图尺寸减半。</p>\n</div></details>\n<figure class=\"highlight python\"><figcaption><span>池化层示例 mark:3</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2×2最大池化，步长为2</span></span><br><span class=\"line\">max_pool = nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)</span><br><span class=\"line\"><span class=\"comment\"># 输入: (batch_size, channels, 28, 28)</span></span><br><span class=\"line\"><span class=\"comment\"># 输出: (batch_size, channels, 14, 14)</span></span><br></pre></td></tr></table></figure>\n<div class=\"note warning no-icon\">\n<p>池化操作的权衡：</p>\n<ul>\n<li><strong>优点</strong>：减少计算量，增强鲁棒性</li>\n<li><strong>缺点</strong>：会丢失部分空间信息和精度</li>\n</ul>\n</div>\n<h1 id=\"cnn完整架构流程\"><a class=\"anchor\" href=\"#cnn完整架构流程\">#</a> CNN 完整架构流程</h1>\n<h2 id=\"标准cnn工作流程\"><a class=\"anchor\" href=\"#标准cnn工作流程\">#</a> 标准 CNN 工作流程</h2>\n<figure class=\"highlight python\"><figcaption><span>CNN完整流程 mark:5,10,15</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. 输入层</span></span><br><span class=\"line\">input_image = torch.randn(<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">224</span>, <span class=\"number\">224</span>)  <span class=\"comment\"># RGB图像</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2. 卷积 + 池化模块（可重复多次）</span></span><br><span class=\"line\">conv1 = nn.Conv2d(<span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)     <span class=\"comment\"># 第一个卷积层</span></span><br><span class=\"line\">pool1 = nn.MaxPool2d(<span class=\"number\">2</span>, <span class=\"number\">2</span>)                 <span class=\"comment\"># 第一个池化层</span></span><br><span class=\"line\">conv2 = nn.Conv2d(<span class=\"number\">32</span>, <span class=\"number\">64</span>, <span class=\"number\">3</span>, padding=<span class=\"number\">1</span>)    <span class=\"comment\"># 第二个卷积层  </span></span><br><span class=\"line\">pool2 = nn.MaxPool2d(<span class=\"number\">2</span>, <span class=\"number\">2</span>)                 <span class=\"comment\"># 第二个池化层</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 3. 展平层（Flatten）</span></span><br><span class=\"line\">flatten = nn.Flatten()                      <span class=\"comment\"># 将3D特征图拉直为1D向量</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 4. 全连接层</span></span><br><span class=\"line\">fc1 = nn.Linear(<span class=\"number\">64</span> * <span class=\"number\">56</span> * <span class=\"number\">56</span>, <span class=\"number\">512</span>)         <span class=\"comment\"># 第一个全连接层</span></span><br><span class=\"line\">fc2 = nn.Linear(<span class=\"number\">512</span>, <span class=\"number\">10</span>)                   <span class=\"comment\"># 输出层（如10分类）</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 5. 激活函数和最终输出</span></span><br><span class=\"line\">softmax = nn.Softmax(dim=<span class=\"number\">1</span>)                <span class=\"comment\"># 分类概率输出</span></span><br></pre></td></tr></table></figure>\n<details class=\"info\"><summary>展平操作详解</summary><div>\n<p>** 展平（Flatten）** 是连接卷积部分和全连接部分的关键步骤：</p>\n<ul>\n<li><strong>目的</strong>：将多维特征图转换为一维向量</li>\n<li><strong>过程</strong>：将 (批量大小，通道数，高度，宽度) 的 4D 张量重塑为 (批量大小，特征数) 的 2D 张量</li>\n<li><strong>位置</strong>：通常放在最后一个池化层之后，第一个全连接层之前</li>\n</ul>\n<p><strong>示例</strong>：(32, 128, 7, 7) → (32, 6272)，其中 6272 = 128 × 7 × 7</p>\n</div></details>\n<h2 id=\"数据预处理one-hot编码\"><a class=\"anchor\" href=\"#数据预处理one-hot编码\">#</a> 数据预处理：One-Hot 编码</h2>\n<p>在分类任务中，CNN 通常使用<strong> One-Hot 编码</strong>来表示类别标签：</p>\n<figure class=\"highlight python\"><figcaption><span>One-Hot编码示例</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 原始标签（如10类分类）</span></span><br><span class=\"line\">label = <span class=\"number\">3</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># One-Hot编码</span></span><br><span class=\"line\">one_hot = [<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\">#          类别: 0  1  2  3  4  5  6  7  8  9</span></span><br></pre></td></tr></table></figure>\n<div class=\"note info no-icon\">\n<p>One-Hot 编码的优势：</p>\n<ul>\n<li>避免类别间的大小关系假设</li>\n<li>便于计算交叉熵损失函数</li>\n<li>输出概率分布更加直观</li>\n</ul>\n</div>\n<h1 id=\"数据增强处理尺寸变化\"><a class=\"anchor\" href=\"#数据增强处理尺寸变化\">#</a> 数据增强：处理尺寸变化</h1>\n<p>CNN 对输入图像尺寸较为敏感，无法直接处理不同大小的图像。因此需要进行<strong>数据增强（Data Augmentation）</strong>。</p>\n<div class=\"tab\" data-id=\"augmentation\" data-title=\"常见数据增强技术\">\n<p><strong>几何变换</strong>：</p>\n<ul>\n<li>随机裁剪和缩放</li>\n<li>旋转和翻转</li>\n<li>平移和错切</li>\n</ul>\n<p><strong>颜色变换</strong>：</p>\n<ul>\n<li>亮度和对比度调整</li>\n<li>色相和饱和度变化</li>\n<li>随机擦除部分区域</li>\n</ul>\n</div>\n<div class=\"tab\" data-id=\"benefits\" data-title=\"数据增强的作用\">\n<p><strong>提升模型泛化能力</strong>：</p>\n<ul>\n<li>增加训练数据的多样性</li>\n<li>减少过拟合风险</li>\n<li>提高对图像变化的鲁棒性</li>\n</ul>\n<p><strong>统一输入格式</strong>：</p>\n<ul>\n<li>将不同尺寸图像调整为固定大小</li>\n<li>保持模型架构的一致性</li>\n</ul>\n</div>\n<figure class=\"highlight python\"><figcaption><span>数据增强代码示例 mark:2-4</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> transforms</span><br><span class=\"line\"></span><br><span class=\"line\">transform = transforms.Compose([</span><br><span class=\"line\">    transforms.RandomResizedCrop(<span class=\"number\">224</span>),      <span class=\"comment\"># 随机裁剪到224×224</span></span><br><span class=\"line\">    transforms.RandomHorizontalFlip(),      <span class=\"comment\"># 随机水平翻转</span></span><br><span class=\"line\">    transforms.ColorJitter(<span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>, <span class=\"number\">0.1</span>), <span class=\"comment\"># 颜色抖动</span></span><br><span class=\"line\">    transforms.ToTensor(),                  <span class=\"comment\"># 转换为张量</span></span><br><span class=\"line\">    transforms.Normalize([<span class=\"number\">0.485</span>, <span class=\"number\">0.456</span>, <span class=\"number\">0.406</span>], </span><br><span class=\"line\">                        [<span class=\"number\">0.229</span>, <span class=\"number\">0.224</span>, <span class=\"number\">0.225</span>]) <span class=\"comment\"># 标准化</span></span><br><span class=\"line\">])</span><br></pre></td></tr></table></figure>\n<h1 id=\"cnn的优势与应用\"><a class=\"anchor\" href=\"#cnn的优势与应用\">#</a> CNN 的优势与应用</h1>\n<p>CNN 相比传统方法具有以下显著优势：</p>\n<ul class=\"task-list success\">\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"cbx_0\" checked=\"true\" disabled=\"true\" /><label for=\"cbx_0\"> <strong>参数效率</strong>：通过参数共享大幅减少模型参数</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"cbx_1\" checked=\"true\" disabled=\"true\" /><label for=\"cbx_1\"> <strong>空间不变性</strong>：对图像中物体的位置变化具有鲁棒性</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"cbx_2\" checked=\"true\" disabled=\"true\" /><label for=\"cbx_2\"> <strong>层次化特征学习</strong>：自动学习从低级到高级的特征表示</label></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" id=\"cbx_3\" checked=\"true\" disabled=\"true\" /><label for=\"cbx_3\"> <strong>端到端训练</strong>：可以直接从原始像素学习到最终分类结果</label></li>\n</ul>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "深度学习",
                "CNN",
                "卷积神经网络",
                "图像识别",
                "计算机视觉",
                "特征提取",
                "池化"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/",
            "title": "批量归一化",
            "date_published": "2025-07-09T06:17:30.000Z",
            "content_html": "<h1 id=\"批量归一化-batch-normalization\"><a class=\"anchor\" href=\"#批量归一化-batch-normalization\">#</a> 批量归一化 (Batch Normalization)</h1>\n<p>批量归一化是深度学习中的一项重要技术，通过对网络中间层的输入进行归一化处理，有效解决了深度神经网络训练中的诸多问题。本文将深入探讨批量归一化的原理、实现方法以及在实际应用中的考虑因素。</p>\n<h2 id=\"特征归一化的必要性\"><a class=\"anchor\" href=\"#特征归一化的必要性\">#</a> 特征归一化的必要性</h2>\n<p>在深度学习模型中，不同特征维度的数值范围往往存在显著差异。这种差异会导致一个严重的问题：<strong>范围变化小的特征对模型结果影响较小，而范围变化大的特征对结果影响过大</strong>。</p>\n<details class=\"info\"><summary>特征归一化详解</summary><div>\n<p>特征归一化 (Feature Normalization) 是机器学习预处理中的关键步骤，其目的是将不同量纲和数值范围的特征统一到相同的尺度上。</p>\n<p><strong>为什么需要特征归一化？</strong></p>\n<ol>\n<li><strong>避免特征偏倚</strong>：数值范围大的特征会主导模型的学习过程</li>\n<li><strong>加速收敛</strong>：归一化后的特征使得梯度下降更加稳定和快速</li>\n<li><strong>提高数值稳定性</strong>：防止因数值过大或过小导致的计算问题</li>\n</ol>\n<p><strong>常见的归一化方法</strong>:</p>\n<ul>\n<li><strong>标准化 (Z-score)</strong>: 将数据转换为均值为 0，标准差为 1 的分布</li>\n<li><strong>最小 - 最大归一化</strong>：将数据缩放到 [0,1] 区间</li>\n<li><strong>鲁棒归一化</strong>：使用中位数和四分位数进行归一化，对异常值更加鲁棒</li>\n</ul>\n</div></details>\n<div class=\"note info\">\n<p>解决方案：对于每一个特征维度，分别求其平均值和标准差，然后进行标准化处理。</p>\n</div>\n<p>标准化的数学表达式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mover accent=\"true\"><mi>x</mi><mo>~</mo></mover><mi>i</mi><mi>r</mi></msubsup><mo>=</mo><mfrac><mrow><msubsup><mi>x</mi><mi>i</mi><mi>r</mi></msubsup><mo>−</mo><msub><mi>μ</mi><mi>i</mi></msub></mrow><msub><mi>σ</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding=\"application/x-tex\">\\tilde{x}^r_i = \\frac{x^r_i - \\mu_i}{\\sigma_i}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9613919999999999em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7143919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.177392em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.341392em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-2.441336em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>x</mi><mi>i</mi><mi>r</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">x^r_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.923056em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-2.441336em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 是第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>r</mi></mrow><annotation encoding=\"application/x-tex\">r</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span></span></span></span> 个样本在第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个特征维度上的原始值</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>μ</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个特征维度的均值</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>σ</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\sigma_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个特征维度的标准差</li>\n</ul>\n<details class=\"warning\"><summary>标准差详解</summary><div>\n<p>标准差 (Standard Deviation) 是衡量数据分散程度的重要统计量，用符号 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> 表示。</p>\n<p><strong>数学定义</strong>:</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>σ</mi><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\mu)^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.1568160000000005em;vertical-align:-1.277669em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8791470000000006em;\"><span class=\"svg-align\" style=\"top:-5.116816em;\"><span class=\"pstrut\" style=\"height:5.116816em;\"></span><span class=\"mord\" style=\"padding-left:1.056em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">μ</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.8391470000000005em;\"><span class=\"pstrut\" style=\"height:5.116816em;\"></span><span class=\"hide-tail\" style=\"min-width:0.742em;height:3.196816em;\"><svg width='400em' height='3.196816em' viewBox='0 0 400000 3196' preserveAspectRatio='xMinYMin slice'><path d='M702 80H40000040\nH742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1\nh-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170\nc-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667\n219 661 l218 661zM702 80H400000v40H742z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>物理意义</strong>:</p>\n<ul>\n<li>标准差越小，数据越集中在均值附近</li>\n<li>标准差越大，数据越分散</li>\n<li>在归一化过程中，标准差用于调节缩放的幅度</li>\n</ul>\n<p><strong>在深度学习中的作用</strong>:</p>\n<ul>\n<li>通过标准差进行除法运算，使得各个特征的方差统一</li>\n<li>保证不同特征对模型的贡献相对平衡</li>\n</ul>\n</div></details>\n<h2 id=\"深度网络中的归一化挑战\"><a class=\"anchor\" href=\"#深度网络中的归一化挑战\">#</a> 深度网络中的归一化挑战</h2>\n<p>对于多层的深度学习网络，情况变得更加复杂。为了保证进入下一层前的输入范围不会产生太大变化，我们需要在网络的各个层次都进行标准化处理。</p>\n<p>这种标准化可以在<strong>激活函数之前或之后</strong>进行：</p>\n<div class=\"tab\" data-id=\"card1\" data-title=\"激活前归一化\">\n<p>在激活函数之前进行归一化：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 伪代码示例</span></span><br><span class=\"line\">z = linear_layer(x)</span><br><span class=\"line\">z_normalized = batch_norm(z)</span><br><span class=\"line\">output = activation(z_normalized)</span><br></pre></td></tr></table></figure>\n<p><strong>优点</strong>:</p>\n<ul>\n<li>确保激活函数接收到标准化的输入</li>\n<li>有利于激活函数工作在最佳区间</li>\n</ul>\n</div>\n<div class=\"tab\" data-id=\"card1\" data-title=\"激活后归一化\">\n<p>在激活函数之后进行归一化：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 伪代码示例</span></span><br><span class=\"line\">z = linear_layer(x)</span><br><span class=\"line\">activated = activation(z)</span><br><span class=\"line\">output = batch_norm(activated)</span><br></pre></td></tr></table></figure>\n<p><strong>优点</strong>:</p>\n<ul>\n<li>直接标准化特征表示</li>\n<li>某些情况下可能更加稳定</li>\n</ul>\n</div>\n<div class=\"note warning\">\n<p>由于进行归一化时，平均值和标准差会对所有输入对象产生影响，因此所有的输入数据实际上变成了一个相互关联的整体。</p>\n</div>\n<h2 id=\"内部协变量偏移问题\"><a class=\"anchor\" href=\"#内部协变量偏移问题\">#</a> 内部协变量偏移问题</h2>\n<details class=\"danger\"><summary>内部协变量偏移详解</summary><div>\n<p>内部协变量偏移 (Internal Covariate Shift) 是深度学习中的一个核心问题，由 Google 的研究团队在批量归一化论文中提出。</p>\n<p><strong>什么是协变量偏移？</strong><br />\n协变量偏移指的是输入数据分布的改变。在深度网络中，由于前面层的参数更新，每一层的输入分布都会发生变化。</p>\n<p><strong>内部协变量偏移的影响</strong>:</p>\n<ol>\n<li><strong>训练速度变慢</strong>：每层都需要适应新的输入分布</li>\n<li><strong>梯度消失 / 爆炸</strong>：分布变化可能导致梯度传播问题</li>\n<li><strong>参数初始化敏感</strong>：对初始化方法要求更高</li>\n<li><strong>学习率限制</strong>：需要使用较小的学习率以保证稳定性</li>\n</ol>\n<p><strong>批量归一化的解决思路</strong>:<br />\n 通过在每一层强制输入保持相对稳定的分布（均值为 0，方差为 1），减少内部协变量偏移的影响。</p>\n</div></details>\n<h2 id=\"批量归一化的实现\"><a class=\"anchor\" href=\"#批量归一化的实现\">#</a> 批量归一化的实现</h2>\n<h3 id=\"基本原理\"><a class=\"anchor\" href=\"#基本原理\">#</a> 基本原理</h3>\n<p>但是，直接处理所有输入数据在计算上是不现实的。我们无法一次性输入所有数据进行处理，因此需要将输入分为多个 batch（批次），在每个 batch 内部进行归一化处理。</p>\n<p>批量归一化的数学表达式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mover accent=\"true\"><mi>z</mi><mo>~</mo></mover><mi>i</mi></msup><mo>=</mo><mfrac><mrow><msup><mi>z</mi><mi>i</mi></msup><mo>−</mo><mi>μ</mi></mrow><mi>σ</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">\\tilde{z}^i = \\frac{z^i - \\mu}{\\sigma}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8746639999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.187664em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5016639999999999em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.824664em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>μ</mi></mrow><annotation encoding=\"application/x-tex\">\\mu</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">μ</span></span></span></span> 和 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span></span></span></span> 是当前 batch 内的均值和标准差。</p>\n<div class=\"note info\">\n<p>批量归一化适用于 batch size 较大的情况。当 batch size 过小时，批内统计量不够稳定，归一化效果会大打折扣。</p>\n</div>\n<h3 id=\"可学习参数的引入\"><a class=\"anchor\" href=\"#可学习参数的引入\">#</a> 可学习参数的引入</h3>\n<p>为了保持模型的表达能力，批量归一化引入了两个可学习参数：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msup><mover accent=\"true\"><mi>z</mi><mo>^</mo></mover><mi>i</mi></msup><mo>=</mo><mi>γ</mi><mo>⊙</mo><msup><mover accent=\"true\"><mi>z</mi><mo>~</mo></mover><mi>i</mi></msup><mo>+</mo><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\hat{z}^i = \\gamma \\odot \\tilde{z}^i + \\beta\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8746639999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⊙</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9579939999999999em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6678599999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span><span style=\"top:-3.35em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">~</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8746639999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>γ</mi></mrow><annotation encoding=\"application/x-tex\">\\gamma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span></span></span></span> 是缩放参数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span></span></span></span> 是偏移参数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding=\"application/x-tex\">\\odot</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">⊙</span></span></span></span> 表示逐元素乘法</li>\n</ul>\n<p>这两个参数允许网络学习到最适合当前层的数据分布。</p>\n<h2 id=\"测试时的处理策略\"><a class=\"anchor\" href=\"#测试时的处理策略\">#</a> 测试时的处理策略</h2>\n<p>在测试阶段，我们面临一个重要挑战：<strong>实际运行时无法保证有足够的输入数据来计算可靠的批统计量</strong>。</p>\n<p>解决方案是在训练过程中计算均值和标准差的<strong>移动平均值 (Moving Average)</strong>：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>μ</mi><mrow><mi>m</mi><mi>o</mi><mi>v</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>=</mo><mi>α</mi><mo>⋅</mo><msub><mi>μ</mi><mrow><mi>m</mi><mi>o</mi><mi>v</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>⋅</mo><msub><mi>μ</mi><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mu_{moving} = \\alpha \\cdot \\mu_{moving} + (1-\\alpha) \\cdot \\mu_{batch}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.44445em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msub><mi>σ</mi><mrow><mi>m</mi><mi>o</mi><mi>v</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>=</mo><mi>α</mi><mo>⋅</mo><msub><mi>σ</mi><mrow><mi>m</mi><mi>o</mi><mi>v</mi><mi>i</mi><mi>n</mi><mi>g</mi></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>⋅</mo><msub><mi>σ</mi><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\sigma_{moving} = \\alpha \\cdot \\sigma_{moving} + (1-\\alpha) \\cdot \\sigma_{batch}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.44445em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">b</span><span class=\"mord mathnormal mtight\">a</span><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">c</span><span class=\"mord mathnormal mtight\">h</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span> 是动量系数，通常设置为 0.9 或 0.99。</p>\n<h2 id=\"实际应用考虑\"><a class=\"anchor\" href=\"#实际应用考虑\">#</a> 实际应用考虑</h2>\n<h3 id=\"batch-size的影响\"><a class=\"anchor\" href=\"#batch-size的影响\">#</a> Batch Size 的影响</h3>\n<ul>\n<li><strong>大 Batch Size</strong>: 统计量更稳定，归一化效果更好</li>\n<li><strong>小 Batch Size</strong>: 可能导致训练不稳定，需要考虑其他归一化方法</li>\n</ul>\n<h3 id=\"替代方案\"><a class=\"anchor\" href=\"#替代方案\">#</a> 替代方案</h3>\n<p>当 batch size 过小时，可以考虑：</p>\n<ul>\n<li><strong>Layer Normalization</strong>: 在特征维度上进行归一化</li>\n<li><strong>Group Normalization</strong>: 将通道分组后进行归一化</li>\n<li><strong>Instance Normalization</strong>: 在每个实例上独立进行归一化</li>\n</ul>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "深度学习",
                "机器学习",
                "批量归一化",
                "特征归一化",
                "训练优化",
                "协变量偏移",
                "标准化"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/",
            "title": "从回归到分类：Softmax与交叉熵",
            "date_published": "2025-07-09T05:01:12.000Z",
            "content_html": "<h1 id=\"分类任务详解\"><a class=\"anchor\" href=\"#分类任务详解\">#</a> 分类任务详解</h1>\n<p>分类是机器学习中最基本也是最重要的任务之一。与回归任务预测连续值不同，分类任务的目标是将输入数据划分到不同的类别中。本文将深入探讨分类任务的核心概念、数学原理以及与回归任务的区别与联系。</p>\n<h2 id=\"从回归到分类的转换\"><a class=\"anchor\" href=\"#从回归到分类的转换\">#</a> 从回归到分类的转换</h2>\n<h3 id=\"分类作为回归问题\"><a class=\"anchor\" href=\"#分类作为回归问题\">#</a> 分类作为回归问题</h3>\n<p>在理解分类之前，我们可以从回归的角度思考分类问题。实际上，<ins class=\"dot\">分类可以看作是一种特殊的回归任务</ins>：</p>\n<p><strong>回归任务</strong>：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>⟷</mo><mi>y</mi><mo>=</mo><mi>b</mi><mo>+</mo><msup><mi>C</mi><mi>T</mi></msup><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>B</mi><mo>+</mo><mi>W</mi><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{y} \\longleftrightarrow y = b + C^T \\sigma(B + Wx)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⟷</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1413309999999999em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913309999999999em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><strong>分类任务</strong>：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>y</mi><mo>=</mo><msup><mi>b</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>+</mo><msup><mi>W</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>b</mi><mo>+</mo><mi>W</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>⟷</mo><msup><mi>y</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>=</mo><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y = b&#x27; + W&#x27; \\sigma(b + Wx), \\quad \\hat{y} \\longleftrightarrow y&#x27; = \\text{softmax}(y)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8852220000000001em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.051892em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⟷</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.996332em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>两者的主要区别在于输出层的处理方式和损失函数的选择。</p>\n<h3 id=\"类别表示one-hot-向量\"><a class=\"anchor\" href=\"#类别表示one-hot-向量\">#</a> 类别表示：One-Hot 向量</h3>\n<details class=\"info\"><summary>深入理解：One-Hot Vector</summary><div>\n<p>One-Hot 向量是一种稀疏的向量表示方法，用于表示分类问题中的类别标签。在一个 one-hot 向量中，只有一个位置为 1，其余位置均为 0。例如，在三分类问题中：</p>\n<ul>\n<li>类别 1：[1, 0, 0]</li>\n<li>类别 2：[0, 1, 0]</li>\n<li>类别 3：[0, 0, 1]</li>\n</ul>\n<p>One-hot 编码的优点：</p>\n<ol>\n<li>避免了类别之间的隐含顺序关系</li>\n<li>便于计算交叉熵损失</li>\n<li>适用于神经网络的输出层设计</li>\n<li>支持多分类问题的统一处理</li>\n</ol>\n<p>One-hot 编码的缺点：</p>\n<ol>\n<li>向量维度等于类别数量，可能造成维度灾难</li>\n<li>稀疏表示，存储效率较低</li>\n<li>无法表示类别之间的相似性关系</li>\n</ol>\n</div></details>\n<p>在分类任务中，我们需要将类别转换为数值表示。<strong>类别被表示为 one-hot 向量</strong>，这是分类问题的标准做法。</p>\n<h2 id=\"softmax-激活函数\"><a class=\"anchor\" href=\"#softmax-激活函数\">#</a> Softmax 激活函数</h2>\n<h3 id=\"softmax-函数的定义\"><a class=\"anchor\" href=\"#softmax-函数的定义\">#</a> Softmax 函数的定义</h3>\n<p>对于 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span></span></span></span> 分类问题，给定网络的输出向量 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">z</mi><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>z</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>z</mi><mi>K</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{z} = [z_1, z_2, ..., z_K]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44444em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>，softmax 函数将其转换为概率分布：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>softmax</mtext><mo stretchy=\"false\">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>z</mi><mi>i</mi></msub></msup><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mi>e</mi><msub><mi>z</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.648441em;vertical-align:-1.3070490000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.341392em;\"><span style=\"top:-2.128769em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6064620000000001em;\"><span style=\"top:-3.0050700000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2818857142857143em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.04398em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3070490000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n<details class=\"info\"><summary>深入理解：Softmax</summary><div>\n<p>Softmax 函数是 sigmoid 函数在多分类问题上的推广。它具有以下重要性质：</p>\n<ol>\n<li><strong>归一化</strong>：输出值的和为 1，可以解释为概率分布</li>\n<li><strong>单调性</strong>：保持原始值的相对大小关系</li>\n<li><strong>可微性</strong>：便于反向传播计算梯度</li>\n<li><strong>数值稳定性</strong>：通常需要减去最大值来避免指数爆炸</li>\n</ol>\n<p>Softmax 函数的核心思想是将任意实数向量转换为概率分布，使得每个输出值都在 (0,1) 范围内，且所有输出值的和为 1。这使得模型输出可以直接解释为各类别的概率。</p>\n</div></details>\n<h3 id=\"二分类的特殊情况\"><a class=\"anchor\" href=\"#二分类的特殊情况\">#</a> 二分类的特殊情况</h3>\n<div class=\"note info\">\n<p>在二分类问题中，softmax 函数与 sigmoid 函数是等价的。这是因为对于两个类别，softmax 退化为 sigmoid 的形式。</p>\n</div>\n<h2 id=\"交叉熵损失函数\"><a class=\"anchor\" href=\"#交叉熵损失函数\">#</a> 交叉熵损失函数</h2>\n<h3 id=\"分类损失的计算流程\"><a class=\"anchor\" href=\"#分类损失的计算流程\">#</a> 分类损失的计算流程</h3>\n<p>分类任务的损失计算遵循以下流程：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>⟷</mo><msup><mi>y</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup><mo>←</mo><mtext>softmax</mtext><mo>←</mo><mi>y</mi><mo>←</mo><mtext>network</mtext><mo>←</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">\\hat{y} \\longleftrightarrow y&#x27; \\leftarrow \\text{softmax} \\leftarrow y \\leftarrow \\text{network} \\leftarrow x\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⟷</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.996332em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.801892em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord text\"><span class=\"mord\">softmax</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord text\"><span class=\"mord\">network</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>：输入特征</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span>：网络原始输出</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>y</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msup></mrow><annotation encoding=\"application/x-tex\">y&#x27;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.946332em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span></span></span></span>：经过 softmax 处理的概率分布</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span>：真实标签的 one-hot 表示</li>\n</ul>\n<h3 id=\"交叉熵公式\"><a class=\"anchor\" href=\"#交叉熵公式\">#</a> 交叉熵公式</h3>\n<p>对于多分类问题，交叉熵损失函数定义为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>L</mi><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msubsup><mi>y</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L = -\\sum_{i=1}^{K} \\hat{y}_i \\log(y&#x27;_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.106005em;vertical-align:-1.277669em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.8283360000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8018919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\hat{y}_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 是真实标签的 one-hot 表示中第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个元素</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>y</mi><mi>i</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup></mrow><annotation encoding=\"application/x-tex\">y&#x27;_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.010556em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 是模型预测的第 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span> 个类别的概率</li>\n</ul>\n<details class=\"info\"><summary>深入理解：Cross-Entropy</summary><div>\n<p>交叉熵（Cross-Entropy）是信息论中的一个重要概念，用于衡量两个概率分布之间的差异。在分类任务中，交叉熵损失函数具有以下特点：</p>\n<ol>\n<li><strong>信息论基础</strong>：交叉熵衡量的是用预测分布来编码真实分布所需的平均信息量</li>\n<li><strong>概率解释</strong>：最小化交叉熵等价于最大化似然函数</li>\n<li><strong>梯度特性</strong>：在预测错误时提供更强的梯度信号</li>\n<li><strong>数值稳定性</strong>：与 softmax 结合使用时具有良好的数值性质</li>\n</ol>\n<p>交叉熵的数学表达式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mo separator=\"true\">,</mo><mi>q</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>i</mi></munder><msub><mi>p</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><msub><mi>q</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">H(p, q) = -\\sum_{i} p_i \\log(q_i)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.327674em;vertical-align:-1.277669em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0500050000000003em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\">p</span></span></span></span> 是真实分布，<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">q</span></span></span></span> 是预测分布。</p>\n</div></details>\n<h3 id=\"与极大似然的等价性\"><a class=\"anchor\" href=\"#与极大似然的等价性\">#</a> 与极大似然的等价性</h3>\n<div class=\"note success\">\n<p>最小化交叉熵等价于极大似然估计。这是因为交叉熵损失函数实际上是负对数似然函数，因此最小化交叉熵就是最大化似然函数。</p>\n</div>\n<h2 id=\"交叉熵-vs-均方误差\"><a class=\"anchor\" href=\"#交叉熵-vs-均方误差\">#</a> 交叉熵 vs 均方误差</h2>\n<h3 id=\"为什么交叉熵更适合分类\"><a class=\"anchor\" href=\"#为什么交叉熵更适合分类\">#</a> 为什么交叉熵更适合分类</h3>\n<details class=\"info\"><summary>深入理解：为什么交叉熵比MSE更适合分类</summary><div>\n<p>在分类任务中，交叉熵损失函数比均方误差（MSE）更为适合，主要原因如下：</p>\n<ol>\n<li>\n<p><strong>梯度特性差异</strong>：</p>\n<ul>\n<li>MSE：当损失很大时，梯度变得平坦，学习速度慢</li>\n<li>交叉熵：当预测错误时，梯度较为陡峭，学习速度快</li>\n</ul>\n</li>\n<li>\n<p><strong>概率解释</strong>：</p>\n<ul>\n<li>交叉熵直接对应于概率分布的负对数似然</li>\n<li>MSE 没有明确的概率解释</li>\n</ul>\n</li>\n<li>\n<p><strong>收敛性质</strong>：</p>\n<ul>\n<li>交叉熵在分类问题上通常收敛更快</li>\n<li>MSE 可能导致梯度消失问题</li>\n</ul>\n</li>\n<li>\n<p><strong>理论基础</strong>：</p>\n<ul>\n<li>交叉熵有坚实的信息论基础</li>\n<li>与最大似然估计原理一致</li>\n</ul>\n</li>\n</ol>\n</div></details>\n<p><strong>关键区别</strong>：</p>\n<ul>\n<li><strong>MSE 在 loss 大时平坦</strong>：当预测严重错误时，MSE 的梯度变小，导致学习缓慢</li>\n<li><strong>交叉熵则比较陡峭</strong>：即使在预测错误时，交叉熵仍能提供足够的梯度信号</li>\n</ul>\n<p>这种差异使得交叉熵在分类任务中具有更好的优化性质。</p>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "分类",
                "one-hot编码",
                "softmax",
                "交叉熵",
                "sigmoid",
                "极大似然"
            ]
        },
        {
            "id": "https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/",
            "url": "https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/",
            "title": "自适应学习率：从AdaGrad到Adam",
            "date_published": "2025-07-09T03:03:30.000Z",
            "content_html": "<h1 id=\"自适应学习率详解\"><a class=\"anchor\" href=\"#自适应学习率详解\">#</a> 自适应学习率详解</h1>\n<p>在深度学习的优化过程中，学习率的选择一直是一个关键问题。传统的固定学习率往往难以在所有参数和训练阶段都保持最优性能。本文将深入探讨自适应学习率的核心概念、算法原理及其在实际应用中的重要性。</p>\n<details class=\"info\"><summary>深入理解：Adaptive Learning Rate</summary><div>\n<p>自适应学习率（Adaptive Learning Rate）是指在训练过程中根据梯度信息、参数历史更新情况或其他启发式规则自动调整学习率的方法。与固定学习率相比，自适应学习率能够：</p>\n<ol>\n<li>为不同参数分配不同的学习率</li>\n<li>根据训练阶段动态调整更新幅度</li>\n<li>自动平衡收敛速度和稳定性</li>\n<li>减少人工调参的复杂性</li>\n</ol>\n</div></details>\n<h2 id=\"学习率的重要性与挑战\"><a class=\"anchor\" href=\"#学习率的重要性与挑战\">#</a> 学习率的重要性与挑战</h2>\n<h3 id=\"学习率大小的影响\"><a class=\"anchor\" href=\"#学习率大小的影响\">#</a> 学习率大小的影响</h3>\n<p>学习率的选择直接影响模型的收敛性能：</p>\n<ul>\n<li><strong>学习率过大</strong>：步子过大，每一次 update 太大，可能导致直接跳过理想的目标点，造成训练不稳定甚至发散</li>\n<li><strong>学习率过小</strong>：在某些方向上可能移动过于缓慢，导致收敛速度极慢，训练时间过长</li>\n</ul>\n<details class=\"info\"><summary>深入理解：Error Surface 误差表面</summary><div>\n<p>误差表面（Error Surface）是指在参数空间中，损失函数随参数变化形成的多维曲面。在深度学习中，这个表面通常具有复杂的非凸结构，存在多个局部最小值、鞍点和平坦区域。理解误差表面的特性对于设计有效的优化算法至关重要。</p>\n</div></details>\n<h3 id=\"梯度与学习率的关系\"><a class=\"anchor\" href=\"#梯度与学习率的关系\">#</a> 梯度与学习率的关系</h3>\n<p>自适应学习率的核心思想是根据梯度信息动态调整学习率：</p>\n<ul>\n<li><strong>坡度小，g 就小，学习率就大</strong>：在平坦区域增大步长，加快收敛</li>\n<li><strong>坡度大，g 就大，学习率就小</strong>：在陡峭区域减小步长，避免震荡</li>\n</ul>\n<div class=\"note info\">\n<p>同一个参数在不同训练阶段的坡度也会不一样，这正是需要自适应调整的根本原因。</p>\n</div>\n<h2 id=\"基础自适应学习率方法\"><a class=\"anchor\" href=\"#基础自适应学习率方法\">#</a> 基础自适应学习率方法</h2>\n<h3 id=\"adagrad-算法\"><a class=\"anchor\" href=\"#adagrad-算法\">#</a> AdaGrad 算法</h3>\n<p>AdaGrad 是最早的自适应学习率算法之一，其核心思想是累积历史梯度信息来调整学习率：</p>\n<p><strong>更新公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>θ</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>←</mo><msubsup><mi>θ</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mfrac><mi>η</mi><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mfrac><msubsup><mi>g</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\theta^{t+1}_i \\leftarrow \\theta^t_i - \\frac{\\eta}{\\sigma^t_i}g^t_i\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.131103em;vertical-align:-0.266995em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.433005em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.266995em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0905559999999999em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8435559999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.070424em;vertical-align:-0.9628639999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7753559999999999em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9628639999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8435559999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>梯度累积：</strong></p>\n<ul>\n<li>初始状态：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>0</mn></msubsup><mo>=</mo><msqrt><mrow><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt><mo>=</mo><mi mathvariant=\"normal\">∣</mi><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma^0_i = \\sqrt{(g^0_i)^2} = |g^0_i|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.072772em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.2954779999999999em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9445220000000001em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-2.904522em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2954779999999999em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.072772em;vertical-align:-0.258664em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span></li>\n<li>第一次更新：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>1</mn></msubsup><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy=\"false\">[</mo><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>1</mn></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo stretchy=\"false\">]</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sigma^1_i = \\sqrt{\\frac{1}{2}[(g^0_i)^2 + (g^1_i)^2]}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.072772em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.604946em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.235054em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mopen\">[</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span><span style=\"top:-3.195054em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.604946em;\"><span></span></span></span></span></span></span></span></span></li>\n<li>一般形式：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></msubsup><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mi>j</mi></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sigma^t_i = \\sqrt{\\frac{1}{t+1}\\sum_{j=0}^{t}(g^j_i)^2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05222em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.601623em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.238377em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">0</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.942572em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1809080000000005em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.198377em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.601623em;\"><span></span></span></span></span></span></span></span></span></li>\n</ul>\n<details class=\"warning\"><summary>AdaGrad 的局限性</summary><div>\n<p>AdaGrad 算法存在一个重要缺陷：随着训练进行，分母 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\sigma^t_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05222em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 会持续增大，导致学习率单调递减，最终可能过早停止学习。这个问题在长时间训练中尤为突出。</p>\n</div></details>\n<h3 id=\"rmsprop-算法\"><a class=\"anchor\" href=\"#rmsprop-算法\">#</a> RMSProp 算法</h3>\n<p>RMSProp 通过引入衰减因子解决了 AdaGrad 的问题：</p>\n<p><strong>核心公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>1</mn></msubsup><mo>=</mo><msqrt><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>1</mn></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sigma^1_i = \\sqrt{\\alpha(\\sigma^0_i)^2 + (1-\\alpha)(g^1_i)^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1111079999999998em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.546603em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.2933970000000001em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7959080000000001em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.2533969999999997em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.546603em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><strong>一般形式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><msqrt><mrow><mi>α</mi><mo stretchy=\"false\">(</mo><msubsup><mi>σ</mi><mi>i</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><msubsup><mi>g</mi><mi>i</mi><mi>t</mi></msubsup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sigma^t_i = \\sqrt{\\alpha(\\sigma^{t-1}_i)^2 + (1-\\alpha)(g^t_i)^2}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0905559999999999em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8435559999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.84em;vertical-align:-0.5174375em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3225625em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.854239em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1031310000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.276864em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7753559999999999em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.740108em;\"><span style=\"top:-2.9890000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.2825625em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5174375em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p>其中 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">0 &lt; \\alpha &lt; 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68354em;vertical-align:-0.0391em;\"></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 是衰减因子。</p>\n<details class=\"info\"><summary>深入理解：RMSProp</summary><div>\n<p>RMSProp（Root Mean Square Propagation）是由 Geoffrey Hinton 在其 Coursera 课程中提出的优化算法。它的核心思想是使用梯度的指数移动平均来调整学习率，从而解决 AdaGrad 学习率单调递减的问题。RMSProp 在处理非平稳目标函数时表现优异，特别适用于在线学习和递归神经网络的训练。</p>\n</div></details>\n<details class=\"info\"><summary>深入理解：Root Mean Square</summary><div>\n<p>Root Mean Square（RMS，均方根）是统计学中的一个重要概念，表示一组数值的平方平均数的算术平方根。在 RMSProp 中，RMS 用于度量梯度的历史变化幅度，从而自适应地调整学习率。这种方法比简单的算术平均更能反映梯度的实际变化趋势。</p>\n</div></details>\n<h3 id=\"adam-算法\"><a class=\"anchor\" href=\"#adam-算法\">#</a> Adam 算法</h3>\n<p>Adam 算法结合了 RMSProp 和 Momentum 的优点：</p>\n<p><strong>更新公式：</strong></p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><msubsup><mi>θ</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>←</mo><msubsup><mi>θ</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mfrac><mi>η</mi><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mfrac><msubsup><mi>m</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\theta^{t+1}_i \\leftarrow \\theta^t_i - \\frac{\\eta}{\\sigma^t_i}m^t_i\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.131103em;vertical-align:-0.266995em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.433005em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.266995em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0905559999999999em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8435559999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.070424em;vertical-align:-0.9628639999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7753559999999999em;\"><span style=\"top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.0448000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.27686399999999994em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9628639999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8435559999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>其中：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>m</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">m^t_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05222em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-2.441336em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 是动量项（一阶矩估计）</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\sigma^t_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.05222em;vertical-align:-0.258664em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.258664em;\"><span></span></span></span></span></span></span></span></span></span> 是 RMSProp 风格的二阶矩估计</li>\n</ul>\n<details class=\"success\"><summary>Adam 算法详解</summary><div>\n<p>Adam（Adaptive Moment Estimation）算法是目前最广泛使用的自适应学习率优化算法。它结合了 AdaGrad 善于处理稀疏梯度的优点和 RMSProp 善于处理非平稳目标的优点。Adam 的核心思想是：</p>\n<ol>\n<li>维护梯度的一阶矩估计（类似 Momentum）</li>\n<li>维护梯度的二阶矩估计（类似 RMSProp）</li>\n<li>对两个估计进行偏差校正</li>\n<li>结合两个估计来更新参数</li>\n</ol>\n<p>Adam 算法具有以下优点：</p>\n<ul>\n<li>对超参数相对不敏感</li>\n<li>适用于大多数深度学习任务</li>\n<li>内存效率高，计算开销小</li>\n<li>在实践中表现稳定可靠</li>\n</ul>\n</div></details>\n<h2 id=\"学习率调度策略\"><a class=\"anchor\" href=\"#学习率调度策略\">#</a> 学习率调度策略</h2>\n<h3 id=\"learning-rate-decay\"><a class=\"anchor\" href=\"#learning-rate-decay\">#</a> Learning Rate Decay</h3>\n<p>学习率衰减是一种常见的调度策略，<strong>随时间衰减</strong>学习率：</p>\n<ul>\n<li><strong>指数衰减</strong>：<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><msub><mi>η</mi><mn>0</mn></msub><mo>⋅</mo><msup><mi>γ</mi><mi>t</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\eta_t = \\eta_0 \\cdot \\gamma^t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.63889em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9879959999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05556em;\">γ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span></span></span></span></span></span></span></span></li>\n<li -\\beta=\"\"><strong>多项式衰减</strong>：\\eta_t = \\eta_0 \\cdot (1 + \\gamma \\cdot t)^</li>\n<li><strong>分段常数衰减</strong>：在特定的训练阶段降低学习率</li>\n</ul>\n<details class=\"info\"><summary>深入理解：Learning Rate Scheduling</summary><div>\n<p>学习率调度（Learning Rate Scheduling）是一种在训练过程中系统性地调整学习率的策略。其基本思想是在训练初期使用较大的学习率快速收敛，在训练后期使用较小的学习率精细调整。常见的调度策略包括：</p>\n<ol>\n<li>步长衰减（Step Decay）：每隔固定步数降低学习率</li>\n<li>指数衰减（Exponential Decay）：按指数函数连续降低学习率</li>\n<li>余弦退火（Cosine Annealing）：按余弦函数周期性调整学习率</li>\n<li>自适应调度：根据验证集性能动态调整学习率</li>\n</ol>\n</div></details>\n<h3 id=\"warmup-策略\"><a class=\"anchor\" href=\"#warmup-策略\">#</a> Warmup 策略</h3>\n<p>Warmup 是一种<strong>先增大后减小</strong>的学习率调度方法：</p>\n<ol>\n<li><strong>预热阶段</strong>：从很小的学习率开始，逐渐增大到目标值</li>\n<li><strong>正常训练</strong>：使用标准的学习率衰减策略</li>\n</ol>\n<div class=\"note warning\">\n<p>Warmup 策略在大批量训练和 Transformer 模型中特别重要，有助于稳定训练初期的梯度更新。</p>\n</div>\n<h2 id=\"实际应用考虑\"><a class=\"anchor\" href=\"#实际应用考虑\">#</a> 实际应用考虑</h2>\n<h3 id=\"残差网络中的应用\"><a class=\"anchor\" href=\"#残差网络中的应用\">#</a> 残差网络中的应用</h3>\n<details class=\"info\"><summary>深入理解：Residual Network</summary><div>\n<p>残差网络（Residual Network, ResNet）是一种深度神经网络架构，通过引入跳跃连接（skip connection）解决了深层网络的梯度消失问题。在 ResNet 中，网络学习的是残差映射 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>H</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>−</mo><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">F(x) = H(x) - x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span>，而不是直接的映射 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">H(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span>。这种设计使得网络能够训练得更深，同时保持良好的性能。残差网络的核心优势包括：</p>\n<ol>\n<li>解决深层网络的梯度消失问题</li>\n<li>允许训练更深的网络结构</li>\n<li>提高网络的表达能力和泛化性能</li>\n<li>简化网络的优化过程</li>\n</ol>\n</div></details>\n<p>在残差网络中，自适应学习率的应用需要特别注意：</p>\n<ul>\n<li><strong>不同层的学习率</strong>：浅层和深层可能需要不同的学习率策略</li>\n<li><strong>跳跃连接的影响</strong>：残差连接改变了梯度的传播方式</li>\n<li><strong>批量归一化的协同</strong>：BN 层与自适应学习率的相互作用</li>\n</ul>\n<h3 id=\"参数特异性调整\"><a class=\"anchor\" href=\"#参数特异性调整\">#</a> 参数特异性调整</h3>\n<p>由于神经网络中不同参数的特性差异巨大，自适应学习率算法能够：</p>\n<ul>\n<li><strong>为每个参数维护独立的学习率</strong></li>\n<li><strong>根据参数的历史梯度信息进行调整</strong></li>\n<li><strong>自动平衡不同参数的更新幅度</strong></li>\n</ul>\n<h2 id=\"算法选择与调优建议\"><a class=\"anchor\" href=\"#算法选择与调优建议\">#</a> 算法选择与调优建议</h2>\n<div class=\"tab\" data-id=\"Adam\" data-title=\"首选方案\">\n<p>Adam 算法通常是初学者和大多数应用场景的首选，具有良好的默认参数设置和广泛的适用性。</p>\n</div>\n<div class=\"tab\" data-id=\"RMSProp\" data-title=\"备选方案\">\n<p>当 Adam 出现收敛问题时，RMSProp 可以作为备选方案，特别是在 RNN 训练中表现优异。</p>\n</div>\n<div class=\"tab\" data-id=\"learning\" data-title=\"lr调度 高级策略\">\n<p>对于追求极致性能的应用，可以结合多种学习率调度策略，如 Warmup + Cosine Decay 等。</p>\n</div>\n",
            "tags": [
                "学习笔记",
                "机器学习",
                "神经网络",
                "梯度下降",
                "深度学习",
                "优化算法",
                "自适应学习率",
                "RMSProp",
                "Adam",
                "学习率调度",
                "残差网络"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3439-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-I/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3439-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-I/",
            "title": "力扣每日一题：3439. 重新安排会议得到最多空余时间 I",
            "date_published": "2025-07-08T17:03:40.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9yZXNjaGVkdWxlLW1lZXRpbmdzLWZvci1tYXhpbXVtLWZyZWUtdGltZS1pP2VudlR5cGU9ZGFpbHktcXVlc3Rpb24mYW1wO2VudklkPTIwMjUtMDctMDk=\">LeetCode 3439</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个整数  <code>eventTime</code>  表示一个活动的总时长，这个活动开始于  <code>t = 0</code>  ，结束于  <code>t = eventTime</code>  。</p>\n<p>同时给你两个长度为  <code>n</code>  的整数数组  <code>startTime</code>  和  <code>endTime</code>  。它们表示这次活动中  <code>n</code>  个时间 没有重叠 的会议，其中第  <code>i</code>  个会议的时间为  <code>[startTime[i], endTime[i]]</code>  。</p>\n<p>你可以重新安排 至多  <code>k</code>  个会议，安排的规则是将会议时间平移，且保持原来的 会议时长 ，你的目的是移动会议后 最大化 相邻两个会议之间的 最长 连续空余时间。</p>\n<p>移动前后所有会议之间的 相对 顺序需要保持不变，而且会议时间也需要保持互不重叠。</p>\n<p>请你返回重新安排会议以后，可以得到的 最大 空余时间。</p>\n<p>注意，会议 不能 安排到整个活动的时间以外。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p>k &lt;= n，所以一定可以选到 k 个会议。又由于顺序不能改变，因此我们可以考虑使用滑动窗口的方式来解决这个问题。维持一个大小为 k 的窗口，窗口内的会议时间和为 sum，窗口左端的会议结束时间为 st，右端的会议开始时间为 et。每次移动窗口时，计算当前空余时间 et - st - sum，并更新最大值。</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maxFreeTime</span><span class=\"params\">(<span class=\"type\">int</span> eventTime, <span class=\"type\">int</span> k, vector&lt;<span class=\"type\">int</span>&gt;&amp; startTime, vector&lt;<span class=\"type\">int</span>&gt;&amp; endTime)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> st = <span class=\"number\">0</span>, et = <span class=\"number\">0</span>, sum = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> i = <span class=\"number\">0</span>, n = startTime.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">while</span>(i &lt; k<span class=\"number\">-1</span>) sum += (endTime[i] - startTime[i]),i++;</span><br><span class=\"line\">        <span class=\"keyword\">while</span> (i &lt; n)&#123;</span><br><span class=\"line\">            sum += (endTime[i] - startTime[i]),i++;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i &lt; n) et = startTime[i];</span><br><span class=\"line\">            <span class=\"keyword\">else</span> et = eventTime;</span><br><span class=\"line\">            ans = <span class=\"built_in\">max</span>(ans, et-st-sum);</span><br><span class=\"line\">            <span class=\"type\">int</span> id = i-k;</span><br><span class=\"line\">            st = endTime[id];</span><br><span class=\"line\">            sum -= (endTime[id]-startTime[id]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "滑动窗口"
            ]
        },
        {
            "id": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1751-%E6%9C%80%E5%A4%9A%E5%8F%AF%E4%BB%A5%E5%8F%82%E5%8A%A0%E7%9A%84%E4%BC%9A%E8%AE%AE%E6%95%B0%E7%9B%AE-II/",
            "url": "https://stinncsky.github.io/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1751-%E6%9C%80%E5%A4%9A%E5%8F%AF%E4%BB%A5%E5%8F%82%E5%8A%A0%E7%9A%84%E4%BC%9A%E8%AE%AE%E6%95%B0%E7%9B%AE-II/",
            "title": "力扣每日一题：1751. 最多可以参加的会议数目 II",
            "date_published": "2025-07-08T13:13:27.000Z",
            "content_html": "<div class=\"note info\">\n<p>本篇为 <span class=\"exturl\" data-url=\"aHR0cHM6Ly9sZWV0Y29kZS5jbi9wcm9ibGVtcy9tYXhpbXVtLW51bWJlci1vZi1ldmVudHMtdGhhdC1jYW4tYmUtYXR0ZW5kZWQtaWk/ZW52VHlwZT1kYWlseS1xdWVzdGlvbiZhbXA7ZW52SWQ9MjAyNS0wNy0wOA==\">LeetCode 1751</span> 的题解，记录了解题思路、代码实现。</p>\n</div>\n<hr />\n<h2 id=\"题目描述\"><a class=\"anchor\" href=\"#题目描述\">#</a> 📘 题目描述</h2>\n<p>给你一个  <code>events</code>  数组，其中  <code>events[i] = [startDayi, endDayi, valuei]</code>  ，表示第  <code>i</code>  个会议在  <code>startDayi</code>  天开始，第  <code>endDayi</code>  天结束，如果你参加这个会议，你能得到价值  <code>valuei</code>  。同时给你一个整数  <code>k</code>  表示你能参加的最多会议数目。</p>\n<p>你同一时间只能参加一个会议。如果你选择参加某个会议，那么你必须 完整 地参加完这个会议。会议结束日期是包含在会议内的，也就是说你不能同时参加一个开始日期与另一个结束日期相同的两个会议。</p>\n<p>请你返回能得到的会议价值 最大和 。</p>\n<hr />\n<h2 id=\"解题思路\"><a class=\"anchor\" href=\"#解题思路\">#</a> 🧠 解题思路</h2>\n<p><mark>解法一</mark>按开始时间排序后，定义 dp [i] 表示选择第 i 个会议作为第一个会议的最大价值，对于每轮迭代 j（表示已选 j+1 个会议），维护一个后缀最大值数组 suf_max 记录此前所有可能方案的最大值，然后通过二分查找确定当前会议结束后可以参加的下一个会议位置 nd，状态转移为 dp [i] = events [i][2] + suf_max [nd]，即为选定从第 i 个会议开始，再选能选的会议选 j 个的最大值。最终实际为遍历选 j 个会议时的最大值，由于最大值选择的会议数不一定相同，最终答案是所有 dp 值的最大值。</p>\n<p><mark>解法二</mark>同样按开始时间排序，定义 dp [i][j] 表示从第 i 个会议开始，最多参加 j 个会议的最大价值，从后往前考虑每个会议，对于位置 i 和剩余可选数量 j，要么不选当前会议 (dp [i+1][j])，要么选择当前会议并找到下一个不冲突的会议位置 nd (events [i][2] + dp [nd][j-1])，取两者最大值，最终答案为 dp [0][k]。（该思路参考大部分人所用的按结束时间排序的解法，本质上和前一个解法相同）</p>\n<hr />\n<h2 id=\"代码实现\"><a class=\"anchor\" href=\"#代码实现\">#</a> 💡 代码实现</h2>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法1</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maxValue</span><span class=\"params\">(vector&lt;vector&lt;<span class=\"type\">int</span>&gt;&gt;&amp; events, <span class=\"type\">int</span> k)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = events.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(events);</span><br><span class=\"line\">        <span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">dp</span><span class=\"params\">(n)</span></span>;</span><br><span class=\"line\">        <span class=\"type\">int</span> ans = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">            dp[i] = events[i][<span class=\"number\">2</span>];</span><br><span class=\"line\">            ans = <span class=\"built_in\">max</span>(ans, dp[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt; k; j++)&#123;</span><br><span class=\"line\">            <span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">suf_max</span><span class=\"params\">(n<span class=\"number\">+1</span>,<span class=\"number\">0</span>)</span></span>;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">                suf_max[i] = <span class=\"built_in\">max</span>(suf_max[i<span class=\"number\">+1</span>],dp[i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i++)&#123;</span><br><span class=\"line\">                <span class=\"type\">int</span> nd = ranges::<span class=\"built_in\">upper_bound</span>(events,events[i][<span class=\"number\">1</span>],&#123;&#125;,[](<span class=\"type\">const</span> vector&lt;<span class=\"type\">int</span>&gt; &amp;a)&#123;<span class=\"keyword\">return</span> a[<span class=\"number\">0</span>];&#125;) - events.<span class=\"built_in\">begin</span>();</span><br><span class=\"line\">                dp[i] = events[i][<span class=\"number\">2</span>] + suf_max[nd];</span><br><span class=\"line\">                ans = <span class=\"built_in\">max</span>(ans, dp[i]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ans;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight cpp\"><figcaption><span>C++ 解法2</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Solution</span> &#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">maxValue</span><span class=\"params\">(vector&lt;vector&lt;<span class=\"type\">int</span>&gt;&gt;&amp; events, <span class=\"type\">int</span> k)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> n = events.<span class=\"built_in\">size</span>();</span><br><span class=\"line\">        ranges::<span class=\"built_in\">sort</span>(events);</span><br><span class=\"line\">        vector&lt;vector&lt;<span class=\"type\">int</span>&gt;&gt; <span class=\"built_in\">dp</span>(n<span class=\"number\">+1</span>,<span class=\"built_in\">vector</span>&lt;<span class=\"type\">int</span>&gt;(k<span class=\"number\">+1</span>,<span class=\"number\">0</span>));</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i--)&#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> nd = ranges::<span class=\"built_in\">upper_bound</span>(events.<span class=\"built_in\">begin</span>()+i,events.<span class=\"built_in\">end</span>(),events[i][<span class=\"number\">1</span>],&#123;&#125;,[](<span class=\"type\">const</span> vector&lt;<span class=\"type\">int</span>&gt; &amp;a)&#123;<span class=\"keyword\">return</span> a[<span class=\"number\">0</span>];&#125;) - events.<span class=\"built_in\">begin</span>();</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= k; j++)&#123;</span><br><span class=\"line\">                dp[i][j] = <span class=\"built_in\">max</span>(dp[i<span class=\"number\">+1</span>][j], events[i][<span class=\"number\">2</span>] + dp[nd][j<span class=\"number\">-1</span>]);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> dp[<span class=\"number\">0</span>][k];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n",
            "tags": [
                "算法题解",
                "力扣",
                "每日一题",
                "算法",
                "LeetCode",
                "C++",
                "排序",
                "动态规划",
                "二分查找"
            ]
        }
    ]
}