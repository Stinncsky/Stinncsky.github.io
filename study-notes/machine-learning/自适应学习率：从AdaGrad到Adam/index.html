<!DOCTYPE html><html lang="zh-CN"><head><link href="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/css/index.css" rel="stylesheet"><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="漠溟绽灵的小站" href="https://stinncsky.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="漠溟绽灵的小站" href="https://stinncsky.github.io/atom.xml"><link rel="alternate" type="application/json" title="漠溟绽灵的小站" href="https://stinncsky.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="神经网络,梯度下降,深度学习,优化算法,自适应学习率,RMSProp,Adam,学习率调度,残差网络"><link rel="canonical" href="https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/"><title>自适应学习率：从AdaGrad到Adam - 机器学习 - 学习笔记 | Stinnc = 漠溟绽灵的小站 = 谁知道里面有什么</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">自适应学习率：从AdaGrad到Adam</h1><div class="meta"><span class="item" title="创建时间：2025-07-09 11:03:30"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2025-07-09T11:03:30+08:00">2025-07-09</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>3.4k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>3 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Stinnc</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="/images/132363104_p0_master1200.jpg"></li><li class="item" data-background-image="/images/132319858_p0_master1200.jpg"></li><li class="item" data-background-image="/images/8b6d46ef3b7137bb49aade189211a4b96b906ca9.jpg"></li><li class="item" data-background-image="/images/132357959_p0_master1200.jpg"></li><li class="item" data-background-image="/images/132325152_p0_master1200.jpg"></li><li class="item" data-background-image="/images/132338096_p0.png"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/study-notes/" itemprop="item" rel="index" title="分类于 学习笔记"><span itemprop="name">学习笔记</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/study-notes/machine-learning/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/hdd.jpg"><meta itemprop="name" content="漠溟绽灵Stinnc"><meta itemprop="description" content="谁知道里面有什么, 嘿嘿嘿~~"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="漠溟绽灵的小站"></span><div class="body md" itemprop="articleBody"><h1 id="自适应学习率详解"><a class="anchor" href="#自适应学习率详解">#</a> 自适应学习率详解</h1><p>在深度学习的优化过程中，学习率的选择一直是一个关键问题。传统的固定学习率往往难以在所有参数和训练阶段都保持最优性能。本文将深入探讨自适应学习率的核心概念、算法原理及其在实际应用中的重要性。</p><details class="info"><summary>深入理解：Adaptive Learning Rate</summary><div><p>自适应学习率（Adaptive Learning Rate）是指在训练过程中根据梯度信息、参数历史更新情况或其他启发式规则自动调整学习率的方法。与固定学习率相比，自适应学习率能够：</p><ol><li>为不同参数分配不同的学习率</li><li>根据训练阶段动态调整更新幅度</li><li>自动平衡收敛速度和稳定性</li><li>减少人工调参的复杂性</li></ol></div></details><h2 id="学习率的重要性与挑战"><a class="anchor" href="#学习率的重要性与挑战">#</a> 学习率的重要性与挑战</h2><h3 id="学习率大小的影响"><a class="anchor" href="#学习率大小的影响">#</a> 学习率大小的影响</h3><p>学习率的选择直接影响模型的收敛性能：</p><ul><li><strong>学习率过大</strong>：步子过大，每一次 update 太大，可能导致直接跳过理想的目标点，造成训练不稳定甚至发散</li><li><strong>学习率过小</strong>：在某些方向上可能移动过于缓慢，导致收敛速度极慢，训练时间过长</li></ul><details class="info"><summary>深入理解：Error Surface 误差表面</summary><div><p>误差表面（Error Surface）是指在参数空间中，损失函数随参数变化形成的多维曲面。在深度学习中，这个表面通常具有复杂的非凸结构，存在多个局部最小值、鞍点和平坦区域。理解误差表面的特性对于设计有效的优化算法至关重要。</p></div></details><h3 id="梯度与学习率的关系"><a class="anchor" href="#梯度与学习率的关系">#</a> 梯度与学习率的关系</h3><p>自适应学习率的核心思想是根据梯度信息动态调整学习率：</p><ul><li><strong>坡度小，g 就小，学习率就大</strong>：在平坦区域增大步长，加快收敛</li><li><strong>坡度大，g 就大，学习率就小</strong>：在陡峭区域减小步长，避免震荡</li></ul><div class="note info"><p>同一个参数在不同训练阶段的坡度也会不一样，这正是需要自适应调整的根本原因。</p></div><h2 id="基础自适应学习率方法"><a class="anchor" href="#基础自适应学习率方法">#</a> 基础自适应学习率方法</h2><h3 id="adagrad-算法"><a class="anchor" href="#adagrad-算法">#</a> AdaGrad 算法</h3><p>AdaGrad 是最早的自适应学习率算法之一，其核心思想是累积历史梯度信息来调整学习率：</p><p><strong>更新公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>θ</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>←</mo><msubsup><mi>θ</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mfrac><mi>η</mi><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mfrac><msubsup><mi>g</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\theta^{t+1}_i \leftarrow \theta^t_i - \frac{\eta}{\sigma^t_i}g^t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.131103em;vertical-align:-.266995em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-2.433005em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.266995em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0905559999999999em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8435559999999999em"><span style="top:-2.4530000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.070424em;vertical-align:-.9628639999999999em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7753559999999999em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9628639999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8435559999999999em"><span style="top:-2.4530000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span></span></span></p><p><strong>梯度累积：</strong></p><ul><li>初始状态：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>0</mn></msubsup><mo>=</mo><msqrt><mrow><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt><mo>=</mo><mi mathvariant="normal">∣</mi><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">\sigma^0_i = \sqrt{(g^0_i)^2} = |g^0_i|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.072772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.24em;vertical-align:-.2954779999999999em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9445220000000001em"><span class="svg-align" style="top:-3.2em"><span class="pstrut" style="height:3.2em"></span><span class="mord" style="padding-left:1em"><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7959080000000001em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-2.904522em"><span class="pstrut" style="height:3.2em"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em"><svg width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2954779999999999em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.072772em;vertical-align:-.258664em"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></li><li>第一次更新：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>1</mn></msubsup><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>1</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma^1_i = \sqrt{\frac{1}{2}[(g^0_i)^2 + (g^1_i)^2]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.072772em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-.604946em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.235054em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">[</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7959080000000001em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7959080000000001em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span><span style="top:-3.195054em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.604946em"><span></span></span></span></span></span></span></span></span></li><li>一般形式：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>t</mi></msubsup><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma^t_i = \sqrt{\frac{1}{t+1}\sum_{j=0}^{t}(g^j_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7935559999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-.601623em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.238377em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.403331em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-.0000050000000000050004em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.933456em"><span style="top:-2.40029em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.43581800000000004em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.942572em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1809080000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.198377em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.601623em"><span></span></span></span></span></span></span></span></span></li></ul><details class="warning"><summary>AdaGrad 的局限性</summary><div><p>AdaGrad 算法存在一个重要缺陷：随着训练进行，分母 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\sigma^t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7935559999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span> 会持续增大，导致学习率单调递减，最终可能过早停止学习。这个问题在长时间训练中尤为突出。</p></div></details><h3 id="rmsprop-算法"><a class="anchor" href="#rmsprop-算法">#</a> RMSProp 算法</h3><p>RMSProp 通过引入衰减因子解决了 AdaGrad 的问题：</p><p><strong>核心公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>1</mn></msubsup><mo>=</mo><msqrt><mrow><mi>α</mi><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>0</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mn>1</mn></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma^1_i = \sqrt{\alpha(\sigma^0_i)^2 + (1-\alpha)(g^1_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1111079999999998em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-2.4530000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-.546603em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2933970000000001em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7959080000000001em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7959080000000001em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2533969999999997em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.546603em"><span></span></span></span></span></span></span></span></span></span></p><p><strong>一般形式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup><mo>=</mo><msqrt><mrow><mi>α</mi><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msubsup><mi>g</mi><mi>i</mi><mi>t</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sigma^t_i = \sqrt{\alpha(\sigma^{t-1}_i)^2 + (1-\alpha)(g^t_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0905559999999999em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8435559999999999em"><span style="top:-2.4530000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.84em;vertical-align:-.5174375em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3225625em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.854239em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.276864em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7753559999999999em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.740108em"><span style="top:-2.9890000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.2825625em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.5174375em"><span></span></span></span></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \alpha &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68354em;vertical-align:-.0391em"></span><span class="mord">0</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.5782em;vertical-align:-.0391em"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span></span></span></span> 是衰减因子。</p><details class="info"><summary>深入理解：RMSProp</summary><div><p>RMSProp（Root Mean Square Propagation）是由 Geoffrey Hinton 在其 Coursera 课程中提出的优化算法。它的核心思想是使用梯度的指数移动平均来调整学习率，从而解决 AdaGrad 学习率单调递减的问题。RMSProp 在处理非平稳目标函数时表现优异，特别适用于在线学习和递归神经网络的训练。</p></div></details><details class="info"><summary>深入理解：Root Mean Square</summary><div><p>Root Mean Square（RMS，均方根）是统计学中的一个重要概念，表示一组数值的平方平均数的算术平方根。在 RMSProp 中，RMS 用于度量梯度的历史变化幅度，从而自适应地调整学习率。这种方法比简单的算术平均更能反映梯度的实际变化趋势。</p></div></details><h3 id="adam-算法"><a class="anchor" href="#adam-算法">#</a> Adam 算法</h3><p>Adam 算法结合了 RMSProp 和 Momentum 的优点：</p><p><strong>更新公式：</strong></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>θ</mi><mi>i</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>←</mo><msubsup><mi>θ</mi><mi>i</mi><mi>t</mi></msubsup><mo>−</mo><mfrac><mi>η</mi><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mfrac><msubsup><mi>m</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\theta^{t+1}_i \leftarrow \theta^t_i - \frac{\eta}{\sigma^t_i}m^t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.131103em;vertical-align:-.266995em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-2.433005em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.266995em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0905559999999999em;vertical-align:-.247em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02778em">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8435559999999999em"><span style="top:-2.4530000000000003em;margin-left:-.02778em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.070424em;vertical-align:-.9628639999999999em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7753559999999999em"><span style="top:-2.4231360000000004em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448000000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.9628639999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8435559999999999em"><span style="top:-2.4530000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中：</p><ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>m</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">m^t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7935559999999999em"><span style="top:-2.441336em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span> 是动量项（一阶矩估计）</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>σ</mi><mi>i</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\sigma^t_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.05222em;vertical-align:-.258664em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.7935559999999999em"><span style="top:-2.441336em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.258664em"><span></span></span></span></span></span></span></span></span></span> 是 RMSProp 风格的二阶矩估计</li></ul><details class="success"><summary>Adam 算法详解</summary><div><p>Adam（Adaptive Moment Estimation）算法是目前最广泛使用的自适应学习率优化算法。它结合了 AdaGrad 善于处理稀疏梯度的优点和 RMSProp 善于处理非平稳目标的优点。Adam 的核心思想是：</p><ol><li>维护梯度的一阶矩估计（类似 Momentum）</li><li>维护梯度的二阶矩估计（类似 RMSProp）</li><li>对两个估计进行偏差校正</li><li>结合两个估计来更新参数</li></ol><p>Adam 算法具有以下优点：</p><ul><li>对超参数相对不敏感</li><li>适用于大多数深度学习任务</li><li>内存效率高，计算开销小</li><li>在实践中表现稳定可靠</li></ul></div></details><h2 id="学习率调度策略"><a class="anchor" href="#学习率调度策略">#</a> 学习率调度策略</h2><h3 id="learning-rate-decay"><a class="anchor" href="#learning-rate-decay">#</a> Learning Rate Decay</h3><p>学习率衰减是一种常见的调度策略，<strong>随时间衰减</strong>学习率：</p><ul><li><strong>指数衰减</strong>：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>η</mi><mi>t</mi></msub><mo>=</mo><msub><mi>η</mi><mn>0</mn></msub><mo>⋅</mo><msup><mi>γ</mi><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\eta_t = \eta_0 \cdot \gamma^t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.63889em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.9879959999999999em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.05556em">γ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7935559999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span></li><li -\beta=""><strong>多项式衰减</strong>：\eta_t = \eta_0 \cdot (1 + \gamma \cdot t)^</li><li><strong>分段常数衰减</strong>：在特定的训练阶段降低学习率</li></ul><details class="info"><summary>深入理解：Learning Rate Scheduling</summary><div><p>学习率调度（Learning Rate Scheduling）是一种在训练过程中系统性地调整学习率的策略。其基本思想是在训练初期使用较大的学习率快速收敛，在训练后期使用较小的学习率精细调整。常见的调度策略包括：</p><ol><li>步长衰减（Step Decay）：每隔固定步数降低学习率</li><li>指数衰减（Exponential Decay）：按指数函数连续降低学习率</li><li>余弦退火（Cosine Annealing）：按余弦函数周期性调整学习率</li><li>自适应调度：根据验证集性能动态调整学习率</li></ol></div></details><h3 id="warmup-策略"><a class="anchor" href="#warmup-策略">#</a> Warmup 策略</h3><p>Warmup 是一种<strong>先增大后减小</strong>的学习率调度方法：</p><ol><li><strong>预热阶段</strong>：从很小的学习率开始，逐渐增大到目标值</li><li><strong>正常训练</strong>：使用标准的学习率衰减策略</li></ol><div class="note warning"><p>Warmup 策略在大批量训练和 Transformer 模型中特别重要，有助于稳定训练初期的梯度更新。</p></div><h2 id="实际应用考虑"><a class="anchor" href="#实际应用考虑">#</a> 实际应用考虑</h2><h3 id="残差网络中的应用"><a class="anchor" href="#残差网络中的应用">#</a> 残差网络中的应用</h3><details class="info"><summary>深入理解：Residual Network</summary><div><p>残差网络（Residual Network, ResNet）是一种深度神经网络架构，通过引入跳跃连接（skip connection）解决了深层网络的梯度消失问题。在 ResNet 中，网络学习的是残差映射 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>H</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>−</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">F(x) = H(x) - x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">x</span></span></span></span>，而不是直接的映射 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>。这种设计使得网络能够训练得更深，同时保持良好的性能。残差网络的核心优势包括：</p><ol><li>解决深层网络的梯度消失问题</li><li>允许训练更深的网络结构</li><li>提高网络的表达能力和泛化性能</li><li>简化网络的优化过程</li></ol></div></details><p>在残差网络中，自适应学习率的应用需要特别注意：</p><ul><li><strong>不同层的学习率</strong>：浅层和深层可能需要不同的学习率策略</li><li><strong>跳跃连接的影响</strong>：残差连接改变了梯度的传播方式</li><li><strong>批量归一化的协同</strong>：BN 层与自适应学习率的相互作用</li></ul><h3 id="参数特异性调整"><a class="anchor" href="#参数特异性调整">#</a> 参数特异性调整</h3><p>由于神经网络中不同参数的特性差异巨大，自适应学习率算法能够：</p><ul><li><strong>为每个参数维护独立的学习率</strong></li><li><strong>根据参数的历史梯度信息进行调整</strong></li><li><strong>自动平衡不同参数的更新幅度</strong></li></ul><h2 id="算法选择与调优建议"><a class="anchor" href="#算法选择与调优建议">#</a> 算法选择与调优建议</h2><div class="tab" data-id="Adam" data-title="首选方案"><p>Adam 算法通常是初学者和大多数应用场景的首选，具有良好的默认参数设置和广泛的适用性。</p></div><div class="tab" data-id="RMSProp" data-title="备选方案"><p>当 Adam 出现收敛问题时，RMSProp 可以作为备选方案，特别是在 RNN 训练中表现优异。</p></div><div class="tab" data-id="learning" data-title="lr调度 高级策略"><p>对于追求极致性能的应用，可以结合多种学习率调度策略，如 Warmup + Cosine Decay 等。</p></div><div class="tags"><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"><i class="ic i-tag"></i> 神经网络</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="tag"><i class="ic i-tag"></i> 梯度下降</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 深度学习</a> <a href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" rel="tag"><i class="ic i-tag"></i> 优化算法</a> <a href="/tags/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87/" rel="tag"><i class="ic i-tag"></i> 自适应学习率</a> <a href="/tags/RMSProp/" rel="tag"><i class="ic i-tag"></i> RMSProp</a> <a href="/tags/Adam/" rel="tag"><i class="ic i-tag"></i> Adam</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6/" rel="tag"><i class="ic i-tag"></i> 学习率调度</a> <a href="/tags/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/" rel="tag"><i class="ic i-tag"></i> 残差网络</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2025-07-09 14:02:05" itemprop="dateModified" datetime="2025-07-09T14:02:05+08:00">2025-07-09</time> </span><span id="study-notes/machine-learning/自适应学习率：从AdaGrad到Adam/" class="item leancloud_visitors" data-flag-title="自适应学习率：从AdaGrad到Adam" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.jpg" alt="漠溟绽灵Stinnc 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.jpg" alt="漠溟绽灵Stinnc 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>漠溟绽灵Stinnc <i class="ic i-at"><em>@</em></i>漠溟绽灵的小站</li><li class="link"><strong>本文链接：</strong> <a href="https://stinncsky.github.io/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/" title="自适应学习率：从AdaGrad到Adam">https://stinncsky.github.io/study-notes/machine-learning/自适应学习率：从AdaGrad到Adam/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3439-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-I/" itemprop="url" rel="prev" data-background-image="&#x2F;images&#x2F;132363104_p0_master1200.jpg" title="力扣每日一题：3439. 重新安排会议得到最多空余时间 I"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 每日一题</span><h3>力扣每日一题：3439. 重新安排会议得到最多空余时间 I</h3></a></div><div class="item right"><a href="/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/" itemprop="url" rel="next" data-background-image="&#x2F;images&#x2F;132325152_p0_master1200.jpg" title="从回归到分类：Softmax与交叉熵"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 机器学习</span><h3>从回归到分类：Softmax与交叉熵</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">自适应学习率详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">1.1.</span> <span class="toc-text">学习率的重要性与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.1.1.</span> <span class="toc-text">学习率大小的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8E%E5%AD%A6%E4%B9%A0%E7%8E%87%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.1.2.</span> <span class="toc-text">梯度与学习率的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">基础自适应学习率方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#adagrad-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.1.</span> <span class="toc-text">AdaGrad 算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rmsprop-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.2.</span> <span class="toc-text">RMSProp 算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adam-%E7%AE%97%E6%B3%95"><span class="toc-number">1.2.3.</span> <span class="toc-text">Adam 算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5"><span class="toc-number">1.3.</span> <span class="toc-text">学习率调度策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#learning-rate-decay"><span class="toc-number">1.3.1.</span> <span class="toc-text">Learning Rate Decay</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#warmup-%E7%AD%96%E7%95%A5"><span class="toc-number">1.3.2.</span> <span class="toc-text">Warmup 策略</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E8%80%83%E8%99%91"><span class="toc-number">1.4.</span> <span class="toc-text">实际应用考虑</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">1.4.1.</span> <span class="toc-text">残差网络中的应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%89%B9%E5%BC%82%E6%80%A7%E8%B0%83%E6%95%B4"><span class="toc-number">1.4.2.</span> <span class="toc-text">参数特异性调整</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.5.</span> <span class="toc-text">算法选择与调优建议</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/study-notes/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%88%9D%E8%AF%86/" rel="bookmark" title="机器学习初识">机器学习初识</a></li><li><a href="/study-notes/machine-learning/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%97%AE%E9%A2%98%EF%BC%9A%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E9%9E%8D%E7%82%B9%E4%B8%8E%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" rel="bookmark" title="模型训练问题：过拟合、鞍点与优化算法">模型训练问题：过拟合、鞍点与优化算法</a></li><li class="active"><a href="/study-notes/machine-learning/%E8%87%AA%E9%80%82%E5%BA%94%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A%E4%BB%8EAdaGrad%E5%88%B0Adam/" rel="bookmark" title="自适应学习率：从AdaGrad到Adam">自适应学习率：从AdaGrad到Adam</a></li><li><a href="/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/" rel="bookmark" title="从回归到分类：Softmax与交叉熵">从回归到分类：Softmax与交叉熵</a></li><li><a href="/study-notes/machine-learning/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" rel="bookmark" title="批量归一化">批量归一化</a></li><li><a href="/study-notes/machine-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/" rel="bookmark" title="卷积神经网络CNN">卷积神经网络CNN</a></li><li><a href="/study-notes/machine-learning/%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B/" rel="bookmark" title="自注意力">自注意力</a></li><li><a href="/study-notes/machine-learning/Transformer/" rel="bookmark" title="Transformer">Transformer</a></li><li><a href="/study-notes/machine-learning/code-implementation/PyTorch%E7%9A%84%E5%88%9D%E6%AD%A5%E4%BD%BF%E7%94%A8%EF%BC%9A%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%AE%80%E5%8D%95%E6%9E%84%E5%BB%BA/" rel="bookmark" title="PyTorch的初步使用：线性模型简单构建">PyTorch的初步使用：线性模型简单构建</a></li><li><a href="/study-notes/machine-learning/code-implementation/Transformer%E7%9A%84%E5%AE%9E%E7%8E%B0/" rel="bookmark" title="Transformer的实现">Transformer的实现</a></li><li><a href="/study-notes/machine-learning/code-implementation/cs231n%E7%9A%84assignment1%EF%BC%9AKNN/" rel="bookmark" title="cs231n的assignment1：KNN">cs231n的assignment1：KNN</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="漠溟绽灵Stinnc" data-src="/images/hdd.jpg"><p class="name" itemprop="name">漠溟绽灵Stinnc</p><div class="description" itemprop="description">嘿嘿嘿~~</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">24</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">10</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">81</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N0aW5uY3NreQ==" title="https:&#x2F;&#x2F;github.com&#x2F;stinncsky"><i class="ic i-github"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTExMDY5NDgzNA==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;110694834"><i class="ic i-cloud-music"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3439-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-I/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/study-notes/" title="分类于 学习笔记">学习笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/study-notes/machine-learning/" title="分类于 机器学习">机器学习</a></div><span><a href="/study-notes/machine-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/" title="卷积神经网络CNN">卷积神经网络CNN</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3169-%E6%97%A0%E9%9C%80%E5%BC%80%E4%BC%9A%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%97%A5/" title="力扣每日一题：3169. 无需开会的工作日">力扣每日一题：3169. 无需开会的工作日</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3202-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-II/" title="力扣每日一题：3202. 找出有效子序列的最大长度 II">力扣每日一题：3202. 找出有效子序列的最大长度 II</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3439-%E9%87%8D%E6%96%B0%E5%AE%89%E6%8E%92%E4%BC%9A%E8%AE%AE%E5%BE%97%E5%88%B0%E6%9C%80%E5%A4%9A%E7%A9%BA%E4%BD%99%E6%97%B6%E9%97%B4-I/" title="力扣每日一题：3439. 重新安排会议得到最多空余时间 I">力扣每日一题：3439. 重新安排会议得到最多空余时间 I</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A2410-%E8%BF%90%E5%8A%A8%E5%91%98%E5%92%8C%E8%AE%AD%E7%BB%83%E5%B8%88%E7%9A%84%E6%9C%80%E5%A4%A7%E5%8C%B9%E9%85%8D%E6%95%B0/" title="力扣每日一题：2410. 运动员和训练师的最大匹配数">力扣每日一题：2410. 运动员和训练师的最大匹配数</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/study-notes/" title="分类于 学习笔记">学习笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/study-notes/machine-learning/" title="分类于 机器学习">机器学习</a></div><span><a href="/study-notes/machine-learning/%E4%BB%8E%E5%9B%9E%E5%BD%92%E5%88%B0%E5%88%86%E7%B1%BB%EF%BC%9ASoftmax%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5/" title="从回归到分类：Softmax与交叉熵">从回归到分类：Softmax与交叉熵</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1290-%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%93%BE%E8%A1%A8%E8%BD%AC%E6%95%B4%E6%95%B0/" title="力扣每日一题：1290. 二进制链表转整数">力扣每日一题：1290. 二进制链表转整数</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A3201-%E6%89%BE%E5%87%BA%E6%9C%89%E6%95%88%E5%AD%90%E5%BA%8F%E5%88%97%E7%9A%84%E6%9C%80%E5%A4%A7%E9%95%BF%E5%BA%A6-I/" title="力扣每日一题：3201. 找出有效子序列的最大长度 I">力扣每日一题：3201. 找出有效子序列的最大长度 I</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/study-notes/" title="分类于 学习笔记">学习笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/study-notes/machine-learning/" title="分类于 机器学习">机器学习</a></div><span><a href="/study-notes/machine-learning/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/" title="批量归一化">批量归一化</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm-solutions/" title="分类于 算法题解">算法题解</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/" title="分类于 力扣">力扣</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm-solutions/leetcode/daily-question/" title="分类于 每日一题">每日一题</a></div><span><a href="/algorithm-solutions/leetcode/daily-question/%E5%8A%9B%E6%89%A3%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%EF%BC%9A1353-%E6%9C%80%E5%A4%9A%E5%8F%AF%E4%BB%A5%E5%8F%82%E5%8A%A0%E7%9A%84%E4%BC%9A%E8%AE%AE%E6%95%B0%E7%9B%AE/" title="力扣每日一题：1353. 最多可以参加的会议数目">力扣每日一题：1353. 最多可以参加的会议数目</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">漠溟绽灵Stinnc @ Stinnc</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">75k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">1:08</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"study-notes/machine-learning/自适应学习率：从AdaGrad到Adam/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script><script src="https://fastly.jsdelivr.net/npm/hexo-tag-common@0.2.0/js/index.js"></script></body></html>